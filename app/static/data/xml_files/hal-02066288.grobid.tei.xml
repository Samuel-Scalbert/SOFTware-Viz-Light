<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Computing and Explaining Query Answers over Inconsistent DL-Lite Knowledge Bases</title>
				<funder ref="#_pdA7y8V">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Meghyn</forename><surname>Bienvenu</surname></persName>
							<email>meghyn@lirmm.fr</email>
						</author>
						<author>
							<persName><forename type="first">François</forename><surname>Goasdoué</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">Université Montpellier</orgName>
								<address>
									<addrLine>2 ; Campus St Priest, 161 rue Ada</addrLine>
									<postCode>34090</postCode>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Télécom ParisTech</orgName>
								<address>
									<addrLine>46 rue Barrault</addrLine>
									<postCode>F-75634, Cedex 13</postCode>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">IRISA</orgName>
								<address>
									<addrLine>6 rue de Kerampont, CS 80518</addrLine>
									<postCode>22305</postCode>
									<settlement>Lannion Cedex</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Computing and Explaining Query Answers over Inconsistent DL-Lite Knowledge Bases</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3CBE11F005716106D5F0B5B12701F650</idno>
					<idno type="DOI">10.1613/jair.1.11395</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-10-23T13:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Several inconsistency-tolerant semantics have been introduced for querying inconsistent description logic knowledge bases. The first contribution of this paper is a practical approach for computing the query answers under three well-known such semantics, namely the AR, IAR and brave semantics, in the lightweight description logic DL-Lite R . We show that query answering under the intractable AR semantics can be performed efficiently by using IAR and brave semantics as tractable approximations and encoding the AR entailment problem as a propositional satisfiability (SAT) problem. The second issue tackled in this work is explaining why a tuple is a (non-)answer to a query under these semantics. We define explanations for positive and negative answers under the brave, AR and IAR semantics. We then study the computational properties of explanations in DL-Lite R . For each type of explanation, we analyze the data complexity of recognizing (preferred) explanations and deciding if a given assertion is relevant or necessary. We establish tight connections between intractable explanation problems and variants of SAT, enabling us to generate explanations by exploiting solvers for Boolean satisfaction and optimization problems. Finally, we empirically study the efficiency of our query answering and explanation framework using a benchmark we built upon the well-established LUBM benchmark.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Description logic (DL) knowledge bases (KBs) consist of a TBox (ontology) that provides conceptual knowledge about the application domain and an ABox (dataset) that contains facts about particular entities <ref type="bibr">(Baader, Calvanese, McGuinness, Nardi, &amp; Patel-Schneider, 2003)</ref>. The problem of querying such KBs using database-style queries (in particular, conjunctive queries, or CQs) has been a major focus of recent DL research. Since scalability is a key concern, much of the work has focused on lightweight DLs for which query answering can be performed in polynomial time w.r.t. the size of the ABox. The DL-Lite family of lightweight DLs <ref type="bibr" target="#b28">(Calvanese, De Giacomo, Lembo, Lenzerini, &amp; Rosati, 2007)</ref> is especially c 2019 AI Access Foundation. All rights reserved.</p><p>popular due to the fact that query answering can be reduced, via query rewriting, to the problem of standard database query evaluation. The importance of the DL-Lite family is witnessed by the inclusion of the OWL 2 QL profile <ref type="bibr" target="#b58">(Motik, Cuenca Grau, Horrocks, Wu, Fokoue, &amp; Lutz, 2012)</ref>, based upon DL-Lite R , in the latest version of OWL <ref type="bibr">(OWL Working Group, 2009)</ref>, the W3C-standardized ontology language for the Semantic Web.</p><p>Since the TBox is usually developed by experts and subject to extensive debugging, it is often reasonable to assume that its contents are correct. By contrast, the ABox is typically substantially larger and subject to frequent modifications, making errors almost inevitable. As such errors may render the KB inconsistent, several inconsistency-tolerant semantics have been introduced to provide meaningful answers to queries posed over inconsistent KBs (see <ref type="bibr">Bienvenu &amp; Bourgaux, 2016</ref>, for a survey and Section 8.1 for further discussion and references). Arguably the most natural and well-known inconsistency-tolerant semantics is the AR semantics (AR for 'ABox Repair') <ref type="bibr" target="#b49">(Lembo, Lenzerini, Rosati, Ruzzi, &amp; Savo, 2010</ref><ref type="bibr">, 2015)</ref>, inspired by work on consistent query answering in databases (initiated by <ref type="bibr" target="#b1">Arenas, Bertossi, and Chomicki, 1999</ref>; see also the survey by <ref type="bibr" target="#b15">Bertossi, 2011)</ref>. Query answering under AR semantics amounts to considering those answers that can be obtained from every repair, the latter being defined as an inclusion-maximal subset of the ABox that is consistent with the TBox. The more cautious IAR semantics (IAR for 'Intersection of ABox Repairs') <ref type="bibr" target="#b49">(Lembo et al., 2010</ref><ref type="bibr" target="#b51">(Lembo et al., , 2015) )</ref> queries the intersection of the repairs and provides a lower bound on AR semantics. The brave semantics <ref type="bibr" target="#b21">(Bienvenu &amp; Rosati, 2013)</ref>, which considers those answers holding in at least one repair, provides a natural upper bound.</p><p>The complexity of ontology-mediated query answering (OMQA) under inconsistencytolerant semantics has been the subject of several papers (see e.g. <ref type="bibr" target="#b64">Rosati, 2011;</ref><ref type="bibr" target="#b17">Bienvenu, 2012;</ref><ref type="bibr" target="#b54">Lukasiewicz, Martinez, &amp; Simari, 2013)</ref>. Not too surprisingly, given prior negative results on consistent query answering in databases, the AR semantics was shown to be coNPhard in data complexity for DL-Lite ontologies <ref type="bibr" target="#b49">(Lembo et al., 2010)</ref>, and coNP-hardness has been shown to hold in even more restricted settings <ref type="bibr" target="#b17">(Bienvenu, 2012)</ref>, dashing hopes of taming intractability by limiting the expressivity of the ontology language. The IAR and brave semantics, by contrast, enjoy polynomial data complexity for DL-Lite ontologies (and more generally, all ontology languages that admit first-order query rewritings) <ref type="bibr" target="#b50">(Lembo, Lenzerini, Rosati, Ruzzi, &amp; Savo, 2011;</ref><ref type="bibr" target="#b51">Lembo et al., 2015;</ref><ref type="bibr" target="#b21">Bienvenu &amp; Rosati, 2013)</ref>.</p><p>As the complexity of inconsistency-tolerant query answering in the presence of ontologies is now well understood, attention has turned to the problem of implementing these alternative semantics. Most work has focused on the IAR semantics and DL-Lite ontology languages, due to the aforementioned tractability result. The QuID system <ref type="bibr" target="#b66">(Rosati, Ruzzi, Graziosi, &amp; Masotti, 2012)</ref> implements the IAR semantics, using either query rewriting or ABox cleaning, and the SaQAI system <ref type="bibr" target="#b71">(Tsalapati, Stoilos, Stamou, &amp; Koletsos, 2016)</ref> implements IAR using ABox cleaning and saturation, as well as the ICAR semantics (that corresponds to the IAR semantics over the saturated ABox, <ref type="bibr" target="#b49">Lembo et al., 2010)</ref>. For the natural but intractable AR semantics, some implementations of consistent query answering have been proposed in the database setting, but we are not aware of any system implementing the AR semantics for DL KBs. It was thus left open whether the IAR semantics constitutes a good approximation of the AR semantics, and whether one can devise practical querying algorithms for AR semantics despite the negative complexity results.</p><p>The first contribution of this paper is to develop and evaluate a practical method for CQ answering over inconsistent DL-Lite R KBs under the AR semantics. Our approach first computes the answers under the simpler IAR and brave semantics, in order to obtain upper and lower bounds on the set of answers under AR semantics: answers holding under the stricter IAR semantics help us identify a portion of the AR-answers, and tuples that are not found to be brave-answers allow us to mark some tuples as non-answers under AR semantics 1 . To determine the status of the remaining tuples (i.e. tuples holding under brave semantics but not under IAR semantics), we provide an encoding in terms of propositional unsatisfiability, which can then be passed to an off-the-shelf SAT solver. In addition to using the IAR and brave semantics to reduce the number of calls to the SAT solver, we propose to use these three semantics to partition query answers into three classes of varying reliability: (Almost) Sure (those answers holding under IAR semantics), Likely (answers holding under AR semantics, but not IAR semantics), and Possible (answers holding only under brave semantics). Our approach has been implemented in the CQAPri system and evaluated over the benchmark we built starting from the well-known LUBM benchmark. 2  The principal conclusion of our experiments is that it is feasible to compute answers under the AR semantics, and this is due in large part to the fact that the IAR semantics is able to identify a large share of the AR-answers.</p><p>While efficiency is crucial when developing ontology-mediated query answering systems, it is also important to consider other aspects related to the usability of such systems. In particular, the need to equip reasoning systems with explanation services is widely acknowledged by the DL community (see Section 8 for discussion and references). The study of explanation services for DLs has thus far focused primarily on explaining entailed TBox axioms or ABox assertions, and the problem of explaining answers to CQs under the classical semantics for consistent KBs has been studied in only a few works, mostly for consistent KBs. A proof-theoretic approach to explaining positive answers to CQs over consistent DL-Lite A KBs was introduced by Borgida, <ref type="bibr" target="#b22">Calvanese, and Rodriguez-Muro (2008)</ref>. It outputs a single proof, involving both TBox axioms and ABox assertions, that is generated by 'tracing back' the relevant part of the rewritten query, using minimality criteria to select a 'simplest' proof. For negative answers, explanations for why a tuple is not an answer to a CQ are defined by <ref type="bibr" target="#b29">Calvanese, Ortiz, Simkus, and Stefanoni (2013)</ref> as sets of ABox assertions that can be added to the ABox to make the tuple become an answer. Practical algorithms and an implementation for computing such explanations were described by <ref type="bibr" target="#b37">Du, Wang, and Shen (2014)</ref>. The latter work was recently extended to the case of inconsistent KBs <ref type="bibr" target="#b38">(Du, Wang, &amp; Shen, 2015)</ref>: essentially the idea is to add a set of ABox assertions that will lead to the answer holding under IAR semantics (in particular, the new assertions must not introduce any inconsistencies). Explanation facilities are all the more essential when using inconsistency-tolerant semantics, as has been argued by <ref type="bibr" target="#b5">Arioua, Tamani, and Croitoru (2014)</ref>. Indeed, as we propose to use the brave, AR, and IAR semantics conjointly 1. The use of tractable upper and lower bounds is a common technique for coping with the intractability of reasoning, cf. the seminal work of <ref type="bibr" target="#b69">Selman and Kautz (1991)</ref> on Horn approximations, or more recent work on using Datalog approximations for CQ answering over expressive DL ontologies <ref type="bibr" target="#b73">(Zhou, Grau, Nenov, Kaminski, &amp; Horrocks, 2015)</ref>. In these works, the original KB is approximated using a tractable language, whereas we keep the original KB but adopt tractable approximate semantics. 2. The CQAPri system and benchmark can be downloaded from https://www.lri.fr/ ~bourgaux/CQAPri.</p><p>to classify query answers into three categories of increasing reliability, a user may naturally wonder why a given tuple was assigned to, or excluded from, one of these categories.</p><p>Our second contribution is the development and experimentation of a framework for explaining query (non)answers under inconsistency-tolerant semantics. Specifically, we define explanations of positive and negative query answers under brave, AR and IAR semantics. Intuitively, such explanations pinpoint the portions of the ABox that, in combination with the TBox, suffice to obtain a given query (non-)answer under the considered semantics. We focus on ABox assertions since inconsistencies are assumed to stem from errors in the ABox, and because this already yields a non-trivial framework to study. We investigate the main search and decision problems related to explanations: generating an (arbitrary) explanation, generating a most preferred explanation according to some natural ranking criteria, recognizing (most preferred) explanations, and checking whether an assertion is relevant/necessary (i.e. appears in some/all explanations). We study the data complexity of these problems for DL-Lite R , showing (in)tractability of each of the tasks and pinpointing the exact complexity of the intractable decision problems. Interestingly, we establish tight connections between the intractable decision problems, as well as the problem of generating (preferred) explanations, and SAT-based reasoning tasks like computing minimal models or minimal unsatisfiable sets of clauses (so-called MUSes). This enables effective solutions to these problems using solvers for Boolean satisfaction and optimization problems. We have implemented our explanation services in CQAPri and performed experiments to understand the practical difficulty of computing (preferred) explanations and the sets of relevant and necessary assertions. Our experiments show that explanations can generally be computed in a reasonable amount of time.</p><p>This article extends two conference papers <ref type="bibr" target="#b19">(Bienvenu, Bourgaux, &amp; Goasdoué, 2014</ref><ref type="bibr" target="#b25">, 2016)</ref>. Compared to the conference versions, the present article includes some improved complexity upper bounds (the AC 0 membership results in Table <ref type="table" target="#tab_2">1</ref>) and full proofs of the complexity results; it also describes the results of a new set of experiments with an improved benchmark and provides a more thorough analysis of the cost of explanations.</p><p>Organization of this paper Section 2 presents the syntax and semantics of DL-Lite knowledge bases, introduces query answering and query rewriting, and recalls relevant complexity classes and complexity results. In Section 3, we define the three inconsistencytolerant semantics considered in this paper (brave, IAR, and AR) and discuss their properties. The following section describes the algorithms we use to perform query answering under these semantics, and in particular, we define the SAT encoding used for the AR semantics. Our explanation framework is presented in Section 5, with a first subsection devoted to introducing and illustrating the different notions of explanation, and a second subsection providing a comprehensive complexity analysis of the main decision and generating tasks related to explanations. In Section 6, we describe the CQAPri system and the benchmark we developed, and Section 7 presents the results of our experimental evaluation. We conclude the paper with a discussion of related work (Section 8) and directions for future work (Section 9). To improve readability, we have moved some proofs to Appendix A and large figures and tables to Appendix B.</p><p>T * = {AProf Prof, FProf Prof, ∃Advise Prof, Prof PhD, Postdoc PhD, AProf ¬FProf, Prof ¬Postdoc} A * = {Postdoc(ann), AProf(ann), FProf(ann), Advise(ann, bob), Teach(ann, c 1 ), Teach(ann, c 2 ), Teach(ann, c 3 )} q 1 (x) = Prof(x) q 2 (x) = ∃y PhD(x) ∧ Teach(x, y) q 3 (x) = ∃y Teach(x, y)</p><p>Figure <ref type="figure">1</ref>: TBox, ABox, and queries used in the running example</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Preliminaries</head><p>In this section, we recall the framework of ontology-mediated query answering in the setting of description logics, focusing on the lightweight logic DL-Lite R , which provides the logical underpinnings of the OWL 2 QL profile.</p><p>Syntax A DL knowledge base (KB) consists of an ABox and a TBox, both constructed from a set N C of concept names (unary predicates), a set of N R of role names (binary predicates), and a set N I of individuals (constants). The ABox (dataset) consists of a finite number of concept assertions of the form A(a) and role assertions of the form R(a, b), where A TBox axiom of the form B 1 B 2 or S 1 S 2 is a positive inclusion, and a TBox axiom of the form B 1 ¬B 2 or S 1 ¬S 2 is a negative inclusion.</p><formula xml:id="formula_0">A ∈ N C , R ∈ N R ,</formula><p>Example 1. For our running example, we will use the DL-Lite R KB K * = T * , A * in Figure <ref type="figure">1</ref> about the university domain. The TBox T * expresses relationships between concepts for professors (Prof) of two levels of seniority (AProf, FProf), PhD holders (PhD), postdoctoral researchers (Postdoc), and roles linking instructors to their courses (Teach) and advisors to their students (Advise). For example, the third inclusion states that everyone who advises someone is a professor, and the last asserts the disjointness of concepts Prof and Postdoc. The ABox A * provides information about an individual ann. For instance, the first and last assertions state respectively that ann is a postdoc and ann teaches c 3 .</p><p>Semantics An interpretation has the form I = (∆ I , • I ), where ∆ I is a non-empty set and We say that I satisfies an inclusion G H if G I ⊆ H I ; it satisfies A(a) (resp. R(a, b)) if a I ∈ A I (resp. (a I , b I ) ∈ R I ). We call I a model of K = T , A if I satisfies all axioms in T and assertions in A. A KB K is consistent if it has a model; otherwise it is inconsistent, denoted K |= ⊥. An ABox A is T -consistent if the KB K = T , A is consistent.</p><formula xml:id="formula_1">• I maps each A ∈ N C to A I ⊆ ∆ I , each R ∈ N R to R I ⊆ ∆ I × ∆ I ,</formula><p>Queries A first-order (FO) query is a first-order logic formula whose atoms are built using the predicate symbols in N C ∪ N R and constants in N I . For the user queries, we will focus on the subclass of conjunctive queries (CQs) which take the form q( x) = ∃ y ψ( x, y), where ψ is a conjunction of atoms of the forms A(t) or R(t, t ) whose terms are either variables from x ∪ y or individuals. A CQ consisting of a single atom is called an instance query (IQ). For convenience, we introduce functions atoms and terms that return respectively the set of atoms and terms in a query. A query without free variables is called Boolean. Given a query q( x) with free variables x = (x 1 , . . . , x k ) and a tuple of individuals a = (a 1 , . . . , a k ), we say that q has arity k and use q( a) to denote the Boolean query resulting from replacing each x i by a i .</p><p>A tuple of individuals a is an answer to an FO query q( x) of an interpretation I, written I |= q( a), iff it has the same arity as q and the Boolean query q( a) is satisfied in I according to standard first-order logic semantics. When q is a CQ, one can define answers in terms of the existence of matches, where a match for q( a) in I is a function π : terms(q) → ∆ I such that (i) π( x) = (a I 1 , . . . , a I k ), (ii) π(t) = t I for every t ∈ N I , (iii) π(t) ∈ A I for every A(t) ∈ atoms(q), and (iv) (π(t), π(t )) ∈ R I for every R(t, t ) ∈ atoms(q). Thus, I |= q( a) iff there is a match for q( a) in I. The set of answers for a query q( x) in I is denoted ans(q, I).</p><p>When we speak of query answering, we mean the problem of computing the set of certain answers to the query, defined as follows. A tuple a is a certain answer to q over K, written K |= q( a), iff a is an answer to q( x) in every model of K. The set of certain answers for q( x) over K is written cert(q, K). We remark that when K is inconsistent, cert(q, K) contains every tuple of ABox individuals having the same arity as q.</p><p>Complexity measures When analyzing the complexity of query answering, we consider the associated decision problem: given a KB K = T , A , query q( x), and tuple of individuals a of the same arity as x, decide whether K |= q( a). There are different ways of measuring the complexity of query answering (or query evaluation), depending on which parameters are regarded as the input. Data complexity considers only the size of the ABox (data), denoted |A|, whereas combined complexity considers the size of the whole problem, i.e. the size of the KB (|K| = |A| + |T |) plus the size of the query |q| (defined as the number of atoms in the query). Data complexity is considered the more relevant measure when the size of the TBox and the size of the query are negligible compared to the size of the ABox, which is typically the case in the context of OMQA.</p><p>The following complexity classes are used in this work (we refer the reader to <ref type="bibr" target="#b61">Papadimitriou, 1995;</ref><ref type="bibr" target="#b7">Arora &amp; Barak, 2009</ref>, for introductions to computational complexity):</p><p>• AC 0 : problems that can be solved by a uniform family of cicuits of constant depth and polynomial-size, with unbounded-fanin AND and OR gates.</p><p>• NL: problems that can be solved in non-deterministic logarithmic space.</p><p>• PTime: problems which are solvable in polynomial time in the size of the input.</p><p>• NP: problems which are solvable in non-deterministic polynomial time.</p><p>• coNP: problems whose complement is in NP.</p><p>• BH 2 : problems that are the intersection of a problem in NP and a problem in coNP.</p><p>• Σ p 2 : problems which are solvable in non-deterministic polynomial time with access to an NP oracle.</p><p>• Π p 2 : problems whose complement is in Σ p 2 .</p><p>These classes are related as follow:</p><formula xml:id="formula_2">AC 0 ⊆ NL ⊆ PTime, PTime ⊆ NP ⊆ Σ p 2 and PTime ⊆ coNP ⊆ Π p 2 . It is known that AC 0</formula><p>PTime, and it is widely believed that all of the inclusions are proper.</p><p>We recall that in the database setting, the problem of deciding if a tuple is an answer to an FO query is in AC 0 in data complexity <ref type="bibr" target="#b46">(Immerman, 1987)</ref>, and (the decision version of) CQ evaluation is NP-complete in combined complexity <ref type="bibr" target="#b30">(Chandra &amp; Merlin, 1977)</ref>.</p><p>Query answering through rewriting We now introduce query rewriting, which is a prominent algorithmic approach to OMQA. The basic idea is to rewrite the query so as to incorporate all relevant information from the TBox, and then evaluate the rewritten query over the ABox, which is treated as a database.</p><p>Formally, with every ABox A, we associate a corresponding interpretation I A = (∆ I A , • I A ) defined as follows:</p><formula xml:id="formula_3">∆ I A = Ind(A) A I A = {a | A(a) ∈ A} for every A ∈ N C a I A = a for every a ∈ Ind(A) R I A = {(a, b) | R(a, b) ∈ A} for every R ∈ N R</formula><p>The interpretation treats the ABox like a relational database by making true precisely those assertions appearing in the ABox. A (first-order) rewriting of a query q w.r.t. a TBox T and T -consistent ABoxes is an FO-query q such that cert(q, T , A ) = ans(q , I A ) for all T -consistent ABoxes A. Observe that the original problem of computing cert(q, T , A ) is reduced to the task of evaluating a first-order query q over the finite interpretation I A , and the latter task can be handled by a relational database system. (We shall see later in the section how to check whether the input ABox is T -consistent, which will allow us to devise rewritings that work for arbitrary ABoxes.)</p><p>The DL-Lite family possesses the first-order rewritability property, meaning that for standard DL-Lite dialects like DL-Lite R , there exists an FO-rewriting of every CQ and every TBox (which is not the case for most DLs). In fact, it is sufficient to consider UCQrewritings, which take the more restricted form of unions of conjunctive queries. We note that when working with UCQs, we will sometimes treat them as sets of CQs, using e.g. q ∈ Q to denote that q is a disjunct of the UCQ Q.</p><p>Example 2. The UCQ q (x) = Prof(x) ∨ AProf(x) ∨ FProf(x) ∨ ∃yAdvise(x, y) is a rewriting of q 1 (x) = Prof(x) w.r.t. T * and consistent ABoxes. Observe that the disjuncts capture the four different ways to infer that an individual is a professor according to the TBox T * .</p><p>Several concrete UCQ-rewriting algorithms have been developed and implemented for DL-Lite R . The original PerfectRef algorithm of <ref type="bibr" target="#b28">Calvanese et al. (2007)</ref> and most subsequent proposals employ a backwards-chaining approach, in which each rewriting step replaces a query atom by another atom which implies it. Importantly, while the resulting UCQ may be of exponential size, every CQ in the disjunction has no more atoms than the original query (a property that we will exploit later).</p><p>Answering a CQ q over a consistent DL-Lite KB T , A amounts to searching for matches for the CQs in a UCQ-rewriting of q in I A . We introduce the notion of image to capture the parts of the ABox that participate in a match. Formally, an image of a CQ q( x) = ∃ y ψ( x, y) in an ABox A is a set of assertions B ⊆ A such that there is a match π : x ∪ y → Ind(A) for q in I A such that B = atoms(ψ(π( x), π( y))). We can extend the notion of image to UCQs as follows: a set of assertions is an image of a UCQ Q iff it is the image of some CQ q ∈ Q.</p><p>The following theorem recalls the complexity of query answering in DL-Lite R . Membership in AC 0 for data complexity is an immediate consequence of the reduction to FO-query evaluation, which is known to be in AC 0 for data complexity, and the NP lower bound is likewise inherited from the NP-hardness of CQ evaluation over relational databases. For the NP upper bound, we cannot directly use the UCQ-rewriting, as it can be of exponential size. Instead, one can guess a single CQ in the UCQ-rewriting, together with a polynomial proof that this CQ appears in the rewriting and has an image in the ABox. For instance queries, one can exploit the fact that each disjunct in the UCQ-rewriting has a single atom.</p><p>Theorem 2.1 <ref type="bibr" target="#b28">(Calvanese et al., 2007;</ref><ref type="bibr" target="#b8">Artale, Calvanese, Kontchakov, &amp; Zakharyaschev, 2009)</ref>. In DL-Lite R , conjunctive query answering is AC 0 w.r.t. data complexity and NPcomplete w.r.t. combined complexity. Instance checking is in PTime (more precisely: NLcomplete) w.r.t. combined complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ABox consistency</head><p>In DL-Lite R , ABox consistency checking reduces to answering a union of conjunctive queries corresponding to each possible violation of the TBox constraints: we can build a Boolean query q T unsat that looks for a counterexample to one of the negative inclusions entailed by T , and which evaluates to true over I A just in the case that the ABox A is T -inconsistent.</p><p>We briefly explain how to construct q T unsat . First, for each negative inclusion ζ ∈ T in the TBox, build a Boolean CQ γ ζ that tests for a direct violation of ζ. Then each CQ γ ζ is rewritten w.r.t. T , yielding a UCQ Γ ζ that tests for any (possibly indirect) violation of ζ. Finally, we take the disjunction of the rewritten queries: q T unsat = ζ Γ ζ , where ζ ranges over the negative inclusions in T . We illustrate the procedure in the following example.</p><p>Example 3. The TBox T * contains two negative inclusions</p><formula xml:id="formula_4">ζ 1 = AProf ¬FProf and ζ 2 = Prof ¬Postdoc.</formula><p>To check for a direct violation of AProf ¬FProf, we can use the CQ γ ζ 1 = ∃xAProf(x) ∧ FProf(x). The rewriting step leaves this CQ unchanged (as there is no way to derive AProf or FProf), so Γ ζ 1 = γ ζ 1 . For the second negative inclusion, we build the CQ</p><formula xml:id="formula_5">γ ζ 2 = ∃xProf(x) ∧ Postdoc(x), which is rewritten into the following UCQ (∃x Prof(x) ∧ Postdoc(x)) ∨ (∃x AProf(x) ∧ Postdoc(x))∨ (∃x FProf(x) ∧ Postdoc(x)) ∨ (∃xy Advise(x, y) ∧ Postdoc(x))</formula><p>Finally, we take the disjunction of the computed UCQs, to get q</p><formula xml:id="formula_6">T * unsat = Γ ζ 1 ∨ Γ ζ 2 .</formula><p>The next theorem recalls the complexity of consistency checking in DL-Lite R . To show the polynomial combined complexity result, one can exploit the fact that each CQ appearing in q T unsat has at most two atoms, and thus it suffices to examine all (polynomially many) subsets of the ABox with at most two assertions to see if they contain a match for q T unsat .</p><p>Theorem 2.2 <ref type="bibr" target="#b28">(Calvanese et al., 2007;</ref><ref type="bibr" target="#b8">Artale et al., 2009)</ref>. In DL-Lite R , consistency checking is in AC 0 w.r.t. data complexity, and in PTime (more precisely: NL-complete) w.r.t. combined complexity.</p><p>We conclude this section by observing that one can combine in a straightforward manner a rewriting of q w.r.t. T and T -consistent ABoxes with the unsatisfiability query q T unsat in order to obtain a rewriting that outputs the certain answers irregardless of whether the considered ABox is T -consistent. Indeed, it suffices to consider the query q rw ∨(q T unsat ∧q all ), where q rw is a rewriting for consistent ABoxes and q all is a query that returns all tuples of ABox individuals of the same arity as q.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Inconsistency-Tolerant Semantics</head><p>When the ABox is inconsistent with the TBox, it may be impossible to clean the data to make it consistent, either for lack of time because the data is too large, or for lack of information on how to resolve the contradictions. It is therefore crucial to be able to retrieve meaningful answers from inconsistent data. However, when the KB is inconsistent, every Boolean query is entailed under the classical semantics, and for non-Boolean queries, every tuple of individuals of the appropriate arity is considered a certain answer. Classical semantics is essentially useless in the inconsistent case, as it fails to provide any relevant information, motivating the need for alternative semantics. In this section, we present three inconsistency-tolerant semantics that have been proposed in the literature to query inconsistent KBs, namely, the AR, IAR, and brave semantics, and we recall what is known about the complexity of query answering under these semantics in DL-Lite R .</p><p>The AR semantics (ABox Repair semantics) <ref type="bibr" target="#b49">(Lembo et al., 2010)</ref> adapts the consistent query answering framework developed in the database arena <ref type="bibr" target="#b1">(Arenas et al., 1999;</ref><ref type="bibr" target="#b14">Bertossi, 2006;</ref><ref type="bibr" target="#b32">Chomicki, 2007;</ref><ref type="bibr" target="#b15">Bertossi, 2011)</ref> to DL KBs. Consistent query answering amounts to considering those answers that hold in every repair, defined as consistent subsets of the database that are "as close as possible" to the actual database instance. In the database setting, which adopts the closed world assumption, repairs may be obtained from the actual database by deletion or insertion of tuples (or changes of attributes values), since constraints may be violated by either the presence or absence of certain tuples. By contrast, in the DL setting where open world semantics is used, inconsistency can only stem from the presence of incompatible ABox assertions, leading to a simpler notion of repair based upon removal of assertions: Definition 3.1 (Repair). An ABox repair of a KB T , A , or repair for short, is an inclusion-maximal subset of the ABox A which is T -consistent. The set of all repairs of K = T , A is denoted by Rep(K) or Rep(T , A). Each repair contains one of the three assertions about the position ann occupies (Postdoc or AProf or FProf), and omits all conflicting assertions. For instance, the first repair, R 1 , retains Postdoc(ann) and drops the three assertions that contradict it according to the knowledge in T * , namely, AProf(ann), FProf(ann), and Advise(ann, bob).</p><p>The repairs correspond to all possible ways of repairing the ABox while preserving as much information as possible (in the sense of set inclusion) and can be viewed as 'possible worlds'. If the quality of the data is relatively good, we can assume that one of the repairs corresponds to the real world, but in the absence of further information, we cannot know which one. For this reason, the AR semantics stipulates that for a tuple to be counted as an answer to a query over an inconsistent KB, it must hold w.r.t. every repair. Formally: Definition 3.2 (AR semantics). A tuple a is an answer to a query q over a KB T , A under AR semantics, written T , A |= AR q( a), if and only if T , R |= q( a) for every repair R ∈ Rep(T , A). We call a a (positive) AR-answer.</p><p>Example 5. In our running example, we consider the three queries given in Figure <ref type="figure">1</ref>. Evaluating these queries over the KB K * under AR semantics yields the following results:</p><formula xml:id="formula_7">K * |= AR Prof(ann) K * |= AR ∃y PhD(ann)∧Teach(ann, y) K * |= AR ∃y Teach(ann, y)</formula><p>Indeed, it can be verified that T * , R 1 |= Prof(ann), and for every 1 ≤ i ≤ 3, we have T * , R i |= ∃y PhD(ann) ∧ Teach(ann, y) and T * , R i |= ∃y Teach(ann, y).</p><p>The AR semantics is arguably the most natural inconsistency-tolerant semantics. Unfortunately, as the next result shows, query answering under AR semantics is intractable in data complexity, even for instance queries. The coNP lower bound exploits the fact that the number of repairs may be exponential in the size of the ABox, while the coNP upper bound can be shown by a simple guess-and-check procedure: to show T , A |= AR q( a), guess a subset R ⊆ A and verify that it is a repair such that T , R |= q( a).</p><p>Theorem 3.3 <ref type="bibr" target="#b49">(Lembo et al., 2010)</ref>. Conjunctive query answering and instance checking under AR semantics over DL-Lite R knowledge bases are both coNP-complete w.r.t. data complexity.</p><p>We remark that tractability cannot be regained by reducing the expressivity of the ontology: <ref type="bibr" target="#b17">Bienvenu (2012)</ref> showed that CQ answering is coNP-complete w.r.t. data complexity even for simple ontologies consisting of axioms of the form</p><formula xml:id="formula_8">A 1 (¬)A 2 , where A 1 , A 2 ∈ N C .</formula><p>As for classical semantics, where the combined complexity of CQ answering is higher than its data complexity (NP vs. AC 0 ), the combined complexity of query answering under AR semantics is a level higher in the polynomial hierarchy than its data complexity.</p><p>Theorem 3.4 <ref type="bibr" target="#b21">(Bienvenu &amp; Rosati, 2013)</ref>. Conjunctive query answering under AR semantics over DL-Lite R knowledge bases is Π p 2 -complete w.r.t. combined complexity, and instance checking is coNP-complete w.r.t. combined complexity.</p><p>The negative complexity results for AR semantics led <ref type="bibr" target="#b49">Lembo et al. (2010)</ref> to propose an approximation of AR semantics that corresponds to querying the intersection of the repairs. The resulting IAR (Intersection of ABox Repairs) semantics is formally defined as follows: Definition 3.5 (IAR semantics). A tuple a is an answer to a query q over a KB K = T , A under IAR semantics, written T , A |= IAR q( a), if and only if T , R ∩ |= q( a), where R ∩ is the intersection of the repairs of K. We call a a (positive) IAR-answer.</p><p>This semantics follows the 'when in doubt throw it out' principle, proposed in the area of belief revision and update, and provides a more conservative semantics than AR. The answers holding under IAR semantics can reasonably be considered the most reliable answers, as they do not rely upon any assertions involved in contradictions.</p><p>Example 6. Intersecting the repairs R 1 , R 2 , and R 3 yields the following ABox:</p><p>A * ∩ = {Teach(ann, c 1 ), Teach(ann, c 2 ), Teach(ann, c 3 )} If we evaluate our example queries over the KB T * , A * ∩ , we obtain:</p><formula xml:id="formula_9">T * A * ∩ |= Prof(ann) T * , A * ∩ |= ∃y PhD(ann) ∧ Teach(ann, y) T * , A *</formula><p>∩ |= ∃y Teach(ann, y) We therefore obtain the following results under IAR semantics:</p><formula xml:id="formula_10">K * |= IAR Prof(ann) K * |= IAR ∃y PhD(ann) ∧ Teach(ann, y) K * |= IAR ∃y Teach(ann, y)</formula><p>Observe that if we move from AR to IAR semantics, ann is no longer considered an answer to q 2 . This is because there is no single justification for PhD(ann) common to all repairs.</p><p>The next theorem summarizes what is known about the complexity of query answering under IAR semantics. The AC 0 upper bound in data complexity (which matches that of classical semantics) is shown by defining a first-order query rewriting procedure. The general idea is to add to the classical UCQ-rewriting expressions that ensure that the assertions used to derive the query are not contradicted by other assertions by enumerating the different possible contradictions. See Section 8.2.1 for other approaches to IAR query answering.</p><p>Theorem 3.6 <ref type="bibr" target="#b50">(Lembo et al., 2011</ref><ref type="bibr" target="#b51">(Lembo et al., , 2015;;</ref><ref type="bibr" target="#b21">Bienvenu &amp; Rosati, 2013)</ref>. CQ answering under IAR semantics over DL-Lite R knowledge bases is in AC 0 w.r.t. data complexity and NPcomplete w.r.t. combined complexity. Instance checking is NL-complete w.r.t. combined complexity.</p><p>While the IAR semantics is the most cautious inconsistency-tolerant semantics, the brave semantics introduced by <ref type="bibr" target="#b21">Bienvenu and Rosati (2013)</ref>, which considers those answers that can be obtained from at least one repair, can be viewed as the most permissive: Definition 3.7 (Brave semantics). A tuple a is an answer for a query q over a KB K = T , A under brave semantics, written T , A |= brave q( a), if and only if T , R |= q( a) for some repair R ∈ Rep(T , A). We call a a (positive) brave-answer.</p><p>It is possible to perform query answering under brave semantics by means of first-order query rewriting, yielding a low AC 0 data complexity: Theorem 3.8 <ref type="bibr" target="#b21">(Bienvenu &amp; Rosati, 2013)</ref>. CQ answering under brave semantics over DL-Lite knowledge bases is in AC 0 w.r.t. data complexity and NP-complete w.r.t. combined complexity. Instance checking is NL-complete w.r.t. combined complexity.</p><p>Example 7. Evaluating our example queries under the brave semantics yields: K * |= brave Prof(ann) K * |= brave ∃y PhD(ann)∧Teach(ann, y) K * |= brave ∃y Teach(ann, y) Indeed, for all three queries, there exists at least one repair in which ann is obtained as an answer. Specifically, we have T * , R 2 |= Prof(ann), T * , R 1 |= ∃y PhD(ann) ∧ Teach(ann, y), and T * , R 1 |= ∃y Teach(ann, y). Observe that under brave semantics, ann is an answer to q 1 , whereas it is not an answer under AR semantics.</p><p>We point out that the set of answers that are obtained using brave semantics may be inconsistent when considered together. In our example, the brave semantics allows us to infer both Postdoc(ann) and AProf(ann), which contradict each other in the presence of the TBox. By contrast, it is impossible to derive a contradiction from the set of query answers obtained using AR (or IAR) semantics, since there exists a single repair from which all such answers can be derived, and by definition, a repair is consistent with the TBox.</p><p>The relations between the three semantics are stated in the following proposition. The IAR semantics is an under-approximation of the AR semantics, i.e. every query answer under IAR semantics also counts as an answer under AR semantics, whereas brave semantics provides an over-approximation, i.e. every query answer obtained using AR semantics is also an answer under brave semantics.</p><p>Proposition 3.9. The IAR, AR, and brave semantics are related as follows:</p><formula xml:id="formula_11">K |= IAR q( a) =⇒ K |= AR q( a) =⇒ K |= brave q( a)</formula><p>None of the reverse implications holds.</p><p>By using the three semantics together, we can classify query answers into three categories based upon their reliability, with IAR semantics identifying the surest answers, AR semantics identifying answers that are reasonably likely to hold, and brave semantics identifying possible answers, which have at least one consistent reason to hold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Efficient Inconsistency-Tolerant Query Answering in DL-Lite</head><p>This section presents the algorithms we use to compute the query answers under the brave, IAR, and AR semantics. Their implementation is described later in Section 6.</p><p>We should emphasize that the novel contribution of this section is the algorithm for the AR semantics and the use of the three semantics together to classify query answers, as algorithms for querying DL-Lite KBs under the IAR and brave semantics have already been proposed by <ref type="bibr" target="#b50">Lembo et al. (2011</ref><ref type="bibr" target="#b51">Lembo et al. ( , 2015) )</ref> and <ref type="bibr" target="#b21">Bienvenu and Rosati (2013)</ref>.</p><p>Henceforth, to simplify formulations, we will sometimes refer to T without explicitly stating that it is a TBox, and likewise, for A (ABox), K (KB), q (conjunctive query), x (tuple of variables), and a (tuple of individuals).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Conflicts and Causes</head><p>As a first step, we introduce two central notions of conflicts and causes, as well as basic procedures for computing them. Conflicts are simply defined as the minimal sets of assertions responsible for a KB being inconsistent:</p><formula xml:id="formula_12">Definition 4.1 (Conflict). A conflict 4 of K = T , A is an inclusion-minimal T -inconsistent subset of A. The set of conflicts of K is denoted conflicts(K).</formula><p>Observe that a consistent KB has an empty set of conflicts, while an inconsistent KB must possess at least one conflict.</p><p>Example 8. The KB K * has the following conflicts: conflicts(K * ) ={{AProf(ann), FProf(ann)}, {AProf(ann), Postdoc(ann)}, {FProf(ann), Postdoc(ann)}, {Advise(ann, bob), Postdoc(ann)}}</p><p>The following proposition relates the conflicts of a KB with the images of the unsatisfiability query q T unsat from Section 2.</p><p>Proposition 4.2. A subset U ⊆ A belongs to conflicts(T , A) iff U is an inclusion-minimal image of q T unsat in A.</p><p>We give an example that shows that some images of q T unsat may not be conflicts:</p><p>Example 9. Consider T = {∃R - ¬∃R} and ABox A = {R(a, a), R(a, b)}. The associated query q T unsat = ∃xyzR(x, y) ∧ R(y, z) has two images in A: {R(a, a), R(a, b)} and {R(a, a)}. However, due to the minimality requirement, only {R(a, a)} is a conflict.</p><p>In Algorithm 1, we propose a simple procedure ComputeConflicts for computing conflicts that is based upon Proposition 4.2 and can use any existing UCQ-rewriting procedure. The first step (line 2) is to construct the query q T unsat using the method described in Section 2. Next, in lines 3-4, the algorithm considers in turn each CQ ∃ y ψ( y) that is a disjunct of q T unsat and computes the set of answers to ψ over I A . Observe that we use the non-Boolean query ψ( y) (which treats y as free variables) in order to obtain all images of ∃ y ψ( y), rather than merely checking for the existence of an image. For each answer a to ψ( y), we substitute a for the variables y and add to Images the set of atoms in ψ( a). At this point, Images contains all of the images of q T unsat in A. Finally, the elements of Images are compared, and the non-minimal images are removed in order to keep only the conflicts (lines 6 to 9).</p><p>We point out that ComputeConflicts can be applied to any DL that admits UCQrewritings of unsatisfiability. The complexity depends of course on the chosen DL. For DL-Lite R , we have seen in Section 2 that the disjuncts of q T unsat all contain at most two atoms, so it is possible to construct and evaluate q T unsat in polynomial time, which gives us:</p><p>Proposition 4.3. ComputeConflicts runs in polynomial time in |A| on input T , A .</p><p>The fact that every conflict of a DL-Lite R KB has at most two assertions enables a natural representation of conflicts in terms of a conflict graph 5 : 4. The notion of a minimal inconsistent set has been considered in numerous works in knowledge representation and reasoning, and in particular, in the works by <ref type="bibr" target="#b51">Lembo et al. (2015)</ref> and by <ref type="bibr" target="#b21">Bienvenu and Rosati (2013)</ref>. We introduce the term 'conflict' to be able to more easily refer to such sets. 5. The notion of conflict graph is inspired by the conflict hypergraphs from the work by <ref type="bibr">Chomicki, Marcinkowski, and</ref><ref type="bibr">Staworko (2004a, 2004b)</ref> ALGORITHM 1: ComputeConflicts Input: a TBox T , an ABox A Output: the set of conflicts of T , A Definition 4.4 (Conflict graph). The conflict graph for a DL-Lite R KB T , A is a graph whose vertices are the assertions in A and which contains an edge from α to β iff {α, β} is a conflict (note that there is an edge from α to itself iff {α} is a conflict).</p><formula xml:id="formula_13">1 Images ← ∅; 2 q T unsat ← BuildUnsatQuery(T ) ; 3 foreach ∃ y ψ( y) ∈ q T unsat do /*</formula><p>Example 10. The conflict graph for K * is displayed below. We will utilize this notion of conflict graph in Section 6 when discussing our implementation of algorithms for inconsistency-tolerant querying.</p><p>For logics like DL-Lite R that admit only unary or binary conflicts, it makes sense to speak of the assertions that enter into a conflict with a given assertion (or set of assertions): Definition 4.5 (Conflicts of a set of assertions). Let K = T , A be a DL-Lite R KB and B ⊆ A. The set of conflicts of B, denoted confl(B, K), is:</p><formula xml:id="formula_14">confl(B, K) = {β | ∃α ∈ B, {α, β} ∈ conflicts(K)} ∪ {α | α ∈ B, {α} ∈ conflicts(K)}.</formula><p>Example 11. We have confl({AProf(ann)}, K * ) = {FProf(ann), Postdoc(ann)}.</p><p>Observe that in the graphical view of conflicts, the set confl(B, K) contains all assertions that are adjacent to an assertion from B. To compute the set confl(B, K) for a set of assertions B ⊆ A, it suffices to examine the conflicts produced by ComputeConflicts, and output all assertions α such that there exists a conflict {α, β} with β ∈ B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Since an inconsistent KB has no model, every tuple of individuals of the same arity as</head><p>x is an answer to the query q( x). However, only some of these answers actually have some consistent reasons to hold, which are captured by the notion of causes.</p><p>ALGORITHM 2: ComputeCauses Input: a conjunctive query q( x), a candidate answer a, a KB K = T , A Output: the set of causes for q( a) in K </p><formula xml:id="formula_15">1 Conflicts ← ComputeConflicts(T , A); 2 Q ← UCQRef(q( a), T ); 3 Images ← ∅; 4 foreach ∃ yψ( y) ∈ Q do /*</formula><formula xml:id="formula_16">if C ∩ confl(C, K) = ∅ then /* C is T -inconsistent */ 9 Images ← Images \ {C}; foreach C ∈ Images do if C ⊆ C then /* C is non-minimal */ Images ← Images \ {C};</formula><p>Output Images; Definition 4.6 (Cause). A cause 6 for a Boolean query q in a KB K = T , A is an inclusion minimal T -consistent subset C ⊆ A such that T , C |= q. We use causes(q, K) to refer to the set of causes for q in K.</p><p>Note that the definition refers to Boolean queries, but we can derive a notion of cause for answers to non-Boolean queries in the obvious way: if q( x) is a non-Boolean query with candidate answer a, then we can commit a slight abuse of terminology and speak of the causes for a being an answer to q( x) when referring to the elements of causes(q( a), K).</p><p>Example 12. There are twelve causes for q 2 (ann) = ∃y PhD(ann) ∧ Teaches(ann, y): {Postdoc(ann), Teach(ann, c i )} {Advise(ann, bob), Teach(ann, c i )} {AProf(ann), Teach(ann, c i )} {FProf(ann), Teach(ann, c i )} for i ∈ {1, 2, 3}.</p><p>The following proposition relates the causes of a query to the images of a UCQ-rewriting of the query.</p><p>Proposition 4.7. Consider a TBox T , a Boolean CQ q, and a UCQ-rewriting q of q w.r.t. T and consistent ABoxes. Then C ⊆ A is a cause for q in T , A iff C is an inclusionminimal T -consistent image of q in A.</p><p>By the preceding proposition, the causes for an answer a to query q( x) in a KB T , A correspond to the images of the CQs in a UCQ-rewriting of q( a) in A that are T -consistent and do not contain any other such image. Based upon this idea, we present in Algorithm 2 a simple procedure ComputeCauses that produces the causes of a tuple a being an answer to a query q over a DL-Lite R KB. It first computes the conflicts of the KB (line 1), to be 6. Causes were referred to as minimal T -supports by <ref type="bibr" target="#b21">Bienvenu and Rosati (2013)</ref>.</p><p>used for checking consistency of the images. The query q( x) is then rewritten and evaluated over I A (using some existing UCQ-rewriting algorithm UCQRef) with all of its variables treated as free in order to construct the set of its images (lines 4 to 6). The inconsistent or non-minimal images are then discarded (lines 7 to 12). To check the consistency of an image C, the algorithm verifies that C has an empty intersection with the set confl(C, K) of assertions that conflict with it. If the set Conflicts computed in line 1 is stored in an appropriate data structure (e.g. as a conflict graph), then it is easy to read off the assertions in confl(C, K).</p><p>Observe that the size of each computed cause is bounded by the maximum number of atoms in a disjunct of the UCQ-rewriting. Since the rewriting is computed independently of the ABox, the number of potential causes is polynomial in the size of A. It follows that:</p><p>Proposition 4.8. ComputeCauses runs in polynomial time in |A| on input T , A , q, a.</p><p>The algorithm ComputeCauses computes the causes for a Boolean query or a single answer tuple a. However, by making some minor modifications to the procedure, we can compute causes for all answers to a non-Boolean query q( x) = ∃ y ϕ( x, y) at the same time.</p><p>In line 5, we compute answers to the considered disjunct ψ( x, y) of the UCQ-rewriting of q( x), with variables in both x and y treated as free. Just after line 6, we insert an additional step where we partition the images so that each group of images assigns the same tuple a to the variables x (these are the possible causes for q( a)). Finally, for every such tuple a, we perform lines 7-12 to remove all inconsistent or non-minimal images, thereby obtaining the causes for q( a).</p><p>The preceding algorithms for computing conflicts and causes have the advantage of allowing us to directly use existing UCQ-rewriting methods. Alternatively, we could adopt techniques by <ref type="bibr" target="#b50">Lembo et al. (2011</ref><ref type="bibr" target="#b51">Lembo et al. ( , 2015) )</ref> and <ref type="bibr" target="#b21">Bienvenu and Rosati (2013)</ref> that modify the UCQ-rewriting in order to incorporate the minimality checks directly into the rewriting. This approach yields a better theoretical complexity (AC 0 ), but the modified rewritings can be larger and more complex, leading to increased evaluation times <ref type="bibr" target="#b51">(Lembo et al., 2015)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Algorithms for Query Answering under Inconsistency-Tolerant Semantics</head><p>We first explain how we can compute the answers that hold under brave and IAR semantics using the procedures ComputeConflicts (Algorithm 1) and ComputeCauses (Algorithm 2) from the preceding subsection, and afterwards we propose a SAT-based approach to handle the AR semantics.</p><p>Brave Semantics A Boolean query is entailed under brave semantics just in the case that it is supported by some internally consistent set of facts, i.e. has at least one cause in the KB. Therefore, to decide if a query is entailed under brave semantics, we simply need to compute its causes with ComputeCauses and verify that the output is not empty. For non-Boolean queries, we can use the modified version of ComputeCauses to compute all brave-answers of a non-Boolean query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IAR Semantics</head><p>The next proposition<ref type="foot" target="#foot_1">7</ref> provides a characterization of the IAR semantics in terms of causes and conflicts: Proposition 4.9. The following are equivalent: (a) K |= IAR q, (b) there exists C ∈ causes(q, K) such that C ⊆ R∈Rep(K) R, and (c) there exists C ∈ causes(q, K) such that confl(C, K) = ∅.</p><p>Proof. To prove (a) implies (b), suppose that K |= IAR q. Then T , R∈Rep(K) R |= q and R∈Rep(K) R is T -consistent, so there is some C ⊆ R∈Rep(K) R that belongs to causes(q, K).</p><p>To show (b) implies (c), take some C ∈ causes(q, K) such that C ⊆ R∈Rep(K) R, and suppose for a contradiction that α ∈ C ∩ D for some D ∈ conflicts(K). By the minimality of conflicts, D \ {α} is T -consistent, and thus can be extended to a repair R α that omits α, contradicting our earlier assumption.</p><p>For the implication from (c) to (a), suppose that there exists C ∈ causes(q, K) such that confl(C, K) = ∅. Then T , C |= q and C ⊆ R∈Rep(K) R, since repairs are maximally consistent and assertions in C are not involved in any conflicts. We thus obtain T , R∈Rep(K) R |= q, i.e. K |= IAR q.</p><p>By the preceding proposition, a query is entailed under IAR semantics iff there is a cause for the query whose assertions do not participate in any conflict. Therefore, deciding if a query is entailed under IAR semantics can be done by computing its causes with ComputeCauses and the conflicts of the KB with ComputeConflicts, and then checking whether there is a cause without conflicts. For non-Boolean queries, we can again employ the modified version of ComputeCauses to compute all causes of all answers, and then isolate those answers that possess a conflict-free cause to identify the IAR-answers.</p><p>AR Semantics For the coNP-complete problem of deciding if a query is entailed under AR semantics, we propose an encoding in terms of propositional unsatisfiability, based upon the following characterization of AR semantics in terms of causes and conflicts: Proposition 4.10. K |= AR q iff there exists a T -consistent subset S ⊆ A such that for every C ∈ causes(q, K), there is some α ∈ S ∩ confl(C, K).</p><p>Proof. First suppose that K |= AR q. By definition, there is some R ∈ Rep(K) such that T , R |= q. Then R is T -consistent and since it does not entail q, it cannot contain any C ∈ causes(q, K). It follows from the maximality of repairs that for every cause C, the set R ∪ C is T -inconsistent, and so R must contain an assertion in conflict with C since C is T -consistent by definition.</p><p>Conversely, suppose S ⊆ A is T -consistent and contains, for every C ∈ causes(q, K), some assertion α C ∈ confl(C, K). Then there exists a repair R that extends S and does not contain any C ∈ causes(q, K) (since it is consistent and contains α C ∈ confl(C, K)). It follows that T , R |= q, which yields K |= AR q.</p><p>Figure 2 presents the two formulas that are used in our encoding, where variables represent assertions of the ABox. Intuitively, the assertions that correspond to the variables</p><formula xml:id="formula_17">ϕ ¬q = C∈causes(q,K) β∈confl(C,K) x β ϕ cons = xα,x β ∈vars(ϕ¬q) β∈confl({α},K) ¬x α ∨ ¬x β</formula><p>where vars(ϕ ¬q ) is the set of variables appearing in ϕ ¬q .</p><p>Figure <ref type="figure">2</ref>: SAT encoding ϕ ¬q ∧ ϕ cons for AR query answering.</p><p>assigned to true in a truth assignment that satisfies ϕ ¬q ∧ ϕ cons form a consistent subset of the ABox that contains at least one assertion of the conflicts of each cause of the query. By Proposition 4.10, such a subset exists just in the case that K |= AR q.</p><p>Theorem 4.11. Let K be a DL-Lite R KB and q be a Boolean conjunctive query. K |= AR q if and only if ϕ ¬q ∧ ϕ cons is satisfiable, where ϕ ¬q and ϕ cons are defined in Figure <ref type="figure">2</ref>.</p><p>Proof. Let ν be a truth assignment of the variables of ϕ ¬q ∧ ϕ cons and</p><formula xml:id="formula_18">R ν = {β | ν(x β ) = true}.</formula><p>The formula ϕ ¬q evaluates to true in ν if and only if for every cause C of q, there exists an assertion β which is in conflict with some assertion of C and such that ν(x β ) = true, so is in R ν . The formula ϕ cons evaluates to true in ν if and only if there is no α, β which are in a conflict and such that ν(x α ) = true and ν(x β ) = true, so if and only if R ν does not contain any conflict of K, i.e. is T -consistent. Hence ϕ ¬q ∧ ϕ cons evaluates to true in ν if and only if R ν is a consistent subset of A that contradicts each cause for q. We conclude by Proposition 4.10 that ϕ ¬q ∧ ϕ cons is satisfiable if and only if K |= AR q.</p><p>The following example illustrates the encoding.</p><p>Example 13. For the Boolean query PhD(ann), which has four causes, {AProf(ann)}, {FProf(ann)}, {Advise(ann, bob)} and {Postdoc(ann)}, we have:</p><formula xml:id="formula_19">confl({AProf(ann)}, K) ={FProf(ann), Postdoc(ann)} confl({FProf(ann)}, K) ={AProf(ann), Postdoc(ann)} confl({Advise(ann, bob)}, K) ={Postdoc(ann)} confl({Postdoc(ann)}, K) ={AProf(ann), FProf(ann), Advise(ann, bob)}</formula><p>so the encoding is as follows:</p><formula xml:id="formula_20">ϕ ¬q =(x FProf(a) ∨ x Postdoc(a) ) ∧ (x AProf(a) ∨ x Postdoc(a) ) ∧ x Postdoc(a) ∧ (x AProf(a) ∨ x FProf(a) ∨ x Advise(a,b) ) ϕ cons =(¬x FProf(a) ∨ ¬x Postdoc(a) ) ∧ (¬x AProf(a) ∨ ¬x Postdoc(a) ) ∧ (¬x Advise(a,b) ∨ ¬x Postdoc(a) )∧ (¬x AProf(a) ∨ ¬x FProf(a) )</formula><p>Since x Postdoc(a) cannot be assigned to true together with x AProf(a) , x FProf(a) , or x Advise(a,b) , the formula ϕ ¬q ∧ ϕ cons is unsatisfiable, so T , A |= AR PhD(ann).</p><p>If we consider instead the query Prof(ann), we obtain the following encoding:</p><formula xml:id="formula_21">ϕ ¬q =(x FProf(a) ∨ x Postdoc(a) ) ∧ (x AProf(a) ∨ x Postdoc(a) ) ∧ x Postdoc(a) ϕ cons =(¬x FProf(a) ∨ ¬x Postdoc(a) ) ∧ (¬x AProf(a) ∨ ¬x Postdoc(a) ) ∧ (¬x AProf(a) ∨ ¬x FProf(a) )</formula><p>A valuation that assigns x Postdoc(a) to true and x AProf(a) and x FProf(a) to false satisfies ϕ ¬q ∧ ϕ cons , so T , A |= AR Prof(ann).</p><p>The interest of the proposed encoding is that it only has as many variables as the number of assertions which are in a conflict with a cause of the query, whereas a naïve encoding that determines a complete repair would need one variable per ABox assertion. Thus, in practice, the size of our encoding may be substantially smaller than the size of the ABox.</p><p>By Theorem 4.11, to decide whether K |= AR q, it suffices to construct the propositional encoding and pass it on to a SAT solver. However, by exploiting the brave and IAR semantics, it is sometimes possible to determine whether a query holds under AR semantics without utilizing the encoding. Indeed, by Proposition 3.9, K |= brave q implies K |= AR q and K |= IAR q implies K |= AR q. Thus, even if one were only interested in the AR semantics, it is advantageous to employ the brave and IAR semantics as tractable upper and lower approximations.</p><p>Putting everything together, we propose the algorithm ClassifyQuery (Algorithm 3) that determines the strongest semantics (among IAR, AR, brave) under which a Boolean query holds (see next paragraph for discussion of the non-Boolean case). As a first step, ClassifyQuery computes and stores the KB's conflicts (line 1) and uses them to identify the set ConflAssertions of assertions that belong to some conflict (line 2). It next generates the causes of q w.r.t. the KB (line 3). If the set of causes is empty, then the query is not entailed under brave semantics, so 'not brave' is output (lines 4-5). Otherwise, each cause is considered in turn (lines 7-12). If a cause has an empty intersection with ConflAssertions, then it is entailed under IAR semantics, so we immediately return 'IAR'; else we construct the set of conflicts for that cause and add it to CausesConfl . In line 13, we generate the encoding from Figure <ref type="figure">2</ref>, using the sets of assertions in CausesConfl to produce the clauses in ϕ ¬q and the sets of assertions in Conflicts to construct the clauses in ϕ cons . If the encoding is unsatisfiable (as determined by a SAT solver), then by Theorem 2, the query is entailed under AR semantics, so we output 'AR' (line 14). Otherwise, we output 'brave' (line 16), as we have determined the query to be brave (as it has at least one cause) but not to hold under AR semantics. It should be clear that the output of the algorithm indeed corresponds to the strongest semantics under which the query q is entailed.</p><p>For a non-Boolean query, the algorithm ClassifyQuery can be slightly modified to classify all tuples that hold under at least one of the semantics. First, we use the non-Boolean version of ComputeCauses to generate the causes for all assignments a to the answer variables x that admit at least one cause. Note that every such tuple a is a brave-answer, and it remains to test whether it holds under IAR or AR semantics. We skip over lines 4-5 as we do not wish to list all tuples that are not brave-answers. Instead, we iterate over all brave-answers a, and for every such tuple, we perform the operations in lines 7-16, using the computed set of causes for a. The only other minor modification is that instead of outputting 'IAR' / 'AR', or 'brave', we add tuples to one of the sets IAR, AR, or brave, which are returned at the end of the execution. We point out that for non-Boolean queries, the number of tuples that need to be classified can be huge, and thus it is all the more essential to use the brave and IAR semantics to reduce the total number of calls that need to be made to the SAT solver.</p><p>ALGORITHM 3: ClassifyQuery Input: a conjunctive query q( x), a candidate answer a, a KB K = T , A Output: IAR if T , A |= IAR q( a), AR if T , A |= AR q( a) and T , A |= IAR q( a), brave if T , A |= brave q( a) and T , A |= AR q( a), and not brave otherwise</p><formula xml:id="formula_22">1 Conflicts ← ComputeConflicts(T , A); 2 ConflAssertions ← B∈Conflicts B; 3 Causes ← ComputeCauses(q( a), T , A); 4 if Causes = ∅ then 5 Output not brave 6 CausesConfl ← ∅; 7 foreach C ∈ Causes do 8 if C ∩ ConflAssertions = ∅ then 9 Output IAR else CausesConfl ← CausesConfl ∪ {ConflictsFor(C, K)} ϕ ← ConstructEncoding(CausesConfl , Conflicts); if Unsat(ϕ) then /* call to a SAT solver */</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Output AR else</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Output brave</head><p>We close this section with a remark on how our SAT-based approach can be extended to handle variants of DL-Lite allowing for n-ary conflicts, such as the language DL-Lite A,id,den considered by <ref type="bibr" target="#b51">Lembo et al. (2015)</ref>.</p><p>Remark 4.12. If we allow in the TBox denial constraints specified using either inclusions of the form B 1 ... B n ⊥ or Boolean CQs (which describe situations which should not hold), then conflicts may contain more than two assertions. When conflicts are not binary, we cannot define the conflicts of a cause as a set of assertions, as it may be necessary to use several assertions to contradict a cause. The encoding can be adapted to take into account n-ary conflicts as follows: K |= AR q iff ϕ 1 ¬q ∧ ϕ 2 ¬q ∧ ϕ cons is satisfiable, where:</p><formula xml:id="formula_23">ϕ 1 ¬q = C∈causes(q,K) B∈conflicts(K),C∩B =∅ x C,B ϕ 2 ¬q = x C,B ∈vars(ϕ 1 ¬q ) β∈B\C ¬x C,B ∨ x β ϕ cons = xα∈vars(ϕ 2 ¬q ) B∈conflicts(K),α∈B β∈B ¬x β</formula><p>The new variables x C,B represent the different ways of contradicting C, and ϕ 1 ¬q expresses that every cause is contradicted. The formula ϕ 2 ¬q ensures that when x C,B is assigned to true, which means that C is contradicted with the conflict B, every assertion of B which does not belong to C is selected, so that adding B \ C creates a conflict. As in the original encoding, ϕ cons enforces consistency of the subset consisting of the assertions whose corresponding variables are assigned to true by preventing all assertions of a conflict to be selected together.</p><p>For example, consider the TBox T = {Postdoc PhD, Prof PhD, Postdoc ¬Prof} extended with the constraint that ∃xy Postdoc(x) ∧ Advise(x, y) ∧ PhD(y) should not hold and the ABox A = {Postdoc(ann), Prof(ann), Postdoc(bob), Advise(ann, bob)}. The resulting KB is inconsistent and has two conflicts B 1 = {Postdoc(ann), Prof(ann)} and B 2 = {Postdoc(ann), Postdoc(bob), Advise(ann, bob)}. The Boolean query PhD(ann) has two causes C 1 = {Postdoc(ann)} and C 2 = {Prof(ann)} and the encoding is as follows:</p><formula xml:id="formula_24">ϕ 1 ¬q =(x C 1 ,B 1 ∨ x C 1 ,B 2 ) ∧ x C 2 ,B 1 ϕ 2 ¬q =(¬x C 1 ,B 1 ∨x Prof(a) )∧(¬x C 1 ,B 2 ∨x Postdoc(b) )∧(¬x C 1 ,B 2 ∨x Advise(a,b) )∧(¬x C 2 ,B 1 ∨x Postdoc(a) ) ϕ cons =(¬x Postdoc(a) ∨ ¬x Prof(a) ) ∧ (¬x Postdoc(a) ∨ ¬x Postdoc(b) ∨ ¬x Advise(a,b) )</formula><p>The formula ϕ 1 ¬q ∧ ϕ 2 ¬q ∧ ϕ cons is unsatisfiable, so T , A |= AR PhD(ann).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Explaining Inconsistency-Tolerant Query Answering</head><p>In the preceding section, we proposed to use conjointly the brave, AR and IAR semantics to identify answers of different levels of confidence. We now turn our attention to the problem of explaining the obtained query results. Our goal is to improve the usability of inconsistency-tolerant querying systems by helping the user understand the classification of a particular tuple, e.g. why is a an AR-answer, and why is it not an IAR-answer? To this end, we introduce notions of explanation for positive and negative query answers under brave, AR, and IAR semantics, and we investigate the computational properties of the resulting explanation framework.</p><p>A proof-theoretic approach to explaining positive answers to CQs over consistent DL-Lite A KBs was introduced by <ref type="bibr" target="#b22">Borgida et al. (2008)</ref>. It outputs a single proof, involving both TBox axioms and ABox assertions, that is generated by 'tracing back' the relevant part of the rewritten query, using minimality criteria to select a 'simplest' proof. For negative answers, explanations for why a tuple is not an answer to a CQ are defined by <ref type="bibr" target="#b29">Calvanese et al. (2013)</ref> as sets of ABox assertions that can be added to the ABox to make the tuple become an answer. Practical algorithms and an implementation for computing such explanations were described by <ref type="bibr" target="#b37">Du et al. (2014)</ref>. The latter work was recently extended to the case of inconsistent KBs <ref type="bibr" target="#b38">(Du et al., 2015)</ref>: essentially the idea is to add a set of ABox assertions that will lead to the answer holding under IAR semantics (in particular, the new assertions must not introduce any inconsistencies).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Explanations for Query (Non-)Answers</head><p>Existing frameworks for explaining (non-)answers to queries over DL KBs are ill adapted to the setting of inconsistency-tolerant query answering. Indeed, it is no longer enough to prove that positive answers are entailed by some part of the ABox together with the TBox (as done by <ref type="bibr" target="#b22">Borgida et al., 2008)</ref> to establish that they hold in every repair, as required by AR semantics. Moreover, negative answers do not result from the absence of supporting facts anymore (like in the works by <ref type="bibr" target="#b29">Calvanese et al., 2013;</ref><ref type="bibr" target="#b37">Du et al., 2014)</ref>, but rather from the presence of conflicting assertions.</p><p>As explained in the introduction, this paper targets scenarios in which inconsistencies are due to errors in the ABox, and so understanding the link between (possibly faulty) ABox assertions and query results is especially important. For this reason, we choose to focus on ABox assertions, rather than TBox axioms. The explanations we consider will therefore take either the form of a set of ABox assertions (viewed as a conjunction) or a set of sets of assertions (interpreted as a disjunction of conjunctions). We shall see that our 'ABox-centric' explanation framework already poses non-trivial computational challenges. To get more detailed explanations, which also take into account the TBox reasoning that led to the results, our approach could be combined with that of <ref type="bibr" target="#b22">Borgida et al. (2008)</ref>.</p><p>We start by considering what are arguably the simplest answers to explain: positive brave-and IAR-answers. Indeed, we have seen that an answer holds under brave semantics just in the case that it possesses some cause, and under IAR semantics just in the case that it has some cause whose assertions do not belong to any conflict. It is therefore natural to use the query's causes as explanations for brave-answers, and the causes that do not participate in any contradiction for IAR-answers.</p><p>Definition 5.1 (Explanations for positive brave-answers). A subset C ⊆ A is an explanation for K |= brave q( a) iff C ∈ causes(q( a), K).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 5.2 (Explanations for positive IAR-answers). A subset</head><formula xml:id="formula_25">C ⊆ A is an explanation for K |= IAR q( a) iff C ∈ causes(q( a), K) and C ⊆ R for every repair R of K (equivalently: confl(C, K) = ∅).</formula><p>Example 14. There are three causes for q 1 (ann) = Prof(ann):</p><formula xml:id="formula_26">{AProf(ann)} {FProf(ann)} {Advise(ann, bob)}</formula><p>and these give us the explanations for K |= brave q 1 (ann) = Prof(ann). Observe that each cause is in conflict with an assertion in A * , so there are no explanations for K |= IAR q 1 (ann).</p><p>If we consider instead q 3 (ann) = ∃y Teach(ann, y), then again we have three causes:</p><formula xml:id="formula_27">{Teach(ann, c 1 )} {Teach(ann, c 2 )} {Teach(ann, c 3 )}</formula><p>However, each of these causes is without conflict, so they are both explanations for K |= brave q 3 (ann) and explanations for K |= IAR q 3 (ann).</p><p>To explain why a tuple is an AR-answer, it is no longer sufficient to give a single cause, since the answer may be supported by different causes in different repairs. We will therefore define explanations as (minimal) disjunctions of causes that 'cover' all repairs.</p><p>Definition 5.3 (Explanations for AR-answers). An explanation for</p><formula xml:id="formula_28">K |= AR q( a) is a set E = {C 1 , . . . , C m } ⊆ causes(q( a), K) such that (i) every repair R of K contains some C i ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>and (ii) no proper subset of E satisfies this property.</head><p>Example 15. There are 36 explanations for K |= AR ∃y PhD(ann) ∧ Teach(ann, y), each taking one of the following two forms:</p><formula xml:id="formula_29">E ij =(Postdoc(ann) ∧ Teach(ann, c i )) ∨ (Advise(ann, bob) ∧ Teach(ann, c j )) E ijk =(Postdoc(ann) ∧ Teach(ann, c i )) ∨ (AProf(ann) ∧ Teach(ann, c j )) ∨ (FProf(ann) ∧ Teach(ann, c k ))</formula><p>for some i, j, k ∈ {1, 2, 3}. Indeed, for repair R 1 , we must choose a cause of the form Postdoc(ann) ∧ Teach(ann, c i ), and to cover the repairs R 2 and R 3 , we may either include a cause of the form Advise(ann, bob) ∧ Teach(ann, c j ) or a pair of causes of the forms AProf(ann) ∧ Teach(ann, c j ) (for R 2 ) and FProf(ann) ∧ Teach(ann, c k ) (for R 3 ).</p><p>We remark that when restricted to consistent KBs, all three notions of explanation for positive answers coincide with the inclusion-minimal subsets of the ABox that, when combined with the TBox, yield the query answer. Such a notion of explanation, defined as a minimal subset that permits the derivation of a target consequence, is broadly similar to the notion of justifications widely used for explaining TBox reasoning (see Section 8 for more discussion of justifications and references).</p><p>We next turn to the problem of explaining why a tuple that is returned as a braveanswer does not hold under one of the stronger semantics (for non-brave answers, one can adapt existing work on query abduction, see Section 8.3.3). Brave-answers that do not hold under AR (resp. IAR) semantics will be called negative AR-answers (resp. IAR-answers).</p><p>To explain negative AR-answers, a first idea might be to provide a repair in which the query answer does not hold, but this could yield very large explanations with lots of irrelevant assertions. Instead, we propose to give a minimal subset of the ABox that is consistent with the TBox and contradicts every cause of the query, since any such subset can be extended to a repair that omits all causes. For IAR semantics, the formulation is slightly different as we only need to ensure that every cause is contradicted by some consistent subset of the ABox, as this shows that no cause belongs to all repairs.</p><p>Definition 5.4 (Explanations for negative AR-answers). An explanation for K |= AR q( a) is a T -consistent subset E ⊆ A such that: (i) T , E ∪ C |= ⊥ for every C ∈ causes(q( a), K), (ii) no proper subset of E has this property.</p><p>Example 16. The unique explanation for K |= AR Prof(ann) is {Postdoc(ann)}, which contradicts the three causes of q 1 (ann) = Prof(ann).</p><p>Definition 5.5 (Explanations for negative IAR-answers). An explanation for K |= IAR q( a) is a (possibly T -inconsistent) subset E ⊆ A such that: (i) for every C ∈ causes(q( a), K), there exists a T -consistent subset E ⊆ E with T , E ∪ C |= ⊥, (ii) no proper subset of E has this property.</p><p>We remark that for DL-Lite R and other DLs admitting only binary conflicts, point (i) of the preceding definition can be simplified, as the set E can be assumed to be a singleton.</p><p>Example 17. Reconsider the query q 2 (x) = ∃yPhD(x) ∧ Teach(x, y). There are 3 explanations for K |= IAR q 2 (ann): {AProf(ann), Postdoc(ann)}, {FProf(ann), Postdoc(ann)}, and {Advise(ann, bob), Postdoc(ann)}, where the first assertion of each explanation contradicts the causes of ∃y PhD(x) ∧ Teach(ann, y) that contain Postdoc(ann), and the second one contradicts those that contain AProf(ann), FProf(ann) or Advise(ann, bob).</p><p>The following example illustrates that explanations are more informative than causes and conflicts, since some causes and conflicts may not be involved in the explanations of an answer. It also shows that explanations for negative answers should be accompanied with the explanations for being a brave-answer (i.e. the causes), because otherwise they may be difficult to understand. If we evaluate the query q(x, y) = Employee(x) ∧ Teach(x, y) using AR semantics, we find that K |= AR q(ann, c 1 ). There are four causes of q(ann, c 1 ) in K: {Postdoc(ann), Teach(ann, c 1 )} {Advise(ann, bob), Teach(ann, c 1 )} {Advise(ann, carl), Teach(ann, c 1 )} {WorkFor(ann, dpt), Teach(ann, c 1 )} but only one explanation for K |= AR q(ann, c 1 ): {{Postdoc(ann), Teach(ann, c 1 )}, {Advise(ann, bob), Teach(ann, c 1 )}}</p><p>To see why the cause {Advise(ann, carl), Teach(ann, c 1 )} does not participate in any explanation, observe that if R is a repair that contains {Advise(ann, carl), Teach(ann, c 1 )}, then R = (R\{Advise(ann, carl)}) ∪ {TakeCourse(c 2 , carl)} is also a repair. As every explanation contains some cause C included in R , and TakeCourse(c 2 , carl) does not belong to any cause, it follows that C ⊆ R, so {Advise(ann, carl), Teach(ann, c 1 )} is not needed to 'cover' R. For a similar reason, the cause {WorkFor(ann, dpt), Teach(ann, c 1 )} does not belong to any explanation K |= AR q(ann, c 1 ).</p><p>From the fact that we need two causes to cover the repairs, we can derive that q(ann, c 1 ) does not hold under IAR semantics. There are two explanations for K |= IAR q(ann, c 1 ): {WorkFor(dpt, dan), Postdoc(ann), Advise(ann, bob)} {WorkFor(dpt, dan), Postdoc(ann), Advise(ann, carl)} Note that TakeCourse(c 2 , carl) is not involved in the explanations of K |= IAR q(ann, c 1 ), even though it conflicts with the cause {Advise(ann, carl), Teach(ann, c 1 )}. This is because Postdoc(ann) is also a conflict of this cause and is the only assertion that contradicts the other cause {Advise(ann, bob), Teach(ann, c 1 )}. It follows that each set of assertions that contradicts every cause must contain Postdoc(ann), and TakeCourse(c 2 , carl) is not needed (so will not appear in any minimal such set).</p><p>If a user receives the explanations for K |= IAR q(ann, c 1 ) without the causes of q(ann, c 1 ), it can be very hard for him to figure out why WorkFor(dpt, dan) is relevant. Indeed, there is no obvious relation between this assertion and the answer (ann, c 1 ), since WorkFor(dpt, dan) does not involve any of the individuals of the answer. Even if the explanations for K |= AR q(ann, c 1 ) are provided, it would not help because neither dpt nor dan appears in them. To understand why WorkFor(dpt, dan) is part of an explanation for K |= IAR q(ann, c 1 ), the user needs to be aware of the cause {WorkFor(ann, dpt), Teach(ann, c 1 )}. A solution would be to accompany an explanation for a negative IAR-answer with (one or more) causes that are conflicted by the assertions in that explanation, or alternatively to allow users to ask why a given assertion α appears in an explanation (in which case, cause(s) conflicted by α could be displayed).</p><p>When there are a large number of explanations for a given answer, it may be impractical to present them all to the user. In such cases, instead of presenting all explanations, one may choose to rank the explanations according to some preference criteria, and to present one or a small number of most preferred explanations. In this work, we will use cardinality to rank explanations for brave-and IAR-answers and negative AR-and IAR-answers. For positive AR-answers, we consider two ranking criteria: the number of disjuncts, and the total number of assertions. Another interesting criterion would be the difficulty of the associated TBox reasoning. For example, we may compute for each cause the minimum number of TBox axioms needed to show that the cause yields the query, and then use this number to rank explanations for brave-and IAR-answers.</p><p>Example 19. Reconsider explanations E 1 1 and E 1 2 3 for K |= AR q 2 (ann) from Example 15. There are at least two reasons why E 1 1 may be considered easier to understand than E 1 2 3 . First, E 1 1 contains fewer disjuncts, hence requires less disjunctive reasoning. Second, both disjuncts of E 1 1 use the same Teach assertion, whereas E 1 2 3 uses three different Teach assertions, which may lead the user to (wrongly) believe all are needed to obtain the query result. Preferring explanations having the fewest number of disjuncts, and among them, those involving a minimal set of assertions, leads to focusing on the explanations of the form E i i , where i ∈ {1, 2, 3}.</p><p>A second complementary approach to dealing with a large number of explanations is to concisely summarize the set of explanations in terms of the necessary assertions (i.e. appearing in every explanation) and the relevant assertions (i.e. appearing in at least one explanation). The advantage of this approach is to present the whole information to the user without overwhelming him with all explanations. This is especially relevant in the case of positive AR and negative answers, where the number of explanations may be exponential in the size of the ABox because of the combination of the different causes for AR-answers, and ways of contradicting each cause for negative answers. Indeed, the set of conflicts of brave, IAR AR neg. AR neg. IAR each cause can be as large as the ABox. Even for positive IAR or brave-answers, the number of explanations can be very large (imagine for instance a query that retrieves the persons who teach something, advise some students and have some publications).</p><formula xml:id="formula_30">genOne in PTime NP-h NP-h in PTime genBest † in PTime Σ p 2 -h ‡ NP-h NP-h * rel in AC 0 Σ p 2 -co NP-co in AC 0 nec in AC 0 NP-co coNP-co in AC 0 rec in AC 0 BH 2 -co in AC 0 in AC 0 best rec † in PTime Π p 2 -co ‡ coNP-co * coNP-co</formula><p>Example 20. If we tweak the example KB to include n courses taught by ann, then there would be n 2 + n 3 explanations of the form E i j and E i j k for K |= AR ∃yPhD(ann) ∧ Teach(ann, y), built using only n + 4 assertions. Presenting the necessary assertions (here: Postdoc(ann)) and the relevant assertions (AProf(ann), FProf(ann), Advise(ann, bob), and Teach(ann, c j ) for 1 ≤ j ≤ n) gives a succinct overview of the set of explanations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Complexity Analysis and Algorithms</head><p>We study the computational properties of the different notions of explanation for DL-Lite R KBs. In addition to the problem of generating a single explanation (genOne), or a single best explanation (genBest) according to a given criteria, we consider four related decision problems: decide whether a given assertion appears in some explanation (rel) or in every explanation (nec), decide whether a candidate is an explanation (rec), resp. a best explanation according to a given criterion (best rec). The remainder of this section will be devoted to proving the following theorem and introducing the procedures that are implemented in the system described in the next section.</p><p>Theorem 5.6. The complexity results displayed in Table <ref type="table" target="#tab_2">1</ref> hold.</p><p>When showing that a decision problem is hard for a given complexity class, we use standard polynomial-time many-one reductions (also known as Karp reductions), which transform an instance of one decision problem into an instance of a second decision problem.</p><p>We consider that a procedure solves the generation task genOne (resp. genBest) if it outputs an explanation (resp. best explanation according to the chosen criterion) when</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Type of Explanation Propositional Equivalent</head><p>Positive AR-answers Minimal unsatisfiable subsets of ϕ ¬q w.r.t. ϕ cons Prop. 5.9</p><p>Negative AR-answers Minimal models of ϕ ¬q ∧ ϕ cons Prop. 5.14</p><p>Negative IAR-answers Minimal models of ϕ ¬q Prop. 5.19</p><p>Table <ref type="table">2</ref>: Connections between explanations and propositional satisfiability.</p><p>there is at least one explanation, and otherwise, it outputs no. To show that a generation task is hard for a class C, we reduce a C-hard decision problem to it. As we cannot use many-one reductions (which relate two decision problems), we will use polynomial-time Turing reductions, that is, we will show how to solve the C-hard decision problem using a polynomial-time Turing machine that can use the generation task as an oracle. Moreover, to prove stronger intractability results, we will only allow a single oracle call. Many of our upper bounds (and some lower bounds too) are obtained by establishing tight connections between explanations for query (non-)answers and different notions related to propositional satisfiability. These connections are summarized in Table <ref type="table">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Positive Brave and IAR-Answers</head><p>By Propositions 4.3 and 4.8, the conflicts for a DL-Lite R KB K = T , A and the causes of a query q can be computed in polynomial time w.r.t. data complexity. Since the explanations for positive brave-answers are the causes, and the explanations for positive IAR-answers are the causes that belong to every repair, i.e. those which do not contain any assertion involved in a conflict of K, it is possible to compute the entire set of explanations for positive brave and IAR-answers in polynomial time. This means that genOne is in PTime. For polynomial-time ranking criteria, both genBest and best rec are solvable in polynomial time since we can compare all of the explanations to identify the best ones. The sets of relevant and necessary assertions can be computed in polynomial time by taking the union and intersection of the explanations.</p><p>In the appendix, we show that the decision problems rec, rel, and nec are not just in PTime but in fact belong to the much lower AC 0 complexity class. The proof involves defining first-order queries that can be used to decide these problems.</p><p>Proposition 5.7. Regarding explanations for positive brave-and IAR-answers, rec, rel, and nec are in AC 0 w.r.t. data complexity.</p><p>The preceding result is primarily of theoretical interest, as computing the sets of relevant and necessary assertions via rewriting would require us to construct and evaluate a huge number of rather complex first-order queries (one per ABox assertion). For this reason, in our implementation, we adopt the polynomial-time procedures sketched above, as they allow us to easily obtain the relevant and necessary assertions from the causes and conflicts (which have already been computed as part of the preprocessing and querying phases).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Positive AR-Answers</head><p>We relate explanations of positive AR-answers to minimal unsatisfiable subsets of a set of propositional clauses.</p><p>Definition 5.8 (Minimal Unsatisfiable Subset). Given sets F and H of soft and hard clauses respectively, a subset M ⊆ F is a minimal unsatisfiable subset (MUS) of F w.r.t. H if (i) M ∪ H is unsatisfiable, and (ii) M ∪ H is satisfiable for every M M .</p><p>To explain K |= AR q( a), we exploit the encoding from Figure <ref type="figure">2</ref>. For the set F of soft clauses, we take the clauses</p><formula xml:id="formula_31">ϕ ¬q = {λ C | C ∈ causes(q( a), K)} with λ C = β∈confl(C,K)</formula><p>x β that aim to contradict every cause, and for the set H of hard clauses, we use the clauses</p><formula xml:id="formula_32">ϕ cons = {¬x α ∨ ¬x β | x α , x β ∈ vars(ϕ ¬q ), β ∈ confl({α}, K)} that enforce consistency. Proposition 5.9. A set E ⊆ causes(q( a), K) is an explanation for K |= AR q( a) iff the set of clauses {λ C | C ∈ E} is a MUS of ϕ ¬q w.r.t. ϕ cons .</formula><p>Proof. First suppose that E is an explanation of K |= AR q( a). By Definition 5.3, this means that every repair of K contains at least one cause C from E. It follows that it is not possible to select one conflicting assertion for each cause in E in a consistent way, i.e. {λ C | C ∈ E} ∪ ϕ cons is inconsistent. Moreover, the minimality condition ensures that for every proper subset E E, there is a repair R that does not contain any cause from E . We can use R to select a consistent set of assertions that conflict with every cause in</p><formula xml:id="formula_33">E , i.e. {λ C | C ∈ E } ∪ ϕ cons is satisfiable. Thus, {λ C | C ∈ E} is a MUS of ϕ ¬q w.r.t. ϕ cons . Conversely, suppose {λ C | C ∈ E} is a MUS of ϕ ¬q w.r.t. ϕ cons . Then {λ C | C ∈ E}∪ϕ cons is unsatisfiable, and every {λ C | C ∈ E } ∪ ϕ cons with E E is satisfiable. The fact that {λ C | C ∈ E} ∪ ϕ cons is</formula><p>unsatisfiable means that every repair must contain one of the causes in E. The satisfiability of {λ C | C ∈ E } ∪ ϕ cons for E E implies the existence of a repair that omits every cause in E . We have thus shown that E satisfies the conditions of Definition 5.3, so it is an explanation of K |= AR q( a). Proposition 5.9 directly yields a method of computing explanations for positive ARanswers: simply construct the encoding and call an algorithm for generating MUSes (as implemented e.g. by some SAT solvers). Moreover, by combining Proposition 5.9 and known complexity results for MUSes, we obtain the following upper bounds: Proposition 5.10. Regarding explanations for positive AR-answers, rec is in BH 2 , best rec is in Π p 2 , and rel is in Σ p 2 w.r.t. data complexity.</p><p>Proof. We recall the following complexity results for MUSes (see <ref type="bibr" target="#b52">Liberatore, 2005)</ref>:</p><formula xml:id="formula_34">• Deciding if a set of clauses is a MUS is BH 2 -complete. • Deciding if a clause belongs to some MUS is Σ p 2 -complete.</formula><p>When combined with Proposition 5.9, the first item yields membership in BH 2 of rec. For best rec, we show that an explanation is not a best one by guessing a better candidate and checking in BH 2 that it is an explanation. This yields a Σ p 2 procedure for the complement of best rec, hence membership in Π p 2 for best rec. For rel, we note that an assertion α is relevant for explaining K |= AR q( a) just in the case that there exists a cause C for q( a) w.r.t. K that contains α and appears in some explanation. By Proposition 5.9, the latter holds iff λ C belongs to some MUS of ϕ ¬q w.r.t. ϕ cons . By the second item above, deciding whether a particular clause λ C belongs to some MUS can be decided in Σ p 2 . To obtain a Σ p 2 decision procedure for rel, we simply add an initial non-deterministic guess of a cause C ∈ causes(q( a), K) that contains α.</p><p>We next show the NP upper bound for nec.</p><p>Proposition 5.11. Regarding explanations for positive AR-answers, nec is in NP w.r.t. data complexity.</p><p>Proof. We claim that α belongs to every explanation of K |= AR q( a) iff there exists a repair R such that every cause for q( a) included in R contains α. Indeed, if every repair R contains a cause C R with α / ∈ C R , then there would be a minimal disjunction of these C R which covers every repair and omits α. Conversely, if there exists such a repair R , then any minimal disjunction of causes that covers every repair must contain α.</p><p>It follows that α belongs to every explanation of K |= AR q( a) just in the case that either there are no explanations at all ( i.e. K |= AR q( a)) or there exists a repair R of K = T , A such that T , R \ {α} |= q( a). Both conditions can be tested in NP w.r.t. data complexity. Indeed, to decide whether the second condition holds, we simply guess a subset R ⊆ A and check (in PTime w.r.t. data complexity) that R is a repair and T , R \ {α} |= q( a).</p><p>The following proposition shows how the connection to MUSes can be exploited to obtain matching lower bounds.</p><p>Proposition 5.12. Regarding explanations for positive AR-answers, rec is BH 2 -hard, nec is NP-hard, rel is Σ p 2 -hard, and genOne is NP-hard w.r.t. data complexity. Moreover, if we rank explanations according to the number of causes or number of assertions, then best rec (resp. genBest) is Π p 2 -hard (resp. Σ p 2 -hard) w.r.t. data complexity. Proof. We show how the MUSes of a propositional clause set can be captured by explanations of positive AR-answers.</p><p>Let ϕ 0 = {C 1 , ..., C k } be a set of propositional clauses over {X 1 , ..., X n }, and consider the KB and query used in the reduction of the proof of coNP-hardness of AR entailment presented by <ref type="bibr" target="#b17">Bienvenu (2012)</ref>:</p><formula xml:id="formula_35">T 0 = {∃P -¬∃N -, ∃P ¬∃U -, ∃N ¬∃U -, ∃U A} A 0 = {P (c j , x i ) | X i ∈ C j } ∪ {N (c j , x i ) | ¬X i ∈ C j } ∪ {U (a, c j ) | 1 ≤ j ≤ k} q 0 (x) = A(x)</formula><p>The causes for q 0 (a) are given by the assertions U (a, c j ), which are in conflict with assertions of the form P (c j , x i ) or N (c j , x i ). It was shown that T 0 , A 0 |= AR A(a) iff ϕ 0 is unsatisfiable. To prove the proposition, we will require the following stronger claim: Claim. The following are equivalent:</p><p>1. the set of clauses {C j 1 , ..., C jp } is unsatisfiable 2. every repair of T 0 , A 0 contains some assertion from {U (a, c j 1 ), ..., U (a, c jp )} Proof of claim. It will be more convenient to show that the negations of the two statements are equivalent. First suppose that {C j 1 , ..., C jp } is satisfiable, as witnessed by the satisfying assignment ν. Define a repair R ν of T 0 , A 0 by including the assertion</p><formula xml:id="formula_36">P (c j , v i ) if ν(v i ) = true, including N (c j , v i ) if ν(v i ) = false,</formula><p>and then adding as many other assertions as needed to obtain a maximal T 0 -consistent subset. Since ν satisfies every clause in {C j 1 , ..., C jp }, it follows that for every index ∈ {j 1 , . . . , j p }, the clause C contains either a positive literal v such that ν(v ) = true or a negative literal ¬v such that ν(v ) = false. In the former case, R ν contains the assertion P (c , v ), and in the latter case, R ν contains N (c , v ). In both cases, there is an assertion in R ν that conflicts with U (a, c ), so the latter assertion cannot appear in R ν . We have thus shown that R ν does not contain any of the assertions in {U (a, c j 1 ), ..., U (a, c jp )}.</p><p>Next suppose that there exists a repair R of T 0 , A 0 that has an empty intersection with the set {U (a, c j 1 ), ..., U (a, c jp )}. By the maximality of R, it follows that for every ∈ {j 1 , . . . , j p }, there must exist an assertion in R of the form P (c , v i ) or N (c , v i ). Define a (possibly partial) assignment ν R by setting X i to true if R contains some P (c j , x i ) and to false if R contains some N (c j , x i ) (recall that R is consistent with T 0 , and so it cannot contain both P (c j , x i ) and N (c j , x i )). By construction, ν R satisfies all of the clauses in {C j 1 , ..., C jp }, i.e. {C j 1 , ..., C jp } is satisfiable. (end proof of claim)</p><p>It follows from the preceding claim that the explanations for T 0 , A 0 |= AR q 0 (a), i.e. the minimal sets of causes for q 0 (a) that cover all repairs, correspond precisely to the MUSes of ϕ 0 . We can therefore exploit known complexity results for MUSes <ref type="bibr" target="#b52">(Liberatore, 2005)</ref>:</p><p>• Deciding if a clause belongs to a MUS is Σ p 2 -complete, so deciding if U (a, c j ) belongs to an explanation for T 0 , A 0 |= AR q 0 (a) is Σ p 2 -hard w.r.t. data complexity. Thus, we have a Σ p 2 lower bound for rel. • Deciding if a clause belongs to every MUS is NP-complete, so deciding if U (a, c j ) belongs to every explanation for T 0 , A 0 |= AR q 0 (a) is NP-hard w.r.t. data complexity. This gives an NP lower bound for nec. • rec: Deciding if a set of clauses is a MUS is BH 2 -complete, so deciding if {{U (a, c j 1 )}, ..., {U (a, c jp )}} is an explanation is BH 2 -hard w.r.t. data complexity. Hence, rec is BH 2 -hard.</p><p>The proof by <ref type="bibr" target="#b52">Liberatore (2005)</ref> for Σ p 2 -hardness of deciding if there exists a MUS of size at most k also shows that deciding if a set of clauses is a smallest MUS is Π p 2 -hard. It follows that deciding if an explanation for an AR-answer contains a smallest number of causes is Π p 2 -hard. Moreover, since every cause in the considered KB consists of a single assertion, deciding if an explanation for an AR-answer contains a smallest number of assertions is also Π p 2 -hard. To see why the generation task genOne is NP-hard, we note that to solve the NPcomplete problem of deciding whether K |= AR q( a), it suffices to call the procedure for genOne to generate a single explanation for K |= AR q( a). If the procedure outputs 'no' (meaning there is no explanation for K |= AR q( a)), then we output 'yes', and if it outputs an explanation, then we return 'no'.</p><p>The Σ p 2 -hardness of genBest, when explanations are ranked based upon the number of disjuncts or the number of assertions, follows from the Π p 2 -hardness of best rec for these same criteria. Indeed, to show that an explanation is not a best explanation, it suffices to generate a best explanation (genBest) and verify that it has fewer disjuncts / assertions than the explanation at hand.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Negative AR-Answers</head><p>We relate explanations of negative AR-answers to minimal models of ϕ ¬q ∪ ϕ cons .</p><p>Definition 5.13 (Minimal model). Given a clause set ψ over variables X, a set M ⊆ X is a minimal model of ψ iff (i) every valuation that assigns true to all variables in M satisfies ψ, (ii) no M M satisfies this condition. Cardinality-minimal models are defined analogously.</p><p>Proposition 5.14. A set E is an explanation (resp. cardinality-minimal explanation) for</p><formula xml:id="formula_37">K |= AR q( a) iff {x α | α ∈ E} is a minimal (resp. cardinality-minimal) model of ϕ ¬q ∪ ϕ cons .</formula><p>Proof. We recall that the reason why K |= AR q( a) iff ϕ ¬q ∧ ϕ cons is unsatisfiable is because the assertions whose corresponding variables are assigned to true in a valuation that satisfies ϕ ¬q ∧ ϕ cons form a subset of the ABox which: (i) contradicts every cause, since ϕ ¬q states that for every cause, one conflicting assertion is selected, and (ii) is consistent, since ϕ cons states that two assertions in a conflict cannot be selected together. Thus, the inclusionminimal models of ϕ ¬q ∧ ϕ cons are precisely the explanations for negative AR-answers.</p><p>Next we show the complexity upper bounds for the decision problems.</p><p>Proposition 5.15. Regarding explanations for negative AR-answers, rec is in AC 0 , best rec is in coNP, rel is in NP, and nec is in coNP w.r.t. data complexity.</p><p>Proof. It follows from Definition 5.4 that deciding whether E ⊆ A is an explanation for K |= AR q( a) can be done in polynomial time (data complexity) by checking:</p><p>• consistency of T , E</p><p>• inconsistency of T , E ∪ C for every C ∈ causes(q( a), K)</p><p>• minimality of E: no proper subset E E satisfies the two previous conditions.</p><p>In the appendix, we prove by means of first-order query rewriting an improved AC 0 upper bound for rec.</p><p>We can decide in NP that an explanation E is not a best explanation (according to some polynomial-time ranking criterion) by guessing a subset E ⊆ A and verifying in polynomial time w.r.t. data complexity that E is an explanation (see previous paragraph) and is better than E according to the given criterion. This yields a coNP upper bound for best rec.</p><p>A simple NP procedure for deciding rel (resp. not nec) consists in guessing a subset E ⊆ A that contains (does not contain) the considered assertion and checking in polynomial time whether it is an explanation (using the polynomial-time procedure for rec).</p><p>For the purposes of implementation, we propose alternative SAT-based procedures for rel and nec, based upon the following two propositions.</p><p>Proposition 5.16. An assertion α is relevant for explaining K |= AR q( a) iff the clause set ϕ ¬q ∪ ϕ cons ∪ ϕ α is satisfiable, where</p><formula xml:id="formula_38">ϕ α = { C∈causes(q( a),K),α∈confl(C,K) x C } ∪ {¬x C ∨ ¬x β | C ∈ causes(q( a), K), α ∈ confl(C, K), β ∈ confl(C, K), β = α}</formula><p>Proof. If α is relevant, then there exists an explanation E such that α ∈ E. Since E is minimal, there exists a cause C such that C ∪ (E\{α}) is consistent. It follows that no assertion β ∈ confl(C, K) belongs to E except for α. Then the valuation ν such that ν(x C ) = true, and for every assertion β, ν(</p><formula xml:id="formula_39">x β ) = true if β ∈ E, ν(x β ) = false otherwise, satisfies ϕ ¬q ∪ ϕ cons ∪ ϕ α .</formula><p>Conversely, if ϕ ¬q ∪ ϕ cons ∪ ϕ α is satisfiable, then it is possible to contradict every cause with a consistent set E of assertions such that there exists a cause C such that the only assertion of E ∩ confl(C, K) is α. Then an explanation that contains α is included in E.</p><p>Proposition 5.17. An assertion α is necessary for explaining K |= AR q( a) iff the set of clauses ϕ ¬q ∪ ϕ cons ∪ {¬x α } is unsatisfiable.</p><p>Proof. By Proposition 5.14, E is an explanation for K |= AR q( a) iff {x α | α ∈ E} is a minimal model of ϕ ¬q ∪ ϕ cons . It follows that α belongs to every explanation for K |= AR q( a) just in the case that x α belongs to every minimal model of ϕ ¬q ∪ ϕ cons , in which case</p><formula xml:id="formula_40">ϕ ¬q ∪ ϕ cons ∪ {¬x α } is unsatisfiable.</formula><p>The next proposition establishes matching lower bounds.</p><p>Proposition 5.18. Regarding explanations for negative AR-answers, nec is coNP-hard, and rel, genOne, and genBest (for any ranking criterion) are NP-hard w.r.t. data complexity. If explanations are ranked by cardinality, then best rec is coNP-hard w.r.t. data complexity.</p><p>Proof. All reductions are from propositional (un)satisfiability. Let ϕ 0 = C 1 ∧ ... ∧ C k be a set of clauses over propositional variables {X 1 , ..., X n }.</p><p>• genOne and genBest: Let T 0 , A 0 , and q 0 be as in Proposition 5.12. We know that ϕ 0 is satisfiable iff T 0 , A 0 |= AR A(a). Thus, to decide the satisfiability of ϕ 0 , we generate a (best) explanation of T 0 , A 0 |= AR A(a). If an explanation is produced, then we return 'yes', and if the procedure returns with no explanation, then we output 'no'.</p><p>• nec: We again let T 0 , A 0 , and q 0 be as in Proposition 5.12. Define a new TBox T 1 = T 0 ∪{∃U ¬S} and ABox A 1 = A 0 ∪{S(a)}. By construction, the assertion S(a) contradicts every cause for q 0 (a), so T 1 , A 1 |= AR q 0 (a). We show that deciding whether ϕ 0 is satisfiable is equivalent to deciding if S(a) is not necessary for explaining T 1 , A 1 |= AR q 0 (a). This establishes the coNP-hardness of checking necessity.</p><p>(⇒) Let ν be a satisfying valuation for ϕ 0 . It can be easily verified that the set</p><formula xml:id="formula_41">{P (c j , v i ) ∈ A 0 | ν(v i ) = true} ∪ {N (c j , v i ) ∈ A 0 | ν(v i ) = false}</formula><p>conflicts with every cause of q 0 (a), and so by choosing a subset of these assertions, we can construct an explanation for T 1 , A 1 |= AR q 0 (a) that does not contain S(a).</p><p>(⇐) An explanation E that does not contain S(a) forms a T 1 -consistent set of P -and N -assertions such that every c j has an outgoing P -or N -edge. We obtain a (partial) assignment ν E that satisfies ϕ 0 by setting ν E (v i ) = true if E contains an assertion P (c j , v i ) and ν E (v i ) = false if E contains an assertion N (c j , v i ).</p><p>• rel: We use the TBox T 1 and the ABox A 2 = A 1 ∪ {U (a, c k+1 ), P (c k+1 , x n+1 )}. Again, we note that S(a) contradicts every cause for q 0 (a), so T 1 , A 2 |= AR q 0 (a). We show that ϕ 0 is satisfiable iff P (c k+1 , x n+1 ) is relevant for explaining T 1 , A 2 |= AR q 0 (a); it follows that relevance is NP-hard.</p><p>(⇒) If ϕ 0 is satisfiable, then we can obtain an explanation for T 1 , A 2 |= AR q 0 (a) by adding P (c k+1 , x n+1 ) to a minimal subset of the P -and N -assertions corresponding to a satisfying truth assignment for ϕ 0 .</p><p>(⇐) If ϕ 0 is unsatisfiable, then every explanation must contain S(a). It follows that {S(a)} is the only explanation, so P (c k+1 , x n+1 ) is not relevant.</p><p>• best rec: We consider the following KB:</p><formula xml:id="formula_42">T 3 = T 0 ∪ {U 1 U, U 2 U, ∃U - 1 ¬T, ∃U 2 ¬S} A 3 = {P (c j , x i ) | X i ∈ C j } ∪ {N (c j , x i ) | ¬X i ∈ C j }∪ {U 1 (a, c j ), U 2 (a, c j ), T (c j ) | 1 ≤ j ≤ k} ∪ {S(a)} We claim that E = {S(a), T (c 1 ), ..., T (c k )} is a smallest explanation for T 3 , A 3 |= AR q 0 (a) iff ϕ 0 is unsatisfiable.</formula><p>(⇒) If ϕ 0 is satisfiable, then we can use a satisfying truth assignment to define a consistent set of k P -and N -edges such that every c j has an outgoing edge. This set is an explanation for T 3 , A 3 |= AR q 0 (a), and it has fewer assertions than E.</p><p>(⇐) If there exists an explanation of size at most k, it contains necessarily only P -and N -edges, since k assertions (P , N or T ) are needed to conflict all U 1 , and S(a) is needed as soon as one of the U 1 -assertions is conflicted only by a T -assertion. It follows that there exists a consistent set of P -and N -assertions such that every c j has an outgoing edge, from which we can construct a satisfying assignment for ϕ 0 .</p><p>Note that role inclusions are not needed for the lower bound, as we can replace the inclusions U 1 U and U 2 U in the reduction by the following set of concept inclusions:</p><formula xml:id="formula_43">∃P ¬∃U - 1 , ∃N ¬∃U - 1 , ∃P ¬∃U - 2 , ∃N ¬∃U - 2 , ∃U 1 A, ∃U 2 A.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.4">Negative IAR-Answers</head><p>Similarly to the case of negative AR-answers, we relate explanations of negative IAR-answers to minimal models of the clause set ϕ ¬q . Indeed, to show that an answer is not IAR, it is sufficient to contradict every cause, without the consistency constraint.</p><p>Proposition 5.19. A set E is an explanation (resp. cardinality-minimal explanation) for</p><formula xml:id="formula_44">K |= IAR q( a) iff {x α | α ∈ E} is a minimal (resp. cardinality-minimal) model of ϕ ¬q .</formula><p>Proof. The assertions whose corresponding variables are assigned to true in a valuation that satisfies ϕ ¬q form a subset of the ABox which contradicts every cause, since ϕ ¬q states that for every cause, one conflicting assertion is selected. Thus, the inclusion-minimal (resp. cardinality-minimal) models of ϕ ¬q are precisely the explanations (resp. cardinality-minimal explanations) for negative IAR-answers.</p><p>Importantly, ϕ ¬q does not contain any negative literals, and it is a folklore result that for positive clause sets, a single minimal model can be computed in polynomial time: one starts with the model in which all variables are set to true, and then one proceeds to set variables to false so long as the clauses are satisfied. By combining this tractability result with Proposition 5.19, we obtain the following: Proposition 5.20. Regarding negative IAR-answers, GenOne is in PTime.</p><p>Deciding the necessity problem for monotone CNF is also straightforward due to the following property: v appears in every minimal model of a monotone CNF ϕ if and only if ϕ contains the clause v. For the relevance problem, we can use another easy-to-check property (proven by <ref type="bibr" target="#b24">Boros, Elbassioni, Gurvich, and Khachiyan (2000)</ref> for the closely related setting of hitting set computation): a variable v is true in some inclusion-minimal model of ϕ iff it appears in a clause of ϕ that is not subsumed by any other clause. The following lemmas result from using Proposition 5.19 to transfer these properties to our setting: Lemma 5.21. An assertion is necessary for explaining K |= IAR q( a) just in the case that it is the only conflict of some cause for q( a).</p><p>Lemma 5.22. An assertion is relevant for explaining K |= IAR q( a) just in the case that it is in conflict with a cause C for q( a) such that for every other cause</p><formula xml:id="formula_45">C , if confl(C , K) ⊆ confl(C, K), then α ∈ confl(C , K).</formula><p>Based upon the preceding lemmas, we introduce a procedure RelNecNegIAR (Algorithm 4) for computing the sets of relevant and necessary assertions for explaining a negative IAR-answer. The procedure starts by computing the causes of q( a) (line 1), and then iterates over the causes (lines 2-5). When examining cause C i , it first tests (line 4) whether |confl(C i , K)| = 1, and if this is the case, the unique assertion in confl(C i , K) is added to N ecessary (as sanctioned by Lemma 5.21). Next, the set Relevant i is initialized to Conf l i (line 6), and then we iterate (lines 7-10) over all other causes C j to filter the assertions in Relevant i and retain only those that satisfy the conditions from Lemma 5.22. Finally, we let Relevant be the union over the sets Relevant i , and we output the sets Relevant and N ecessary. Correctness of the procedure follows from Lemmas 5.21 and 5.22.</p><p>As causes and conflicts can be computed in polynomial time for data complexity (Propositions 4.3 and 4.8), it is easy to show that RelNecNegIAR runs in polynomial time in |A|. In the appendix, we prove the following improved AC 0 upper bound for rec, nec, and rel by showing how these problems can be solved by means of first-order query rewriting. Again, the AC 0 upper bound is mostly of theoretical interest, as for our implementation, we will prefer to use the polynomial-time RelNecNegIAR procedure rather than FO-rewritings.</p><p>Proposition 5.23. Regarding explanations for negative IAR-answers, rec, nec, and rel are in AC 0 w.r.t. data complexity.</p><p>We next establish the remaining complexity upper bound.</p><p>Proposition 5.24. Regarding explanations for negative IAR-answers, best rec is in coNP w.r.t. data complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Implementation and Benchmark</head><p>In this section, we present the CQAPri system, which implements the query answering and explanation algorithms described in Sections 4 and 5, as well as the benchmark we created to test the system; the results of our experimental evaluation will be presented in the following section. To improve readability, full-page figures and results tables for Sections 6 and 7 are given in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">The CQAPri System</head><p>We implemented our query answering and explaining framework under AR, IAR and brave semantics over DL-Lite R KBs in Java v1.7 within our CQAPri ("Consistent Query Answering with Priorities") tool<ref type="foot" target="#foot_2">8</ref> . CQAPri is built on top of the relational database server PostgreSQL v9.3.2 (www.postgresql.org), the Rapid v1.0 query rewriting engine for DL-Lite <ref type="bibr" target="#b35">(Chortaras, Trivela, &amp; Stamou, 2011)</ref>, and the SAT4J v2.3.4 SAT solver <ref type="bibr" target="#b13">(Berre &amp; Parrain, 2010)</ref>. All these building blocks are used with their default settings.</p><p>Following the framework developed in Section 4, CQAPri utilizes the brave, AR, and IAR together to classify a query answer a into one of 3 classes:</p><p>• Possible: K |= brave q( a) and K |= AR q( a)</p><p>• Likely: K |= AR q( a) and K |= IAR q( a)</p><formula xml:id="formula_46">• (Almost) sure: K |= IAR q( a)</formula><p>CQAPri handles ABoxes stored in PostgreSQL, while it keeps the TBox in-memory. ABoxes are stored as relational databases with one table per concept and role, of one or two columns (named s for concept and s and o for role) that contains the individuals involved in that concept or role. B-Tree indexes have been created for each table, on s for concepts and (s, o) and (o, s) for roles. The concept, role, and individual names are encoded by integers, and a dictionary table relates each name to its identifier.</p><p>CQAPri computes the set of conflicts for the KB in a preprocessing phase since it is query-independent. Conflicts are computed following the steps in Algorithm 1 and stored as a conflict graph (Definition 4.4). More precisely, the SQLized rewritings of the queries looking for counter-examples to the negative TBox inclusions are evaluated over the ABox, their images are retrieved and stored as a graph whose vertices are assertions and edges indicate images, and finally the non-minimal ones are discarded by removing edges between any self-inconsistent assertion and the others to obtain the conflict graph.</p><p>At query time, the system implements the steps from the (non-Boolean version of) ClassifyQuery procedure. When a query arrives, CQAPri first evaluates it over the ABox using its SQLized rewriting, to obtain its candidate answers and their images. Candidate answers define a superset of the answers holding under the brave, AR and IAR semantics. Among the candidate answers, CQAPri identifies those which are not brave-answers by discarding the inconsistent images, that contain an edge of the conflict graph: an answer that has only such images does not hold under brave semantics. It also identifies the IAR ones, by checking whether there is some image whose assertions do not participate in any edges in the conflict graph, since such an image contains a cause such that none of its assertions is involved in a conflict. Finally, for brave-answers that are not found to be IAR-answers, deciding whether they are entailed under the AR semantics is done using the SAT encodings of Figure <ref type="figure">2</ref>. Using consistent images instead of causes is not a problem here because the set of causes is included in the set of images and every consistent image contains a cause, so it is possible to consistently contradict every cause iff it is possible to consistently contradict every consistent image.</p><p>To explain why a query answer a belongs to one of the three classes Possible, Likely and Sure that correspond to K |= S q( a) and K |= S' q( a) for two semantics S and S', CQAPri provides all the explanations for a being a positive answer under the first semantics and a single explanation for it being a negative answer under the other one (i.e. a counterexample), together with the necessary and relevant assertions for both positive and negative answers. For Possible answers, we additionally provide the necessary and relevant assertions for explaining K |= IAR q( a) (which can be used e.g. to identify how to modify the ABox to make an answer hold under IAR semantics). Positive explanations are ranked as explained in Section 5.1: using the number of assertions for negative answers and positive brave and IAR-answers, and numbers of disjuncts and total number of assertions for positive ARanswers; for ranking the latter, the user can choose the priority between the two criteria.</p><p>Explanations are computed using the results on positive and negative answers from Section 5.2. We thus need the causes of the query answers as well as their conflicts. For the causes, CQAPri prunes the non-minimal images computed during the query answering phase. The conflicts are directly available from the previous steps.</p><p>For positive IAR-answers, CQAPri stores the causes that are without conflict during the query answering phase. Instead of halting at the first cause without conflict, which is enough to show an answer holds under IAR semantics, it passes in review all causes. For positive AR-answers, the SAT encoding is constructed for the query answering phase, and CQAPri uses the solver SAT4J to compute the MUSes (see Section 6, <ref type="bibr" target="#b13">Berre and Parrain, 2010)</ref>. Necessary and relevant assertions for positive answers are computed simply by taking the intersection and union of the explanations. For negative AR-answers, we rely on SAT4J to compute a smallest model of ϕ ¬q ∧ ϕ cons , as well as the necessary and relevant assertions with the encodings presented in Propositions 5.16 and 5.17 that we use to test every potentially relevant assertion, i.e. that appears in ϕ ¬q . For negative IAR-answers, we choose to compute by default an arbitrary explanation in polynomial time (cf. Section 7.3 for the reason for this choice), but CQAPri can also provide a smallest explanation using the SAT solver to find a cardinality-minimal model of ϕ ¬q . The relevant and necessary assertions are computed using Algorithm 4 that exploits Lemmas 5.21 and 5.22.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">The CQAPri Benchmark</head><p>To evaluate CQAPri, we needed a DL-Lite R KB with a large and inconsistent ABox. Very few experiments have been done on inconsistent KBs, and the only DL-Lite R benchmark we found was not suitable for our purposes (cf. Section 8.2.2), so we designed our own. Ontology We built our TBox over the LUBM ∃ 20 TBox <ref type="bibr" target="#b55">(Lutz, Seylan, Toman, &amp; Wolter, 2013)</ref>, which provides an extended DL-Lite R version of the well-known ELI TBox of the Lehigh University Benchmark (LUBM) <ref type="bibr" target="#b42">(Guo, Pan, &amp; Heflin, 2005</ref>) that describes the university domain. LUBM ∃ 20 differs from the original LUBM by the removal of the axioms that go beyond DL-Lite R but also by the addition of concept inclusions, many of which having existential restrictions on the right-hand side, and of subconcepts to increase the size of the ontology. LUBM ∃ 20 comprises 127 concepts, 27 roles and 202 positive inclusions. To enable contradictions, we added negative inclusions to state the disjointness of pairs of concepts or roles having the same closest super-concept or super-role. Such concepts and roles appear at the same level in the TBox (that is, have the same distance to the top concept Thing). We excluded a small number of such inclusions when they did not seem to reflect the intended meaning of the concepts or roles. Figure <ref type="figure">3</ref> illustrates how we added negative inclusions for an example concept AssistantProfessor. We added a total of 875 negative inclusions. This apparently huge number of constraints results from the many pairwise disjoint concepts or roles used in the TBox.</p><p>Datasets We generated ABoxes of increasing sizes with the Extended University Data Generator (EUGen) provided with LUBM ∃ 20 by setting its data completeness parameter (i.e. the percentage of individuals from a given concept for which roles describing this concept are indeed filled) to its default value of 95%, which seems realistic from the application viewpoint. All the generated ABoxes were found consistent w.r.t. our enriched TBox, which suggests that the added disjointness constraints were faithful to the reused benchmark. The size of these ABoxes ranges from 75,663 to 9,938,139 assertions, which corresponds to 1 to 100 universities in EUGen settings, and each ABox is included in the larger ones: the smallest corresponds to university 0, the largest to universities 0 to 99.</p><p>Inconsistencies were introduced by reviewing all of the assertions of the consistent ABox, and contradicting the presence of an individual in a concept assertion with probability p, and the presence of each individual in a role assertion with probability p/2. A contradicting assertion is built by stating that the considered individual also belongs to a disjoint but close concept, i.e. the two concepts have the same closest super-concept which is not the top concept Thing. Note that a concept may here be an unqualified existential role restriction. The contradicting assertion is added either explicitly or implicitly by choosing one of its specializations (obtained by query rewriting). The concept or role that is used to build the assertion which will actually be added to the ABox is chosen among all rewritings of all possible contradicting assertions with a uniform probability distribution. We chose to generate such inconsistencies because they seem quite natural in real applications (e.g. using by mistake AssistantProfessor in place of AssociateProfessor). Conflicting assertions thus introduced are in turn processed as described above to create a few more complex conflicts. Additionally, for every role assertion, its individuals are switched with probability p/10. We chose to generate such misuses of roles because they also seem quite natural mistakes and may lead to inconsistencies (e.g. inverting the Faculty and Course in a TeacherOf role assertion).</p><p>Example 21. Below are four assertions that have been created to conflict some assertions of the original consistent ABoxes 9 .</p><p>• The assertion Subj4Course(Dept11.U niv1/GradCourse33) contradicts the assertion Subj20Course(Dept11.U niv1/GradCourse33) because these concepts are disjoint (Subj20Course ¬Subj4Course).</p><p>9. For readability, we have abbreviated some of the individual names, e.g. replacing Department by Dept.</p><p>• The assertion Subj3Dept(U niv462) was inserted to contradict the assertion MastersDegreeFrom(Dept22.U niv0/Lecturer2, U niv462): indeed, the range of MastersDegreeFrom is Univ (∃MastersDegreeFrom - Univ), which is disjoint with Dept (Univ ¬Dept), which has Subj3Dept as a subconcept (Subj3Dept Dept).</p><p>• The assertion PublicationResearch(DU M M Y 1 1 749, Dept18.U niv1/Course32) conflicts with TakesCourse(Dept18.U niv1/U ndergradStud124, Dept18.U niv1/Course32). Indeed, TakesCourse has Course for range, which is disjoint with Research which is the range of PublicationResearch.</p><p>• Finally MemberOf(Dept5.U niv1, Dept5.U niv1/U ndergradStud47) is obtained by switching the two individuals of an assertion. Note that this may induce that an individual belongs to a totally different concept, since the domain and the role of a concept have often no common super-concept other than Thing. Such inversions generally yield a lot of conflicts.</p><p>For each of the 100 universities that constitute our consistent ABoxes, we set p = 0.002 and generated 50 batches of conflicting assertions using the method described above. We obtain inconsistent ABoxes with increasing ratios of assertions involved in some conflict by adding the n first batches of conflicting assertions to each university of the original consistent ABox, n ranging from 1 to 50, that roughly leads to a percentage of assertions involved in some conflict varying from about 3% to about 46%. We consider that ABoxes with a few percent of assertions in conflicts are realistic, but we also built ABoxes with a huge number of conflicts in order to study the impact of the data quality on the efficiency of our approach.</p><p>Table <ref type="table" target="#tab_5">5</ref> in the appendix displays the characteristics of the generated ABoxes in terms of size, inserted assertions, and number and percentage of assertions involved in conflicts of the ABoxes of our benchmark. Every ABox's id uXcY indicates the number X of universities generated by EUGen and the number of queries batches used to add conflicts Y. Note that our method ensures that uXcY ⊆ uX cY when X ≤ X and uXcY ⊆ uXcY when Y ≤ Y .</p><p>Queries Table <ref type="table" target="#tab_3">3</ref> summarizes the characteristics of the 20 queries used in our experiments (for the complete queries, consult Figure <ref type="figure" target="#fig_2">4</ref> in the appendix). They have between 1 and 8 atoms, with an average of 4.25 atoms. Their rewritings produced with Rapid have between 2 and 202,710 CQs, 23,185.95 on average. Queries q14 to q20 were used in experiments of the DL-Lite query answering systems<ref type="foot" target="#foot_3">10</ref> by Pérez-Urbina, Horrocks, and <ref type="bibr" target="#b63">Motik (2009)</ref>, <ref type="bibr" target="#b55">Lutz et al. (2013), and</ref><ref type="bibr" target="#b66">Rosati et al. (2012)</ref>, and we designed the others ourselves. Our rationale when building queries was to use some concepts that have disjoint specializations to get more chance to get answers that hold under AR semantics and not under IAR semantics (as such cases are the most challenging to handle and thus the most interesting for testing purposes). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Experimental Evaluation</head><p>We conducted experiments to empirically study the properties of our query answering and explanation frameworks. We study in particular the impact of varying the size of the ABoxes and the ratio of assertions involved in some conflicts on CQAPri behaviour.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Experimental Setting</head><p>All experiments reported in this work were run on an Intel Xeon X5647 at 2.93 GHz with 16 GB of RAM, running CentOS 6.8. Reported times are averaged over 5 runs. We did not measure the time that our prototype takes to present the results (i.e. translating the answers back in the original terminology with the dictionary table of the database and printing the results in text files), since the goal of our experiments was to study the properties of the computation of query answers and explanations rather than their presentation (which a full-fledged OMQA system would probably handle in a more refined and efficient way).</p><p>We use the benchmark presented in Section 6. To test the explanation component of our tool, we explain all answers of the queries over all the ABoxes of our benchmark, except for those which have more than 200,000 answers, because it yields unreasonable experimental times. We note that in practice, a user will never examine the explanations of more than a small number of answers, so there would typically be no need to generate explanations for (hundreds of) thousands of answers.</p><formula xml:id="formula_47">c1 c5 c10 c20 c30 c50 u1 2,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Experimental Results for Query Answering</head><p>We empirically study the properties of our consistent query answering framework by measuring the time spent in the different phases of query answering under IAR, AR and brave semantics, and how it varies with the size of the ABoxes and the ratio of assertions involved in some conflicts. We also consider how the repartition of the number of answers under the three semantics changes as the percentage of assertions in conflict increases.</p><p>The time it took CQAPri to be up and ready to answer queries is dominated by the construction of the conflict graph for the ABox (Table <ref type="table" target="#tab_4">4</ref>); it took about 2 seconds to load the TBox, construct the queries that correspond to the violation of negative inclusions, and open the PostgreSQL connection to the ABox. The time for the construction of the conflict graph has a linear behavior w.r.t. the size of the ABox, and the more conflicts there are, the higher the slope.</p><p>Table <ref type="table" target="#tab_6">6</ref> shows, for each query-ABox pair, how many Sure, Likely and Possible answers were identified among the candidate answers. In this table, OOM means that CQAPri ran out of memory. In all of our experiments, we found only a few candidate answers that are not brave: only q9 got such answers, on all ABoxes (up to 802 inconsistent answers on u100conf50). Only 9 queries out of 20 got Likely answers over some ABoxes, 5 of them have only one or two atoms (q1, q2, q11, q12, q13) while the others are more complex (q5, q6, q9, q18). Such answers occur because these queries are general and involve concepts with many disjoint sub-concepts. For 67.5% of our query-ABox pairs, the AR semantics does not provide any additional answers compared to IAR semantics. However, all answers of q5 over the different uXc20 ABoxes hold under AR semantics but not IAR semantics. For such selective queries, using the AR semantics rather than IAR semantics may be necessary to identify some likely answers. Unsurprisingly, for a given ABox size, when the proportion of conflicting assertions increases, the number of Sure answers decreases while the number of Likely and Possible answers increases. This incurs a higher computational cost since a call to the SAT solver is needed for each non-IAR-answer to decide if it holds under AR semantics or not.</p><p>Figure <ref type="figure" target="#fig_5">5</ref> shows the evolution of the time spent by CQAPri for the query answering phase (consisting in identifying all Possible, Likely, and Sure answers) w.r.t. the size of the ABox, for three different ratios of assertions in conflict: a few percent (about 4%, uXc1), as we expect to be the case in most real applications, about 30% (uXc20), or about 45% (uXc50). Figure <ref type="figure" target="#fig_6">6</ref> shows the evolution of the time spent by CQAPri for query answering w.r.t. the proportion of ABox assertions involved in some conflicts, for small (u1cY), intermediate (u20cY), and large (u100cY) ABoxes. Figure <ref type="figure" target="#fig_7">7</ref> shows the proportion of the query answering time spent in rewriting the query, executing the rewritten query to get candidate answers, filtering the IAR-or not brave-answers, and identifying the AR-answers among the remaining answers.</p><p>In Figure <ref type="figure" target="#fig_5">5</ref>, we remark two outlier queries, q4 and q9, whose answering times have an exponential-like growth w.r.t. ABox size even when only a small fraction of the assertions participate in conflicts. Query q4 is very sensitive both to ABox size and ratio of conflicts, while q9 is rather robust to conflicts. This behaviour seems due to the uncommon characteristics of these queries. Indeed, q9 has 202,579 rewritings, with 4 variables and no constant, that leads to a very costly execution over the database, as illustrated on Figure <ref type="figure" target="#fig_7">7</ref> where almost 90% of the time is spent on executing the rewritten query even in the case of the largest ABox with the highest percentage of conflicts. Query q10 that differs from q9 only by the introduction of a constant, behaves very differently since its answering time stabilizes quickly. As for q4, it has a high number of atoms and variables, which are all free, yielding a huge number of answers (10,362,220 answers on u100c10), which become quickly non-IAR since their causes involve lots of assertions. These two queries are interesting to challenge our system, but are not realistic, especially q4.</p><p>For the other queries, CQAPri scales up to large ABoxes when the proportion of assertions involved in some conflict is only a few percent, and even a few tens percent for most of the queries. The increase in the number of non-IAR-answers when the proportion of conflicts increases generally significantly augments the time spent in this last phase. This explains our observation that the lower the ratio of conflicts, the more query answering time shows a linear behaviour w.r.t. the ABox size.</p><p>The average time to classify an answer is generally under the millisecond, and at most 7 ms (for q19 on u20c50). The average time to decide whether a brave and non-IAR-answer holds under AR semantics is generally a little higher but also under the millisecond.</p><p>Overall, CQAPri scales well in settings ranging from ones we consider realistic to more artificial ones. Our experiments thus demonstrate that the AR-answers can be computed in practice, and our analysis shows that this is due to the fact that the IAR semantics often constitutes a very good approximation of the AR semantics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Experimental Results for Query Answer Explanation</head><p>To assess the practical interest of our explanation framework, we empirically study the properties of our implementation, in particular: the impact of varying the percentage of assertions in conflict, the typical number and size of explanations, and the extra effort required to generate cardinality-minimal explanations for negative IAR-answers rather than arbitrary ones.</p><p>Tables <ref type="table">7</ref><ref type="table" target="#tab_7">8</ref><ref type="table" target="#tab_8">9</ref>show the number of answers from each class for each query, as well as the distribution of the explanation times for these answers, for ABoxes of growing sizes and ratios of conflicts. (We recall that for our explanation experiments, we exclude queries that have more than 200,000 answers, which is why queries q8, q10, q17, and q19 do not appear in these tables.) Figures <ref type="figure" target="#fig_8">8</ref> and<ref type="figure" target="#fig_9">9</ref> show the time spent in explaining all query answers w.r.t. ABox size and proportion of conflicting assertions respectively. Figure <ref type="figure" target="#fig_10">10</ref> displays the proportion of time spent in the different phases to explain all query answers for ABoxes of growing difficulty. The explanation cost, given by the two upper bars, consists in pruning non-minimal consistent subsets of the ABox entailing the answers to get the causes, and computing the explanations from the causes and conflicts. The three lower bars relate to the query answering phase, which consists in rewriting and executing the query to get the candidate answers, and identifying Sure, Likely, and Possible answers (classify).</p><p>We summarize the general tendencies we observed. Regarding the time needed to produce explanations, the main conclusion is that explaining a single query answer is always feasible and fast (≤1s) when there are a few percent of conflicts in the ABox (Tables <ref type="table">7</ref><ref type="table" target="#tab_7">8</ref><ref type="table" target="#tab_8">9</ref>, uXc1 case), as is likely to be the case in most real applications. Even with a high percentage of conflicts, the longest time observed is below 20s (19.5s for explaining a Possible answer of q9 on u100c50), and remains lower than 1s for small ABoxes (up to u20cY case, i.e. 2 million assertions), and lower than 8s for a significant percentage of conflicts (uXc20 case, i.e. 30% of assertions in conflict). In all the experiments we made, explaining a single answer typically takes less than 10ms, rarely more than 1s. However, computing explanations of all answers can be prohibitively expensive when there are very many answers, which is why we do not produce them all by default.</p><p>Adding conflicts to the ABox complicates the explanations of answers, due to their shift from the Sure to the Likely and Possible classes. Explaining such answers indeed comes at higher computational cost, as can be seen in Figures <ref type="figure" target="#fig_8">8,</ref><ref type="figure" target="#fig_9">9</ref> and 10. Compared to query answering, we found that explaining all query answers is more sensitive both to ABox size and ratio of conflicts.</p><p>We observed that the average number of explanations per answer is often reasonably low, although some answers do have a large number of explanations. For instance, on the ABoxes u100cY, there were less than 10 explanations on average, but this number varies from about 1 to more than 400, and for u100c50, we got up to 4560 explanations for an AR-answer (and up to 741 causes for a brave-answer). Even on small ABoxes (u1cY), we got up to 693 explanations for a brave-answer and 243 explanations for an AR-answer. Regarding the size of explanations of AR-answers, the number of causes in the disjunction was up to 25 (for a q12 Likely answer on u100c50; up to 5 on the u1cY ABoxes), showing the practical interest of ranking the explanations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.1">Explaining Negative Answers</head><p>Our prototype is able to explain K |= S q( a) by providing a (possibly smallest) explanation for K |= S q( a), together with the relevant and necessary assertions for K |= S q( a). We explain here why we chose to compute an arbitrary explanation for K |= IAR q( a) by default rather than a cardinality-minimal one. We also give some insight into the explanation times for K |= AR q( a) and the contribution of the computation of necessary and relevant assertions to the overall runtime.</p><p>We considered the following four cases in our experiments:</p><p>• Case 1 is our default setting, in which we compute an arbitrary explanation for negative IAR-answers, a smallest explanation for negative AR-answers, and the necessary and relevant assertions for explaining negative answers, • Case 2 differs from Case 1 in omitting the computation of the necessary and relevant assertions for K |= AR q( a) and K |= IAR q( a), • Case 3 differs from Case 1 in omitting the computation of the relevant assertions for K |= AR q( a), • Case 4 differs from Case 1 in computing a cardinality-minimal explanation for K |= IAR q( a) instead of using a polynomial-time procedure to generate an arbitrary one.</p><p>Table <ref type="table" target="#tab_10">10</ref> displays, for each query, the number of Likely and Possible answers the query possesses, and the distribution of the times for explaining K |= S q( a) in our default setting (Case 1). If we compare these distributions with those of Tables <ref type="table">7</ref><ref type="table" target="#tab_7">8</ref><ref type="table" target="#tab_8">9</ref>, we can see that for many queries, there is the same number of answers having the longest explanation times (columns [0.1, 1[ and &gt;1) when only the negative answer is explained as in the case where both K |= S q( a) and K |= S q( a) are explained. This shows that for many queries, the difficulty comes from explaining K |= S q( a).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cost of relevant and necessary assertions</head><p>Table <ref type="table" target="#tab_2">11</ref> shows the same information as Table <ref type="table" target="#tab_10">10</ref>, in the case where the necessary and relevant assertions for explaining K |= IAR q( a) or K |= AR q( a) are not computed. In this case, almost all negative answers are explained in less than 10ms. This shows that the main part of the explanation time for negative answers is spent in computing these assertions. Note that for negative IAR-answers (Likely answers), most of the explanation times were already below 10ms in our default case.</p><p>Computation of relevant assertions for negative AR-answers Since computing the necessary and relevant assertions for K |= AR q( a) appears to be costly, we investigate further to see how this cost is distributed and if it is possible to reduce the cost of negative explanation without losing too much information. For negative AR-answers, deciding if an assertion α appears in some explanation is an NP-complete problem, and deciding if it appears in all explanations is coNP-complete. In practice the problem of finding the necessary assertions can be solved efficiently because for a negative AR-answer, the SAT solver has already found a model of ϕ ¬q ∪ϕ cons during the query answer classification phase, so checking whether ϕ ¬q ∪ ϕ cons ∪ {¬x α } is unsatisfiable is trivial when α does not appear in this model, and if it does, the SAT solver may reuse what it has already computed for a closely related problem. Deciding if α is relevant is more difficult because the encoding we use differs more from ϕ ¬q ∪ϕ cons . Indeed, if we compare the execution times with (Table <ref type="table" target="#tab_10">10</ref>, for Possible answers) and without (Table <ref type="table" target="#tab_2">12</ref>) the computation of the relevant assertions for K |= AR q( a), we observe significant differences: for all queries and ABoxes, at least 60% of the negative AR-answers are explained in less than 10ms (only 6.45% for q19 on u100c50 in Case 1), and less than 0.15% of them need more than 1s (12.72% of the negative AR-answers of q12 on u100c50 in Case 1). Moreover, the longest time required to explain an answer in Case 1 is generally significantly longer than in Case 3 ( for instance on u100c20, the longest time required to explain an answer is 8s in Case 1, while it is 5s for Case 3).</p><p>We therefore tried to obtain an approximation of these assertions that is fast to compute. The assertions relevant for K |= IAR q( a) can be computed very quickly and provide a superset of those relevant for K |= AR q( a), since the explanations for K |= AR q( a) are the consistent explanations for K |= IAR q( a). However, in our experiments, those two sets of assertions differ quite significantly, and when they do the difference may be huge (hundreds of assertions instead of one to four assertions for some answers of q12 on u100c20). When the ABox size and ratio of conflicts increase, the proportion of answers having additional relevant assertions for K |= IAR q( a) and the difference between the two sets of relevant assertions for K |= IAR q( a) and K |= AR q( a) increase. The two sets always coincide on u1c1, while on the uXc50 ABoxes, they differ in up to 100% of the Possible answers of a query (up to 27 assertions for u1c50, up to 651 assertions for u100c50). On u100c1 they differ in up to 5.6% of the Possible answers of a query, and up to 501 assertions. This shows that there is no straightforward way to reduce the computation of relevant assertions for negative AR-answers without sacrificing too much information.</p><p>Cardinality of explanations for negative IAR-answers Although smallest explanations for negative answers may be preferred, we found it worthwhile to use a polynomial-time method to obtain an arbitrary explanation for a negative IAR-answer rather than relying on the SAT solver to generate a smallest such explanation.</p><p>Indeed, computing an arbitrary explanation for K |= IAR q( a) always takes less than 100ms (see Table <ref type="table" target="#tab_10">10</ref>, Likely answers), and in almost all cases less than 10ms.</p><p>By contrast, when a smallest explanation is computed (Table <ref type="table" target="#tab_3">13</ref>), more time may be needed. A striking case is that of query q12: on u20c20, almost 19 minutes are spent in computing a smallest explanation for one negative IAR-answer, and on u100c20, it takes around 50 minutes, while computing an arbitrary explanation was done in less than 10ms for every ABox and negative IAR-answer of q12 (Table <ref type="table" target="#tab_10">10</ref>). This even leads to a timeout for ABoxes from u20c30. This long explanation time is due to the unusual size of the explanation (18 assertions for the answer on u100c20, whereas other explanations for negative answers typically contained only a few assertions).</p><p>As for the size of explanations, we found that on u100c20, the arbitrary explanations generated for all negative IAR-answers of q5, q6, q11, and q12 have exactly the same size as the smallest explanations found with the SAT solver, that only one negative IAR-answer of q13 had a suboptimal explanation (with 4 assertions instead of 3), as well as about 61% of the negative IAR-answers of q9, whose explanations contain at most two assertions more than the smallest ones.</p><p>The possibly very high additional cost of computing a smallest explanation for a limited benefit in terms of the size of explanations led us to adopt arbitrary explanations for negative IAR-answers as the default setting in our system. However, note that this very high additional cost concerns very few answers: for instance all the other negative IAR-answers of q12 on u20c20 are explained in less than 10ms. One could therefore envision a mixed approach in which one allocates a short amount of time to try to find a smallest explanation, falling back to arbitrary explanations if no smallest explanation is identified within the allotted amount of time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Related Work</head><p>This section provides an overview of different lines of research that are related to our own.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Inconsistency-Tolerant Semantics</head><p>There have been several different inconsistency-tolerant semantics that have been proposed for DL KBs. We will only give a brief discussion of the literature here and refer the reader to the recent survey by <ref type="bibr">Bienvenu and Bourgaux (2016)</ref> for further details and references.</p><p>The survey by Bienvenu and Bourgaux compares different semantics w.r.t. the properties they satisfy and the set of answers they produce. Two key semantic properties are considered: Consistent Support and Consistent Results. A semantics S (with entailment relation |= S ) satisfies the Consistent Support property if for every KB K = T , A , query q, and tuple a, if K |= S q( a), then there exists a T -consistent subset C ⊆ A such that T , C |= q( a) (in our terminology, there is a cause for q( a)). This is a desirable property as it means that a query answer can always be justified by exhibiting a consistent subset of the KB which yields the answer. The brave, AR, and IAR semantics all satisfy this property, with the brave semantics being the most permissive semantics with this property. By contrast, variants of the AR and IAR semantics based upon repairs of the closed ABox (the so-called CAR and ICAR semantics, introduced by <ref type="bibr" target="#b49">Lembo et al., 2010)</ref> do not satisfy this property. The second property, Consistent Results, holds for a semantics S just in the case that for every KB K = T , A , there exists a model I of T such that I |= q( a) for every q( a) with K |= S q( a). This property thus requires that query results obtained from a KB are jointly consistent with the TBox, meaning that users can safely combine query results without risking contradiction. As discussed in Section 3, this property is verified by both AR and IAR semantics, but not by the brave semantics.</p><p>The comparison of semantics by <ref type="bibr">Bienvenu and Bourgaux (2016)</ref> also considers the relationships of over-and under-approximation that hold between the different semantics. We have seen in Section 3 that the IAR and brave semantics provide respectively over-and under-approximations of the AR semantics, a fact that we exploit in our system. To obtain finer approximations, the families of k-support and k-defeater semantics were proposed <ref type="bibr" target="#b21">(Bienvenu &amp; Rosati, 2013)</ref>. It was shown that the k-support semantics (resp. k-defeater semantics) contain the IAR (resp. brave) semantics as special cases, converge to the AR semantics in the limit, and possess the same desirable semantic and computational properties (in particular, AC 0 data complexity) as the IAR (resp. brave) semantics. We observe that these semantics can be elegantly defined in terms of our notions of explanations: a tuple a is an answer to q( x) under the k-support semantics iff K |= AR q( a) has an explanation consisting of at most k causes, and it is an answer to q( a) under the k-defeater semantics iff there is no explanation of K |= AR q( a) of size at most k. Thus, the input parameter k used by these semantics is naturally interpreted as the size of explanations for q( a) being a (non)-answer under AR semantics.</p><p>We note in passing that another parameterized family of semantics, the k-lazy semantics <ref type="bibr" target="#b53">(Lukasiewicz, Martinez, &amp; Simari, 2012)</ref>, has been proposed as a compromise to interpolate between the IAR and AR semantics, but these semantics have less desirable semantic and computational properties than the k-support semantics (as has been argued by <ref type="bibr" target="#b21">Bienvenu &amp; Rosati, 2013;</ref><ref type="bibr">Bienvenu &amp; Bourgaux, 2016)</ref>. We also point out that a recent work by <ref type="bibr" target="#b12">Benferhat, Bouraoui, Croitoru, Papini, and Tabia (2016)</ref> introduces a new semantics, called non-objection inference, that is an over-approximation of the AR semantics and an underapproximation of the brave semantics. This semantics is defined as follows: a tuple a is an answer to q( x) under non-objection semantics iff (i) there is some repair R such that T , R |= q( a) and (ii) for every repair R, there is a model I of T , R in which q( a) holds. Interestingly, unlike the brave semantics, the non-objection semantics satisfies the Consistent Results property. Moreover, ground CQ answering (i.e., Boolean CQs without existentially quantified variables) is in PTime w.r.t. data complexity for DL-Lite.</p><p>Most of the semantics discussed so far are based upon the notion of repair, defined as an inclusion-minimal T -consistent subset of the ABox. However, just as we introduced preferences to isolate the most interesting explanations, it is natural to use preferences to focus on the most likely repairs. In the DL setting, the idea was first explored by <ref type="bibr" target="#b36">Du, Qi, and Shen (2013)</ref>, who considered a weight-based variant of the AR semantics to query highly expressive description logics. Closer to the present work, variants of the IAR, brave, and AR semantics based upon several notions of preferred repair (namely, cardinality, prioritized set inclusion, prioritized cardinality, and weights) have been considered by the authors of this paper <ref type="bibr" target="#b19">(Bienvenu et al., 2014;</ref><ref type="bibr" target="#b25">Bourgaux, 2016)</ref>. We showed that in most cases the addition of preferences increases the complexity of query answering over DL-Lite KBs. However, for preferred repairs based upon prioritized set inclusion, query answering under modified AR and IAR semantics is coNP-complete w.r.t. data complexity, and thus no higher than for 'plain' AR semantics. This led us to extend the SAT encoding from Section 4 to these semantics and to implement the resulting encodings in CQAPri. The main result of the experiments was that the addition of preferences makes query answering more challenging. We note that a variant of non-objection semantics based upon cardinality-maximal repairs has been considered by <ref type="bibr" target="#b12">Benferhat et al. (2016)</ref> and unsurprisingly, it was shown to have intractable data complexity.</p><p>In this work, we chose to focus on the AR semantics, as it is the most widely studied semantics and arguably the most reasonable. We additionally considered the IAR and brave semantics, which can be seen as the most and least permissive semantics, in order to classify answers based upon their reliability and to aid us in computing the answers under AR semantics. It would be interesting to experiment with other approximations of AR semantics that offer polynomial data complexity, like the k-support semantics, k-defeater semantics, and the non-objection semantics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Systems and Benchmarks for Inconsistency-tolerant Query Answering</head><p>We next discuss previous implementations and testing of algorithms for inconsistencytolerant query answering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2.1">Systems for Inconsistency-tolerant Query Answering</head><p>In terms of implemented tools and benchmarks for inconsistency-tolerant query answering over DL KBs, we are aware of three systems: the QuID system <ref type="bibr" target="#b66">(Rosati et al., 2012;</ref><ref type="bibr" target="#b51">Lembo et al., 2015)</ref> that handles IAR semantics for CQs and DL-Lite A KBs, the SaQAI system <ref type="bibr" target="#b71">(Tsalapati et al., 2016)</ref> that handles IAR and ICAR semantics for CQs and DL-Lite KBs, and the system by <ref type="bibr" target="#b36">Du et al. (2013)</ref> for querying SHIQ KBs under a variant of AR semantics with weight on ABox assertions that handles CQs without non-distinguished variables (which reduces to the simpler task of ABox assertion entailment). None of these systems is directly comparable to our own, since they employ different semantics, and in the case of the system of Du et al. target different DLs and queries.</p><p>The QuID system implements three approaches for IAR query answering: query rewriting, annotated ABox, and ABox cleaning. The query rewriting approach consists in rewriting the query and evaluating the rewritten query over the original inconsistent ABox (see Section 3 for the intuition on how rewritings for IAR semantics can be constructed). In the annotated ABox approach, the ABox is annotated with information about assertions that belong to some conflict, and at query time, we enrich the original query with conditions to filter out such assertions. The cleaning approach evaluates the original query over a 'cleaned' version of the ABox, in which every assertion involved in some conflict has been removed (which yields precisely the intersection of repairs). Our approach regarding IAR semantics is closer to the last two approaches, since our preprocessing phase where we compute and store the conflicts is similar in spirit to the annotation and extraction of the intersection of the repairs. The main difference is that we do not modify the query to retrieve only IAR-answers at evaluation time but rather filter out IAR-answers from candidate answers by checking a posteriori that they have causes without conflict.</p><p>The SaQAI system computes the intersection of the repairs by computing the conflicts and removing them from the ABox, then saturates the ABox obtained before performing standard query evaluation. The experiments reported by <ref type="bibr" target="#b71">Tsalapati et al. (2016)</ref> show that for IAR query answering, CQAPri performances are comparable to those of QuID and often better, while SaQAI is much more efficient. This is not surprising given that SaQAI uses saturation while the others use query rewriting. However, cleaning and saturating the ABox is not always possible (if the ABox cannot be modified). Moreover, such an approach is not compatible with the AR semantics, which avoids the loss of information that results from discarding all assertions involved in conflicts.</p><p>We can observe some high-level similarities with Du et al.'s system which also has a preprocessing phase that compiles the KB, then employs SAT solvers and uses a reachability analysis to identify a query-relevant portion of the KB to do query answering.</p><p>There are also a few systems for querying inconsistent relational databases. Most relevant to our work is EQUIP <ref type="bibr" target="#b48">(Kolaitis, Pema, &amp; Tan, 2013)</ref>, which reduces AR conjunctive query answering in the presence of primary key constraints to binary integer programming (BIP). Similarly to our system, EQUIP first computes the IAR-answers and the causes of the answers with their conflicts. The encoding for AR semantics consists in a first part that encodes the repairs, enforcing that exactly one tuple of each group of same-key tuple is selected, and a second part that ensures that the repair contains no cause. The main difference with CQAPri is that instead of building and solving one encoding for each answer, only one is built using variables to represent the different answers, so that setting them to 1 trivializes the equations related to the causes of this answer. The answers that do not hold under AR semantics are computed iteratively, by minimizing the sum of the answers variables, that are then set to 1 when found not AR, until the system becomes unsatisfiable. We considered using BIP rather than SAT solvers but were not convinced by our preliminary experiments. Some systems focus on cases where consistent query answering is tractable, for restricted types of constraints or queries, using first-order rewritings (ConQuer, <ref type="bibr">Fuxman &amp; Miller, 2005;</ref><ref type="bibr" target="#b40">Fuxman, Fazli, &amp; Miller, 2005)</ref> or conflict-hypergraphs (Hippo, <ref type="bibr">Chomicki et al., 2004a</ref><ref type="bibr" target="#b34">Chomicki et al., , 2004b))</ref>. Other systems handle more general constraints that can lead to dif-ferent kinds of repairs, since for databases it may be necessary to insert or modify tuples to restore consistency. For instance, ConsEx <ref type="bibr" target="#b56">(Marileo &amp; Bertossi, 2010)</ref> reduces AR query answering to answer set programming (ASP) by building repair programs such that there is a one-to-one correspondence between stable models and repairs. Experiments reported by <ref type="bibr" target="#b48">Kolaitis et al. (2013)</ref> show that EQUIP outperforms ConsEx on its restricted setting that is closer to our own.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2.2">Experimental Settings Involving Inconsistent DL-Lite KBs</head><p>The QuID benchmark QuID is evaluated using the LUBM TBox containing 43 concepts, 25 roles, 7 attributes and about 200 positive inclusions, approximated in DL-Lite by eliminating the inclusions that go beyond DL-Lite, then enriched with 10 negative inclusions, 5 identifications (that state that some sets of properties identify the instances of some basic concepts), and 3 denial constraints given by Boolean CQs (of the form ∃ y ψ( y), where ψ is a conjunction of atoms using variables from y) which have to be false.</p><p>Datasets are generated with the UBA Data Generator provided with LUBM, for 1, 5, 10 and 20 universities, leading to a size varying from about 100K to about 2 million assertions. For each of these consistent ABoxes, four inconsistent ABoxes are constructed by adding 1%, 5%, 10% and 20% of assertions that are in conflict. The main difference with our setting is the way conflicts are generated. Indeed, the original ABox produced by the generator is left consistent, while each assertion that is added is in conflict with others. In practice, for a growing n, the same n fresh individuals are assigned to all eleven concepts that appear in some negative inclusion, and the same n pairs of fresh individuals are assigned all five roles (or inverse roles) that appear in some negative inclusion. While such way of adding conflicts may make sense for evaluating the QuID system that implements IAR semantics, which only needs to ignore the assertions that are in some conflicts, it is not realistic at all because the new individuals are inserted in many concepts that are semantically very far from each other, like Person, Publication, Course, and Organization. We could therefore not use these datasets to evaluate CQAPri, since there is no chance obtaining query answer that hold under AR semantics but not under IAR semantics. <ref type="bibr">In Du et al.'s later work (2015)</ref> on abduction over inconsistent DL-Lite KBs, the Semintec and LUBM TBoxes without the non-DL-Lite axioms are used. The authors added negative inclusions to LUBM in a similar fashion to ours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Du et al.'s benchmark</head><p>Regarding data, Semintec has a small ABox of about 65K assertions and the number of universities used for LUBM datasets ranges from 1 to 100 as in our experimental setting. <ref type="bibr" target="#b36">Du et al. (2013)</ref> present a tool called Injector to insert conflicts in ABoxes. Given a consistent KB and a number of conflicts to be inserted, Injector randomly selects a functional role or an atomic concept that has disjoint atomic concepts. If the KB already entails assertions that correspond to that role or concept, Injector randomly selects such an assertion and adds an assertion that conflicts it: in the case of a functional role, it relates the corresponding individual of the ABox to a new individual with that role, and in case of concept assertions, it assigns the individual to one of the disjoint atomic concepts. Otherwise, Injector adds two assertions that are in conflict in the same way using fresh individuals. This way of adding conflicts is much more realistic than that of QuID. Even if it is similar in spirit to ours, since it tries to distribute randomly conflicts over the ABox, there are some differences. First, we randomly select assertions of the initial ABox rather than concepts or roles that may be contradicted, which leads to a repartition of the conflicts that respects the structure of the data (since there may be lots of assertions for some concepts and few or no assertions for others). Second, we do not use only atomic concepts to build contradictions but also unqualified existential role restrictions. Finally we take into account another kind of possible errors by switching role individuals. <ref type="bibr" target="#b38">Du et al. (2015)</ref> added 0 to 400 "conflicts" (i.e. assertions that contradict an original assertion, or inconsistent pairs of assertions) to the consistent ABoxes. We prefer to quantify the degree of inconsistency in terms of assertions involved in some conflicts rather than in terms of assertions added to the consistent ABox, since we can compute the ratio of conflicts (as we define them) of a real dataset, but not its ratio of erroneous facts. However, note that we added many more assertions than Du et al. for original datasets of the same size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Related Work on Explanation</head><p>We now discuss related work on explaining entailments and query (non-)answers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3.1">Justifications of Entailed Axioms</head><p>As mentioned in the introduction, there has been significant interest in equipping DL reasoning systems with explanation facilities. The earliest work proposed formal proof systems as a basis for explaining concept subsumptions <ref type="bibr" target="#b57">(McGuinness &amp; Borgida, 1995;</ref><ref type="bibr" target="#b23">Borgida, Franconi, &amp; Horrocks, 2000)</ref>, while the post-2000 literature mainly focuses on axiom pinpointing <ref type="bibr" target="#b67">(Schlobach &amp; Cornet, 2003;</ref><ref type="bibr" target="#b47">Kalyanpur, Parsia, Sirin, &amp; Hendler, 2005;</ref><ref type="bibr" target="#b45">Horridge, Parsia, &amp; Sattler, 2012)</ref>, in which the problem is to generate minimal subsets of the KB that yield a given (surprising or undesirable) consequence. Such subsets are often called justifications. It should be noted that work on axiom pinpointing has thus far focused on explaining entailed TBox axioms (or possibly ABox assertions), and in particular on TBox debugging by explaining unsatisfiable classes. In our work, we assume that the TBox has been properly debugged, so is consistent and correct, i.e. all consequences of the TBox are desirable. This work on axiom pinpointing can therefore be seen as a first step that allows us to be sure that the errors stem from the data.</p><p>For the lightweight DL EL+, justifications have been shown to correspond to minimal models of propositional Horn formulas and can be computed using SAT solvers <ref type="bibr" target="#b68">(Sebastiani &amp; Vescovi, 2009)</ref>; a polynomial algorithm has been proposed to compute one justification <ref type="bibr" target="#b10">(Baader, Peñaloza, &amp; Suntisrivaraporn, 2007)</ref>. In DL-Lite, the problem is simpler: all justifications can be enumerated in polynomial delay <ref type="bibr" target="#b62">(Peñaloza &amp; Sertkaya, 2010)</ref>.</p><p>Beside computing justifications efficiently, several works addressed the problem of making them understandable for the user, either by studying their cognitive complexity (Horridge, <ref type="bibr" target="#b44">Bail, Parsia, &amp; Sattler, 2011)</ref>, or by grouping justifications that have a similar structure to help to handle large number of justifications <ref type="bibr" target="#b11">(Bail, Parsia, &amp; Sattler, 2013)</ref>. Our experiments showed that a query answer can possess a very large number of explanations, many of which are quite similar in structure. It could therefore be interesting to investigate ways of improving the presentation of explanations, e.g. by identifying and grouping similar explanations as has been done for justifications, or by adopting a factorized representation (like in the work by <ref type="bibr" target="#b59">Olteanu &amp; Zavodny, 2012)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3.2">Explanation of Query Answers</head><p>The problem of explaining answers to conjunctive queries over DL-Lite KBs is considered by <ref type="bibr" target="#b22">Borgida et al. (2008)</ref> who provide a proof-theoretic approach to explaining positive answers. The proof of an answer involves the ABox assertions and TBox axioms used to derived it. As mentioned in Section 5, the difficulty of such proofs could provide an additional criteria for ranking explanations, and the work on the cognitive complexity of justifications may give clues on this difficulty.</p><p>Probably the closest related work is by <ref type="bibr" target="#b6">Arioua, Tamani, and Croitoru (2015)</ref> who introduce an argumentation framework for explaining positive and negative answers under the inconsistency-tolerant semantics ICR. Their motivations are quite similar to our own, and there are some high-level similarities in the definition of explanations (e.g. to explain positive ICR-answers, they consider sets of arguments that minimally cover the preferred extensions, whereas for positive AR-answers, we use sets of causes that minimally cover the repairs). They propose to compute one explanation for a positive or negative ICR-answer with a hitting set algorithm, applied either on the sets of supporting arguments (which correspond to our causes) present in each extension (corresponding to the repair), or on the set of attacking arguments (which correspond to the conflicts of the causes). Our work differs from theirs by considering different semantics and by providing detailed complexity analysis, in which we do not assume that the set of repairs is given, and an implemented prototype. Another argumentation framework has been proposed for ground BCQ explanation under IAR and brave semantics by <ref type="bibr">Arioua and Croitoru (2016a)</ref>. They consider that a brave-answer is explained if an argument supporting it has been found and that an IARanswer is explained if an argument without attacking argument has been found. Contrary to our work, the focus is not on the computation of the explanations, since the arguments are considered given, but on the characterization of the dialogue between a proponent and an opponent to the answer exchanging arguments, depending on the semantics under which it is entailed. The same kind of study has then been conducted for the AR semantics <ref type="bibr" target="#b3">(Arioua &amp; Croitoru, 2016b)</ref>. This framework has been implemented in the DALEK prototype <ref type="bibr" target="#b4">(Arioua, Croitoru, &amp; Buche, 2016)</ref>. To support the explanatory dialogue and build (counter)arguments, DALEK computes the set of conflicts of the KB in a similar way to our system, as well as the causes of the claim. However, the explanations themselves are not computed but result from the interaction between the user and the system.</p><p>Finally, we note that the problem of explaining query results has been studied in the database community (cf. <ref type="bibr" target="#b31">Cheney, Chiticariu, &amp; Tan, 2009</ref>, for a survey). The lineage of a query answer is the set of tuples of the database that contribute to produce the answer, i.e. the union of the images for the answer. The why-provenance corresponds to the images and the minimal witness basis to the set of causes of the answer. The how-provenance describes how a result was produced from the tuples. The where-provenance provides the location (i.e. relation, tuple and attribute) of the values in the answer tuple.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3.3">Query Abduction</head><p>Since we defined explanations for a negative AR-or IAR-answer using assertions of the ABox that conflict its causes, defining explanations for negative brave-answers (which have no cause) would significantly differ in spirit. The problem of explaining negative answers has been primarily seen as the problem of finding a minimal dataset to be added to the data to get the missing answers, i.e. as query abduction, both in the DL literature (see e.g. <ref type="bibr" target="#b29">Calvanese et al., 2013;</ref><ref type="bibr">Du et al., 2014, for DL-Lite and</ref><ref type="bibr" target="#b72">Wang, Chitsaz, Wang, and</ref><ref type="bibr">Du, 2015</ref>, for ELH ⊥ ) and in the database arena (see e.g. <ref type="bibr" target="#b43">Herschel &amp; Hernández, 2010)</ref>. In both settings, restrictions on the signature of the explanation are allowed. Note that a different approach related to query debugging was proposed in the database context <ref type="bibr" target="#b16">(Bidoit, Herschel, &amp; Tzompanaki, 2014)</ref>, and focuses on finding subqueries responsible for pruning the missing answer from a query result. This approach is less relevant to our setting since conjunctive queries over DL KBs are much simpler and less error-prone than SQL queries. <ref type="bibr" target="#b29">Calvanese et al. (2013)</ref> studied the complexity of the decision problems related to explaining negative answers in DL-Lite (recognition and existence of an explanation, necessity and relevance of an assertion). <ref type="bibr" target="#b37">Du et al. (2014)</ref> presented an implementation that computes explanations in DL-Lite and later treated the case of inconsistent <ref type="bibr">KBs (2015)</ref>. In this case, an explanation is a set of assertions to add that will lead to the answer holding under IAR semantics. These three papers tackle the issue of preferred explanations in different ways. <ref type="bibr">Calvanese et al. consider subset-or cardinality-minimal explanations. Du et al.</ref> introduce the notion of representative explanation, which is an explanation that is minimal (when allowing renaming of fresh individuals to compare explanations) and is not subsumed by any other (e.g. if Advise(ann, ann), Advise(ann, bob), and Advise(ann, ind) where ind is a fresh individual are the explanations for ann not being an answer to ∃yAdvise(x, y), the last one is the unique representative explanation). Du et al. also consider cardinality-minimal preferred explanations for a preference relation based on cardinality-preserving substitutions.</p><p>We could build on the work on query abduction to define explanations for negative brave-answers as minimal sets of assertions E such that T , A ∪ E |= brave q( a). Note that if we define explanations in this way, then E is an explanation for q( a) being a negative brave answer in T , A iff E is an inclusion-minimal explanation for q( a) being a negative answer in T P , A , where T P is the set of positive inclusions in T , and T , A ∪ E |= brave q( a). Since <ref type="bibr">Du et al. have</ref> shown that computing all minimal explanations is polynomial w.r.t. data complexity, we can build all explanations for T , A |= brave q( a) by first computing all minimal explanations for T P , A |= q( a), and then pruning those that does not respect the condition T , A ∪ E |= brave q( a). It follows that all of the decision and generation problems that we consider are in PTime w.r.t. data complexity, and the implementation would be a straightforward adaptation of the method of Du et al. However, as argued by <ref type="bibr">Du et al.,</ref> the number of such explanations can be too large to be computed in practice, and it would probably be relevant to adopt their notion of representative explanations.</p><p>The idea of representative explanation could also be used for presenting the notions of explanations proposed in the present paper, by treating the individuals that are mapped to existentially quantified variables in the same way as Du et al. treat fresh individuals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">Conclusion and Perspectives</head><p>Prior work on inconsistency-tolerant querying in DL-Lite left open whether the IAR constitutes a good approximation of AR semantics, as well as whether the AR semantics can be feasibly computed in practice. Encouraged by the performance of modern-day SAT solvers, we proposed a practical SAT-based approach for query answering in DL-Lite R under the AR semantics, using the IAR and brave semantics as tractable lower and upper bounds. We then devised a framework for explaining query (non-)answers over DL KBs under these three semantics and studied the computational properties of our framework, focusing on DL-Lite R . For intractable explanation tasks, we exhibited tight connections with variants of propositional satisfiability. We implemented both inconsistency-tolerant query answering and the explanation framework in our CQAPri system and built a benchmark for inconsistency-tolerant query answering upon a well-established DL-Lite R benchmark. Our experiments show that CQAPri scales up to large ABoxes for realistic to challenging ratios of conflicting assertions. We thus show that (i) the AR semantics can be computed in practice and that this is due to the fact that the IAR semantics often constitutes a very good approximation of the AR semantics, and (ii) our explanation framework is of practical interest since explanations of query (non-)answers are generated fast overall.</p><p>We focused on DL-Lite R for simplicity and because it is the basis for the W3C standard OWL 2 QL. Most of our results actually hold for other dialects of the DL-Lite family, but the problem of reasoning with the inconsistency-tolerant semantics we consider becomes considerably harder for many other well-known DLs. Regarding DL-Lite dialects, we recall that DL-Lite core is the core language of the family and amounts to DL-Lite R without role inclusions, and DL-Lite F extends DL-Lite core with functionality axioms on roles or on their inverses of the form (funct S). DL-Lite A extends DL-Lite core with both role inclusions and functionality with the restriction that functional roles cannot be used positively on the right-hand side of a role inclusion, and also allows for attributes (binary relations between objects and values from concrete domains, e.g. strings, integers). The complexity of query answering, consistency checking and computation of the causes for a query and the conflicts of a knowledge base are the same for all these languages, and the size of the conflicts is at most two in all cases. Therefore, all complexity upper bounds presented hold for DL-Lite core , DL-Lite R , DL-Lite F and DL-Lite A . Moreover, since all our algorithms only need the causes and conflicts, they can be used without any modification. To make our prototype CQAPri able to handle KBs expressed in DL-Lite F or DL-Lite A , we simply need to modify the computation of the conflicts of the knowledge base that currently only search for violation of disjointness TBox axioms in order to also find pairs of assertions that contradict functionality axioms (as well as datatype restrictions, in the case of DL-Lite A ). Regarding complexity lower bounds, all hardness results of Section 5 hold for KBs expressed in DL-Lite core , hence for these four DL-Lite dialects. For Horn versions of DL-Lite, which allow the use of conjunctions in the concepts appearing in the left-hand side of TBox inclusions, the size of causes is not bounded by |q| anymore but is bounded by |q| * |T |, and the size of conflicts is bounded by |T |, so conflicts and causes can still be computed in polynomial time w.r.t. data complexity. For AR (non)-answers, the extension of the SAT encoding presented in Remark 4.12 can be used, and the MUSes of ϕ 1 ¬q w.r.t. ϕ 2 ¬q ∧ ϕ cons would allow us to generate the explanations for AR-answers, while the minimal models of ϕ 1 ¬q ∧ ϕ 2 ¬q ∧ ϕ cons (resp. of ϕ 1 ¬q ∧ ϕ 2 ¬q ) can be connected to the explanations of negative AR (resp. IAR) answers. It is also possible to adapt the rewritings presented in the appendix to obtain the AC 0 upper bounds by taking into account the higher possible size of the conflicts. When moving to other DLs outside the DL-Lite family, query answering under the AR semantics, or even the IAR and brave semantics, becomes hard <ref type="bibr" target="#b64">(Rosati, 2011)</ref>. For ALC, which is the prototypical expressive description logic, query answering under these three semantics is in the second level of the polynomial hierarchy w.r.t. data complexity, while it is coNP-complete under classical semantics. Even for EL ⊥ , which extends the lightweight DL EL with the ability to express disjointness using ⊥, query answering under the IAR and brave semantics is intractable w.r.t. data complexity, while query answering is in PTime under classical semantics. However, for EL ⊥ , query answering under AR semantics has the same complexity as in DL-Lite. It would be interesting to see if query answering under these semantics can be done efficiently for EL ⊥ , since the IAR semantics does not provide a tractable approximation of AR in this setting.</p><p>Regarding the performance of inconsistency-tolerant query answering, we see two possible directions to investigate. First, we could try to lower the cost of query evaluation. Indeed, our approach is based on the computation of the causes of the answers, which are obtained straightforwardly using the UCQ-rewritings of the initial queries. However, database management systems perform poorly on large UCQs, and it is not uncommon for UCQ-rewritings to be (very) large (there were more than 200,000 CQs in the rewritings of some queries of our benchmark!). That is why FO-rewritings that can be evaluated more efficiently in practice than the standard UCQs have been proposed (see e.g. <ref type="bibr" target="#b65">Rosati &amp; Almatelli, 2010;</ref><ref type="bibr" target="#b39">Eiter, Ortiz, Simkus, Tran, &amp; Xiao, 2012;</ref><ref type="bibr" target="#b70">Thomazo, 2013;</ref><ref type="bibr" target="#b26">Bursztyn, Goasdoué, &amp; Manolescu, 2015</ref><ref type="bibr" target="#b25">, 2016)</ref>. To improve the performance of our system for queries that have a long evaluation time, we could try to use such optimized techniques to find the candidate answers, and then evaluate only the Boolean UCQ-rewritings instantiated with these answers to retrieve their causes. Indeed, such Boolean specializations would typically contain fewer variables and so would be easier to evaluate than the original UCQs. An open question is whether it is possible to compute the causes more directly, without employing UCQ-rewritings. Second, we could try alternative methods for AR query answering based on the pre-computation of the set of facts that hold under AR semantics that could provide some AR answers without using the SAT encoding, or by using other lower and upper approximations of AR semantics in place of the IAR and brave semantics.</p><p>There are several natural directions to explore related to explaining query (non-)answers. First, it would be useful to accompany our explanations with details on the TBox reasoning involved, using the work by <ref type="bibr" target="#b22">Borgida et al. (2008)</ref> on proofs of positive answers as a starting point. The difficulty of such proofs could provide an additional criteria for ranking explanations (cf. the work on the cognitive complexity of justifications by <ref type="bibr" target="#b44">Horridge et al., 2011)</ref>. Second, our experiments showed that an answer can have a huge number of explanations, many of which are quite similar in structure. We thus plan to investigate ways of improving the presentation of explanations, e.g. by identifying and grouping similar explanations (cf. work on comparing justifications by <ref type="bibr" target="#b11">Bail et al., 2013)</ref>, or by defining a notion of representative explanation <ref type="bibr" target="#b37">(Du et al., 2014)</ref>. Third, we plan to experiment with other methods of generating explanations of negative answers, by comparing alternative encodings and using tools for computing hitting sets or diagnoses.</p><p>The construction is analogous but simpler when α is a concept atom.</p><p>For the second statement, observe that some assignments may yield a consistent image while others lead to an inconsistent image. We therefore need to consider the different types of images that can be generated from Ψ by applying an assignment. To this end, we consider all possible equivalence relations ≡ 1 , . . . , ≡ M on the terms in Ψ such that no two individuals belong to the same equivalence class. Intuitively, an equivalence relation ≡ i represents a class of assignments, with t 1 ≡ i t 2 meaning that t 1 and t 2 are mapped to the same individual. For each equivalence relation ≡ i , the induced CQ Ψ i is obtained from Ψ by unifying all terms that occur in the same equivalence class of ≡ i . The CQs Ψ i represent all possible images of Ψ under an assignment. Finally, we let EqUnsat be the set of all ≡ i such that A Ψ i is T -inconsistent, and we set</p><formula xml:id="formula_48">incons(Ψ) = ≡ i ∈EqUnsat ( t≡ i t t = t ∧ t ≡ i t t = t )</formula><p>To see why this formula gives the desired result, consider an assignment π with π(Ψ) ⊆ A. If I A |= π incons(Ψ), then there must exist an equivalence relation</p><formula xml:id="formula_49">≡ i ∈ EqUnsat such that π(t) = π(t ) (resp. π(t) = π(t )) whenever t ≡ i t (resp. t ≡ i t ). It follows that π(Ψ) is isomorphic to A Ψ i . As A Ψ i is T -inconsistent,</formula><p>and inconsistency is preserved under isomorphisms, π(Ψ) is also T -inconsistent. Conversely, suppose π(Ψ) is T -inconsistent, and let ≡ i be the equivalence relation on the terms of Ψ obtained by putting t, t in the same equivalence class whenever π(t) = π(t ) (here we assume π maps individuals to themselves). By construction, A Ψ i is isomorphic to π(Ψ), so A Ψ i is T -inconsistent. It follows that ≡ i belongs to EqUnsat, so π satisfies the disjunct of incons(Ψ) corresponding to ≡ i , yielding I A |= π incons(Ψ). <ref type="formula">3</ref>) is an immediate corollary of (2), as we can set cons(Ψ) = ¬incons(Ψ). For (4), the construction is broadly similar to that of (2). We consider all possible equivalence relations ≡ 1 , . . . , ≡ K over the set of terms in Ψ and the individuals occurring in q( a), again with the restriction that each class can contain at most one individual. As before, each ≡ i induces a corresponding CQ Ψ i . We let EqMatch be the set of ≡ i such that T , A Ψ i |= q( a). We then set</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statement (</head><formula xml:id="formula_50">hasMatch(Ψ) = ≡ i ∈EqMatch ( t≡ i t t = t ∧ t ≡ i t t = t )</formula><p>Correctness can be shown using a similar argument to that for (2). The only relevant difference is that since q( a) contains individuals, we must argue that π(Ψ) and A Ψ i are isomorphic w.r.t. an isomorphism that is the identity on the individuals in q( a) (this is why we consider equivalence relations involving the individuals in q( a)).</p><p>Finally, let us prove statement (5). Unlike the previous formulas, which only contained (in)equality atoms (and whose satisfaction depended only on π rather than the contents of the ABox), to check whether an image has a conflict in the ABox, we will need to verify whether certain assertions occur in the ABox. To define hasConflict(Ψ), let q T unsat = Γ 1 ∨ . . . ∨ Γ L be the UCQ-rewriting of unsatisfiability constructed in the manner described in Section 2. We recall that each CQ Γ i in q T unsat contains at most 2 atoms, and by repeating atoms, we may assume they all contain precisely 2 atoms, so Γ i = ∃ z γ 1 i ∧ γ 2 i . We may also assume for convenience that every Γ i has the same initial existential quantifier: ∃ z. The desired formula can then be defined as follows:</p><formula xml:id="formula_51">hasConflict(Ψ) = L i=1 2 j=1 ∃ z γ 1 i ∧ γ 2 i ∧ contains(Ψ, γ j i )∧ contains(γ 1 i , γ 2 i ) ∨ (cons(γ 1 i ) ∧ cons(γ 2 i ))</formula><p>The first line of the formula holds if for some i, π(Γ i ) is present in the ABox and one of its assertions occurs in π(Ψ). As Γ i is a disjunct of q T unsat , we know that π(Γ i ) is T -inconsistent. The second line ensures that π(Γ i ) is a conflict, which trivially holds if it consists of a single assertion (which we can test using contains(γ 1 i , γ 2 i )) or if each of the component assertions is T -consistent (here we can use the cons formula from item (2)). Correctness follows from the definition of conflicts and the properties given in items (1) and ( <ref type="formula">2</ref>).</p><p>Next, we use the preceding building blocks to construct a formula that identifies causes:</p><formula xml:id="formula_52">isCause(Ψ) = Ψ ∧ cons(Ψ) ∧ hasMatch(Ψ) ∧ γ∈Ψ (contains(Ψ \ {γ}, γ) ∨ ¬hasMatch(Ψ \ {γ}))</formula><p>This formula closely follows the definition of causes: it checks that the assertions in (the image of) Ψ are present in the ABox, that they are T -consistent and entail the query answer, and that the query answer cannot be obtained from any proper subset. To verify the latter, for each atom in Ψ, we require that either removing γ does not change the image of the CQ (which can be the case when some variables are mapped to the same individuals) or the removal of the atom leads to the query answer no longer holding. The following lemma, which is a straightforward consequence of the definition of causes and items (2) and (4) of Lemma A.1, states that the formula has the intended meaning: Lemma A.2. For every ABox A and variable assignment π:</p><formula xml:id="formula_53">I A |= π isCause(Ψ) iff π(Ψ) is a cause of q( a) in the KB T , A .</formula><p>For explanations of negative AR-and IAR-answers, we will need to be able to check whether a set of assertions conflicts all the causes of q( a). To do so, we introduce the following formula, where E is the set of assertions we wish to test:</p><formula xml:id="formula_54">conflictsAllCauses(E) = Ψ( z)∈Q ∀ z (isCause(Ψ( z)) → α∈E, T ,{α} |=⊥ incons(Ψ( z) ∧ α))</formula><p>The preceding formula considers every CQ Ψ( z) in the UCQ-rewriting of q( a) and requires that for every possible instantiation of z, if the resulting set of assertions is a cause, then it is conflicted by some T -consistent assertion in the set E. Correctness is given in the following lemma.</p><p>Lemma A.3. For every ABox A, subset E ⊆ A, and variable assignment π:</p><formula xml:id="formula_55">I A |= π conflictsAllCauses(E) iff for every C ∈ causes(q( a), T , A ), there is α ∈ E such that {α} is T -consistent and C ∪ {α} is T -inconsistent.</formula><p>Proof. First suppose I A |= π conflictsAllCauses(E), and let C ∈ causes(q( a), T , A ). By Proposition 4.7, there exists Ψ( z) ∈ Q such that C is the image of Ψ( z) under some assignment of the variables z. From I A |= π conflictsAllCauses(E), it follows that there exists a T -consistent assertion α ∈ E such that C ∪ {α} is T -inconsistent.</p><p>For the other direction, suppose that for every C ∈ causes(q( a), T , A ), there is α</p><formula xml:id="formula_56">C ∈ E such that {α C } is T -consistent and C ∪ {α C } is T -inconsistent. Consider some Ψ( z) ∈ Q</formula><p>and some assignment ρ of the variables z, and set S = ρ(Ψ( z)). If S is not a cause, then the implication for Ψ( z) and ρ is trivially satisfied. If S ∈ causes(q( a), T , A ), then we can use the assertion α S to show that α∈E, T ,{α} |=⊥ incons(Ψ( z) ∧ α) is satisfied.</p><p>We will also require a formula that checks whether the set of conflicts associated with one cause is contained in the set of conflicts of another cause. To this end, given two CQs Ψ and Ψ , we define a formula compareConflicts(Ψ, Ψ ) as follows:</p><formula xml:id="formula_57">A∈Σ C ∀v (A(v) ∧ cons(A(v)) ∧ incons(Ψ ( z ) ∧ A(v))) → incons(Ψ( z) ∧ A(v)) ∧ R∈Σ C ∀v,v (R(v, v )∧cons(R(v, v ))∧incons(Ψ ( z ) ∧ R(v, v ))) → incons(Ψ( z) ∧ R(v, v ))</formula><p>The first line amounts to verifying that every T -consistent concept assertion A(a) in the ABox that conflicts the image of the second CQ also conflicts the image of the first CQ. The second line is similar, but formulated for role assertions. The next lemma formally states the properties of this formula: Lemma A.4. Let Ψ and Ψ be CQs. For every ABox A and variable assignment π such that π(Ψ) and π(Ψ ) are T -consistent subsets of A:</p><formula xml:id="formula_58">I A |= π compareConflicts(Ψ, Ψ ) iff confl(π(Ψ ), T , A ) ⊆ confl(π(Ψ), T , A ).</formula><p>Proof. Fix an ABox A and variable assignment π such that π(Ψ) and π(Ψ ) are T -consistent subsets of A. First suppose I A |= π compareConflicts(Ψ, Ψ ). Then there exists A ∈ Σ C or R ∈ Σ R such that the corresponding subformula is not satisfied. Assume this is the case for R ∈ Σ R (the argument is analogous for the case of A ∈ Σ C ). Then there is some</p><formula xml:id="formula_59">R(a, b) ∈ A such that {R(a, b)} is T -consistent, π(Ψ ( z )) ∪ {R(a, b)} is T -inconsistent, and π(Ψ( z )) ∪ {R(a, b)} is T -consistent. Thus, R(a, b) is a conflict for π(Ψ ) but not for π(Ψ), proving confl(π(Ψ ), T , A ) ⊆ confl(π(Ψ), T , A ).</formula><p>For the second direction, suppose confl(π(Ψ ), T , A ) ⊆ confl(π(Ψ), T , A ), as witnessed by the assertion R(a, b) which conflicts with π(Ψ ) but not for π(Ψ) (the argument is analogous if A(a) is the witness assertion). It follows that the subformula for role R and assignment π to the variables z is not satisfied in I A , so I A |= π compareConflicts(Ψ, Ψ ).</p><p>With these building blocks in hand, we can now proceed to the definition of the desired formulas for testing recognition, relevance, and necessity.</p><p>Positive brave-answers As the explanations for positive brave-answers are causes, we can use the formula for identifying causes to recognize positive brave-answers:</p><formula xml:id="formula_60">Q rec brave (E) = isCause(E)</formula><p>For relevance, we know from Proposition 4.7 that every cause is an image of a CQ appearing as a disjunct in the rewriting Q. We can thus take a disjunction over all CQs Ψ( z) in Q and test whether there is some assignment to the variables z that yields an image that is a cause containing the considered assertion:</p><formula xml:id="formula_61">Q rel brave (α) = Ψ( z)∈Q ∃ z (isCause(Ψ( z)) ∧ contains(Ψ( z), α))</formula><p>A similar idea can be used for the necessity problem. An assertion α is necessary if there is no cause that omits α. Thus, we take a conjunction over all CQs Ψ( z) in Q and check that for every assignment, if the resulting set of assertions is a cause, then it contains α.</p><formula xml:id="formula_62">Q nec brave (α) = Ψ( z)∈Q ∀ z (isCause(Ψ( z)) → contains(Ψ( z), α))</formula><p>Positive IAR-answers A first-order formula for recognizing positive IAR-answers is easily obtained by combining the earlier formulas for identifying causes and determining whether a set of assertions has a conflict:</p><formula xml:id="formula_63">Q rec IAR (E) = isCause(E) ∧ ¬hasConflict(E)</formula><p>For relevance, we proceed as for the brave semantics: take a disjunction over all CQs in Q and check whether one such CQ has an image that is a cause that is without conflicts. This yields the following formula:</p><formula xml:id="formula_64">Q rel IAR (α) = Ψ( z)∈Q ∃ z (isCause(Ψ( z)) ∧ contains(Ψ( z), α) ∧ ¬hasConflict(Ψ( z)))</formula><p>For necessity, we can again follow the brave case, considering all CQs in the rewriting Q and requiring that every image that is a cause and is without conflicts contains α:</p><formula xml:id="formula_65">Q nec IAR (α) = Ψ( z)∈Q ∀ z (isCause(Ψ( z)) → hasConflict(Ψ( z)) ∨ contains(Ψ( z), α))</formula><p>Negative AR-answers For negative AR-answers, we consider only the recognition task, as relevance and necessity were proven intractable. The following formula expresses the conditions for a set of assertions to be an explanation for a negative AR-answer:</p><formula xml:id="formula_66">Q rec ¬AR (E) = E ∧ cons(E) ∧ conflictsAllCauses(E)</formula><p>Correctness immediately follows from Lemmas A.2 and A.3.</p><p>Negative IAR-answers To recognize explanations for negative IAR-answers, we can simply drop the consistency requirement from the formula for the AR case:</p><formula xml:id="formula_67">Q rec ¬IAR (E) = E ∧ conflictsAllCauses(E)</formula><p>For the relevance problem, we exploit the characterization given in Proposition 5.22, which states that an assertion α is relevant iff there exists a cause C such that α conflicts C, and for every other cause C , if confl(C , T , A ) ⊆ confl(C, T , A ), then α ∈ confl(C , K). We translate this condition into first-order logic as follows:</p><formula xml:id="formula_68">Q rel ¬IAR (α) = Ψ( z)∈Q ∃ z isCause(Ψ( z)) ∧ incons(Ψ( z) ∧ α) ∧ Ψ ( z )∈Q ∀ z (isCause(Ψ ( z )) ∧ compareConflicts(Ψ, Ψ )) → incons(Ψ ( z ) ∧ α)</formula><p>In the first line, we take a disjunction over all CQs in Q (representing the choices for the shape of the first cause) and check whether there is some assignment such that the resulting set of assertions, call it C, is a cause satisfying the preceding requirements. We may assume that {α} is T -consistent, since otherwise α cannot be relevant (so we could simply set Q rel ¬IAR (α) = ⊥). This, together with the fact that C is a cause (hence T -consistent), means that α conflicts with C iff C ∪ {α} is T -inconsistent, which is checked in the first line of the formula. In the second and third lines, we verify that every cause C satisfied the aforementioned conditions. To do so, we take the conjunction over all CQs in Q (in order to capture all possible causes), and ask that for every assignment that yields a cause whose set of conflicts is contained in the conflicts of C has the assertion α as a conflict. Correctness follows from Proposition 5.22, Lemmas A.1, A.2 and A.4.</p><p>For the necessity task, we make use of the characterization given in Proposition 5.21, which states that an assertion α appears in all explanations of a negative IAR-answer iff there exists a cause for that answer that is only conflicted by α. We thus create a formula that checks for the existence of a cause that is conflict with the assertion α and such that every other assertion that is not equal to α (either because it uses a different concept or role name, or because it uses different individuals), is consistent with the cause. The formulation is slightly different depending on whether α is a concept or role assertion. We give here the formulation for the case of role assertions:         u1c1 u1c20 u1c50 #ans 0.01 <ref type="bibr">[0.01, 0.1[ [0.1, 1[ &gt;1 #ans &lt;0.01 [0.01, 0.1[ [0.1, 1[ &gt;1 #ans &lt;0.01 [0.01, 0.1[ [0.1,</ref>   Table 10: Distribution of the times (in second) for explaining K |= S q( a) in Case 1. u100c1 u100c20 u100c50 #ans 0.01 <ref type="bibr">[0.01, 0.1[ [0.1, 1[ &gt;1 #ans &lt;0.01 [0.01, 0.1[ [0.1, 1[ &gt;1 #ans &lt;0.01 [0.01, 0.1[ [0.1,</ref>    </p><formula xml:id="formula_69">Q nec ¬IAR (R(a, b)) = Ψ( z)∈Q ∃ z isCause(Ψ( z)) ∧ ¬cons(Ψ( z) ∪ {R(a, b)}) ∧ ∀v, v ((v = a ∧ v = b) ∨ ¬R(v, v ) ∨ cons(Ψ( z) ∪ {R(v, v )})) ∧ P ∈Σ R ,P =R ∀v, v (¬P (v, v ) ∨ cons(Ψ( z) ∪ {P (v, v )})) ∧ B∈Σ C ∀v (¬B(v) ∨ cons(Ψ( z) ∪ {B(v)}))</formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>a, b ∈ N I . We use Ind(A) to refer to the set of individuals that appear in A. The TBox (ontology) consists of a set of axioms whose form depends on the DL in question. In DL-Lite R , TBox axioms are concept inclusions B C and role inclusions of the form S Q built according to the following syntax, where A ∈ N C and R ∈ N R : B := A | ∃S, C := B | ¬B, S := R | R -, Q := S | ¬S</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>and each a ∈ N I to a I ∈ ∆ I , with a I = b I for a = b (the last condition is the well known Unique Names Assumption, or UNA 3 ). The function • I is straightforwardly extended to general concepts and roles, e.g. (R -) I = {(c, d) | (d, c) ∈ R I } and (∃Q) I = {c | ∃d : (c, d) ∈ Q I }.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Example 4 .</head><label>4</label><figDesc>The inconsistent KB K * has the following three repairs: R 1 = {Postdoc(ann), Teach(ann, c 1 ), Teach(ann, c 2 ), Teach(ann, c 3 )} R 2 = {AProf(ann), Advise(ann, bob), Teach(ann, c 1 ), Teach(ann, c 2 ), Teach(ann, c 3 )} R 3 = {FProf(ann), Advise(ann, bob), Teach(ann, c 1 ), Teach(ann, c 2 ), Teach(ann, c 3 )}</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Example 18 .</head><label>18</label><figDesc>Consider the KB K = T , A defined as follows: T = {∃Advise Prof, Prof Employee, Postdoc Employee, Prof ¬Postdoc, ∃WorkFor Employee, ∃WorkFor -Department, Employee ¬Department, ∃TakeCourse -Course, ∃Advise -Person, Course ¬Person} A = {Postdoc(ann), Advise(ann, bob), Advise(ann, carl), Teach(ann, c 1 ), TakeCourse(c 2 , carl), WorkFor(ann, dpt), WorkFor(dpt, dan)} This KB has the following four conflicts: {Postdoc(ann), Advise(ann, bob)} {Postdoc(ann), Advise(ann, carl)}, {Advise(ann, carl), TakeCourse(c 2 , carl)} {WorkFor(ann, dpt), WorkFor(dpt, dan)} giving rise to the following repairs: R 1 = {Postdoc(ann), Teach(ann, c 1 ), TakeCourse(c 2 , carl), WorkFor(ann, dpt)} R 2 = {Advise(ann, bob), Advise(ann, carl), Teach(ann, c 1 ), WorkFor(ann, dpt)} R 3 = {Advise(ann, bob), TakeCourse(c 2 , carl), Teach(ann, c 1 ), WorkFor(ann, dpt)} R 4 = {Postdoc(ann), Teach(ann, c 1 ), TakeCourse(c 2 , carl), WorkFor(dpt, dan)} R 5 = {Advise(ann, bob), Advise(ann, carl), Teach(ann, c 1 ), WorkFor(dpt, dan)} R 6 = {Advise(ann, bob), TakeCourse(c 2 , carl), Teach(ann, c 1 ), WorkFor(dpt, dan)}</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure5: Time in seconds for query answering w.r.t. the size of the ABox for three ratios of conflicts (about 4%, 30%, and 45% of assertions in some conflict). For readability, the center and right columns focus on the queries whose answering times are lower and whose behaviours are thus not visible in the left column.</figDesc><graphic coords="66,90.00,436.65,141.74,141.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Time in seconds for query answering w.r.t. the ratios of conflicts for three ABox sizes (about 76 thousand, 2 million, and 10 million assertions). The center and right columns focus on the queries whose answering times are lower and whose behaviours are thus not visible in the left column.</figDesc><graphic coords="67,90.00,436.65,141.74,141.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Proportion of time spent by CQAPri in the different phases of query answering on 9 ABoxes. The two lower bars are the time for rewriting the query and executing the rewritten query to get candidate answers, and the two upper bars represent the time needed to classify such answers, by identifying the IAR-and non-brave-answers in a first step ('sure/inconsistent' in the legend), then the AR-answers ('likely answers').</figDesc><graphic coords="68,90.00,429.87,141.74,141.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 :</head><label>8</label><figDesc>Figure8: Time in seconds for explaining all query answers w.r.t. the size of the ABox for three ratios of conflicts (about 4%, 30%, and 45% of assertions involved in some conflict). The center and right columns focus on the queries whose answering times are lower and whose behaviours are thus not visible in the left column.</figDesc><graphic coords="72,94.02,435.22,138.90,138.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Time in seconds for explaining all query answers w.r.t. the ratios of conflicts for three ABox sizes (about 76 thousand, 2 million, and 10 million assertions). The center and right columns focus on the queries whose answering times are lower and whose behaviours are thus not visible in the left column.</figDesc><graphic coords="73,94.02,435.23,138.90,138.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Proportion of time spent by CQAPri in the different phases of query answers explanation on 9 ABoxes of differing sizes and proportions of assertions in conflicts. The two lower bars are the time for rewriting the query and executing the rewritten query to get candidate answers, the middle bar is the time needed to classify such answers, and the two upper bars give the added cost of generating explanations, which is divided into the time spent computing the causes by pruning the non-minimal causes and the time needed to compute the explanations from the causes and conflicts.</figDesc><graphic coords="74,94.02,414.90,138.90,138.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>01 [0.01, 0.1[ [0.1, 1[ &gt;1 #ans &lt;0.01 [0.01, 0.1[ [0.1, 1[ &gt;1 #ans &lt;0.01 [0.01, 0.1[ [0.1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>01 [0.01, 0.1[ [0.1, 1[ &gt;1 #ans &lt;0.01 [0.01, 0.1[ [0.1, 1[ &gt;1 #ans &lt;0.01 [0.01, 0.1[ [0.1Table 11: Distribution of the times (in second) for explaining K |= S q( a) in Case 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>01 [0.01, 0.1[ [0.1, 1[ &gt;1 #ans &lt;0.01 [0.01, 0.1[ [0.1, 1[ &gt;1 #ans &lt;0.01 [0.01, 0.1[ [0.1Table11: Distribution of the times (in second) for explaining K |= S q( a) in Case 2. u1c1 u1c20 u1c50 #ans 0.01 [0.01, 0.1[ [0.1, 1[ &gt;1 #ans &lt;0.01 [0.01, 0.1[ [0.1, 1[ &gt;1 #ans &lt;0.01 [0.01, 0.1[ [0.101 [0.01, 0.1[ [0.1, 1[ &gt;1 #ans &lt;0.01 [0.01, 0.1[ [0.1, 1[ &gt;1 #ans &lt;0.01 [0.01, 0.1[ [0.1, 101 [0.01, 0.1[ [0.1, 1[ &gt;1 #ans &lt;0.01 [0.01, 0.1[ [0.1, 1[  &gt;1 #ans &lt;0.01 [0.01, 0.1[ [0.1, 1[ &gt;1   </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="62,93.40,192.48,425.20,342.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>* † upper bounds hold for ranking criteria that can be decided in PTime ‡ lower bounds hold for smallest disjunction or fewest assertions Data complexity results for explanations of query answers in DL-Lite R .</figDesc><table /><note><p>* lower bounds hold for cardinality-minimal explanations</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table><row><cell>id</cell><cell cols="6">shape #atoms #variables #constants #rewritings rew.time (ms)</cell></row><row><cell>q1</cell><cell>chain</cell><cell>2</cell><cell>2</cell><cell>0</cell><cell>80</cell><cell>4</cell></row><row><cell>q2</cell><cell>chain</cell><cell>2</cell><cell>2</cell><cell>0</cell><cell>44</cell><cell>3</cell></row><row><cell>q3</cell><cell>tree</cell><cell>3</cell><cell>2</cell><cell>1</cell><cell>58</cell><cell>4</cell></row><row><cell>q4</cell><cell>dag</cell><cell>7</cell><cell>6</cell><cell>0</cell><cell>25</cell><cell>3</cell></row><row><cell>q5</cell><cell>dag</cell><cell>5</cell><cell>2</cell><cell>1</cell><cell>6,401</cell><cell>88</cell></row><row><cell>q6</cell><cell>dag</cell><cell>5</cell><cell>3</cell><cell>1</cell><cell>8,240</cell><cell>742</cell></row><row><cell>q7</cell><cell>tree</cell><cell>3</cell><cell>2</cell><cell>1</cell><cell>450</cell><cell>7</cell></row><row><cell>q8</cell><cell>tree</cell><cell>2</cell><cell>2</cell><cell>1</cell><cell>155</cell><cell>4</cell></row><row><cell>q9</cell><cell>dag</cell><cell>6</cell><cell>4</cell><cell>0</cell><cell>202,579</cell><cell>15,917</cell></row><row><cell>q10</cell><cell>dag</cell><cell>6</cell><cell>3</cell><cell>1</cell><cell>202,710</cell><cell>33,865</cell></row><row><cell cols="2">q11 chain</cell><cell>2</cell><cell>2</cell><cell>0</cell><cell>35</cell><cell>3</cell></row><row><cell cols="2">q12 atomic</cell><cell>1</cell><cell>1</cell><cell>0</cell><cell>44</cell><cell>3</cell></row><row><cell cols="2">q13 atomic</cell><cell>1</cell><cell>1</cell><cell>0</cell><cell>44</cell><cell>3</cell></row><row><cell>q14</cell><cell>dag</cell><cell>6</cell><cell>3</cell><cell>0</cell><cell>23</cell><cell>3</cell></row><row><cell cols="2">q15 chain</cell><cell>3</cell><cell>2</cell><cell>0</cell><cell>2</cell><cell>3</cell></row><row><cell>q16</cell><cell>dag</cell><cell>8</cell><cell>4</cell><cell>0</cell><cell>3,887</cell><cell>124</cell></row><row><cell cols="2">q17 chain</cell><cell>6</cell><cell>3</cell><cell>0</cell><cell>14,700</cell><cell>190</cell></row><row><cell>q18</cell><cell>tree</cell><cell>5</cell><cell>3</cell><cell>0</cell><cell>667</cell><cell>13</cell></row><row><cell>q19</cell><cell>dag</cell><cell>8</cell><cell>4</cell><cell>0</cell><cell>23,552</cell><cell>920</cell></row><row><cell cols="2">q20 chain</cell><cell>4</cell><cell>2</cell><cell>1</cell><cell>23</cell><cell>3</cell></row></table><note><p>Queries in terms of shape, numbers of atoms, variables, constants, rewritings, and rewriting time (Rapid).</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Construction of conflict graph in milliseconds w.r.t. size uX and conflicts cY.</figDesc><table><row><cell></cell><cell>033</cell><cell>2,384</cell><cell>2,498</cell><cell>2,710</cell><cell>2,920</cell><cell>3,113</cell></row><row><cell>u5</cell><cell>7,758</cell><cell>8,542</cell><cell>8,920</cell><cell>9,644</cell><cell>10,462</cell><cell>11,230</cell></row><row><cell>u20</cell><cell>27,748</cell><cell>29,878</cell><cell>31,792</cell><cell>34,683</cell><cell>36,982</cell><cell>40,586</cell></row><row><cell>u50</cell><cell>73,031</cell><cell>78,673</cell><cell>80,563</cell><cell>91,122</cell><cell>100,134</cell><cell>118,375</cell></row><row><cell>u100</cell><cell>153,476</cell><cell>166,234</cell><cell>177,441</cell><cell>200,468</cell><cell>221,172</cell><cell>247,191</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Characteristics of ABoxes used in experiments.</figDesc><table><row><cell>ABox id</cell><cell>size</cell><cell>% assertions</cell><cell># assertions</cell><cell>% assertions</cell></row><row><cell></cell><cell></cell><cell>added to uXc0</cell><cell>in some conflict</cell><cell>in some conflict</cell></row><row><cell>u1c0</cell><cell>75,663</cell><cell>0</cell><cell>0</cell><cell></cell></row><row><cell>u1c1</cell><cell>75,724</cell><cell>0.08</cell><cell>2,373</cell><cell></cell></row><row><cell>u1c5</cell><cell>75,951</cell><cell>0.38</cell><cell>6,412</cell><cell></cell></row><row><cell>u1c10</cell><cell>76,201</cell><cell>0.70</cell><cell>10,891</cell><cell></cell></row><row><cell>u1c20</cell><cell>76,821</cell><cell>1.51</cell><cell>20,175</cell><cell></cell></row><row><cell>u1c30</cell><cell>77,447</cell><cell>2.30</cell><cell>26,086</cell><cell></cell></row><row><cell>u1c50</cell><cell>78,593</cell><cell>3.73</cell><cell>34,814</cell><cell></cell></row><row><cell>u5c0</cell><cell>463,325</cell><cell>0</cell><cell>0</cell><cell></cell></row><row><cell>u5c1</cell><cell>463,691</cell><cell>0.08</cell><cell>12,191</cell><cell></cell></row><row><cell>u5c5</cell><cell>465,157</cell><cell>0.39</cell><cell>45,906</cell><cell></cell></row><row><cell>u5c10</cell><cell>466,919</cell><cell>0.77</cell><cell>83,263</cell><cell></cell></row><row><cell>u5c20</cell><cell>470,674</cell><cell>1.56</cell><cell>137,836</cell><cell></cell></row><row><cell>u5c30</cell><cell>474,368</cell><cell>2.33</cell><cell>172,245</cell><cell></cell></row><row><cell>u5c50</cell><cell>481,400</cell><cell>3.75</cell><cell>221,900</cell><cell></cell></row><row><cell>u20c0</cell><cell>1,981,872</cell><cell>0</cell><cell>0</cell><cell></cell></row><row><cell>u20c1</cell><cell>1,983,493</cell><cell>0.08</cell><cell>69,597</cell><cell></cell></row><row><cell>u20c5</cell><cell>1,989,788</cell><cell>0.40</cell><cell>253,141</cell><cell></cell></row><row><cell>u20c10</cell><cell>1,997,445</cell><cell>0.78</cell><cell>408,398</cell><cell></cell></row><row><cell>u20c20</cell><cell>2,013,048</cell><cell>1.55</cell><cell>610,271</cell><cell></cell></row><row><cell>u20c30</cell><cell>2,028,069</cell><cell>2.28</cell><cell>748,664</cell><cell></cell></row><row><cell>u20c50</cell><cell>2,056,957</cell><cell>3.65</cell><cell>946,819</cell><cell></cell></row><row><cell>u50c0</cell><cell>4,934,691</cell><cell>0</cell><cell>0</cell><cell></cell></row><row><cell>u50c1</cell><cell>4,938,737</cell><cell>0.08</cell><cell>224,131</cell><cell></cell></row><row><cell>u50c5</cell><cell>4,954,494</cell><cell>0.40</cell><cell>686,159</cell><cell></cell></row><row><cell>u50c10</cell><cell>4,973,292</cell><cell>0.78</cell><cell>1,034,226</cell><cell></cell></row><row><cell>u50c20</cell><cell>5,010,776</cell><cell>1.52</cell><cell>1,517,499</cell><cell></cell></row><row><cell>u50c30</cell><cell>5,046,802</cell><cell>2.22</cell><cell>1,865,679</cell><cell></cell></row><row><cell>u50c50</cell><cell>5,115,473</cell><cell>3.53</cell><cell>2,353,739</cell><cell></cell></row><row><cell>u100c0</cell><cell>9,938,139</cell><cell>0</cell><cell>0</cell><cell></cell></row><row><cell>u100c1</cell><cell>9,946,144</cell><cell>0.08</cell><cell>546,708</cell><cell></cell></row><row><cell>u100c5</cell><cell>9,977,656</cell><cell>0.40</cell><cell>1,381,298</cell><cell></cell></row><row><cell>u100c10</cell><cell>10,014,894</cell><cell>0.77</cell><cell>2,077,201</cell><cell></cell></row><row><cell>u100c20</cell><cell>10,087,801</cell><cell>1.48</cell><cell>3,069,321</cell><cell></cell></row><row><cell>u100c30</cell><cell>10,157,192</cell><cell>2.16</cell><cell>3,755,732</cell><cell></cell></row><row><cell>u100c50</cell><cell>10,289,863</cell><cell>3.42</cell><cell>4,728,588</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Number of answers per category for three sizes of ABoxes and three ratios of conflicts (about 4%, 30%, and 45% of assertions involved in some conflict).</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 8 :</head><label>8</label><figDesc>Number of answers of each class with distribution (in %) of their explanation times (in second) per query over ABoxes with 20 universities and three different ratios of conflicts.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>u20c1</cell><cell></cell><cell></cell><cell></cell><cell>u20c20</cell><cell></cell><cell></cell><cell></cell><cell>u20c50</cell><cell></cell></row><row><cell></cell><cell>#ans</cell><cell cols="11">0.01 [0.01, 0.1[ [0.1, 1[ &gt;1 #ans &lt;0.01 [0.01, 0.1[ [0.1, 1[ &gt;1 #ans &lt;0.01 [0.01, 0.1[ [0.1, 1[ &gt;1</cell></row><row><cell cols="3">q2 Sure 189186 &gt;99.99</cell><cell>&lt;0.01</cell><cell cols="3">0 0 163260 &gt;99.99</cell><cell>&lt;0.01</cell><cell cols="3">0 0 127098 &gt;99.99</cell><cell>&lt;0.01</cell><cell>0 0</cell></row><row><cell>Likely</cell><cell>228</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell cols="2">9927 99.98</cell><cell>0.02</cell><cell cols="3">0 0 23819 99.97</cell><cell>0.03</cell><cell>0 0</cell></row><row><cell>Poss.</cell><cell>1019</cell><cell>100</cell><cell>0</cell><cell cols="3">0 0 22489 99.96</cell><cell>0.04</cell><cell cols="3">0 0 52117 99.95</cell><cell>0.05</cell><cell>0 0</cell></row><row><cell>q3 Sure</cell><cell>85</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell>0</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Poss.</cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell>85</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>87</cell><cell>100</cell><cell>0</cell><cell>0 0</cell></row><row><cell>q5 Sure</cell><cell>10</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell>0</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Likely</cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell>10</cell><cell>70</cell><cell>30</cell><cell>0 0</cell><cell>0</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Poss.</cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell>10</cell><cell>90</cell><cell>10</cell><cell>0 0</cell></row><row><cell>q6 Sure</cell><cell>235</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>177</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>0</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Likely</cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell>14</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>0</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Poss.</cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell>110</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>342</cell><cell>100</cell><cell>0</cell><cell>0 0</cell></row><row><cell>q7 Sure</cell><cell>91</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell>0</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Poss.</cell><cell>46</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>138</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>149</cell><cell>100</cell><cell>0</cell><cell>0 0</cell></row><row><cell>q8 Poss.</cell><cell>31</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>31</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>32</cell><cell>100</cell><cell>0</cell><cell>0 0</cell></row><row><cell>q9 Sure</cell><cell cols="2">33433 &gt;99.99</cell><cell>&lt;0.01</cell><cell cols="3">0 0 25701 &gt;99.99</cell><cell>&lt;0.01</cell><cell cols="3">0 0 21462 99.96</cell><cell>0.04</cell><cell>0 0</cell></row><row><cell>Likely</cell><cell>60</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>59</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell cols="2">267 99.63</cell><cell>0.37</cell><cell>0 0</cell></row><row><cell>Poss.</cell><cell>2714</cell><cell>100</cell><cell>0</cell><cell cols="3">0 0 13282 99.89</cell><cell>0.11</cell><cell cols="3">0 0 21419 93.01</cell><cell>6.99</cell><cell>0 0</cell></row><row><cell>q10 Poss.</cell><cell>58</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>62</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>66</cell><cell>100</cell><cell>0</cell><cell>0 0</cell></row><row><cell>q11 Sure</cell><cell>14331</cell><cell>100</cell><cell>0</cell><cell cols="2">0 0 12613</cell><cell>100</cell><cell>0</cell><cell cols="2">0 0 10329</cell><cell>100</cell><cell>0</cell><cell>0 0</cell></row><row><cell>Likely</cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell>42</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>267</cell><cell>100</cell><cell>0</cell><cell>0 0</cell></row><row><cell>Poss.</cell><cell>145</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell cols="2">2781 99.89</cell><cell>0.11</cell><cell>0 0</cell><cell cols="2">6373 99.70</cell><cell>0.30</cell><cell>0 0</cell></row><row><cell>q12 Sure</cell><cell>7082</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>5830</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>5395</cell><cell>100</cell><cell>0</cell><cell>0 0</cell></row><row><cell>Likely</cell><cell cols="2">218 11.93</cell><cell>88.07</cell><cell>0 0</cell><cell cols="2">880 25.68</cell><cell>74.32</cell><cell>0 0</cell><cell cols="2">991 58.83</cell><cell cols="2">40.06 1.11 0</cell></row><row><cell>Poss.</cell><cell cols="2">251 47.41</cell><cell cols="2">23.90 28.69 0</cell><cell cols="2">3881 50.40</cell><cell cols="2">18.50 31.10 0</cell><cell cols="2">8769 54.29</cell><cell cols="2">11.68 34.03 0</cell></row><row><cell>q13 Sure</cell><cell>28891</cell><cell>100</cell><cell>0</cell><cell cols="2">0 0 25791</cell><cell>100</cell><cell>0</cell><cell cols="2">0 0 21471</cell><cell>100</cell><cell>0</cell><cell>0 0</cell></row><row><cell>Likely</cell><cell>64</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>1780</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell cols="2">4185 99.95</cell><cell>0.05</cell><cell>0 0</cell></row><row><cell>Poss.</cell><cell cols="2">204 98.53</cell><cell cols="2">0 1.47 0</cell><cell cols="2">4028 98.01</cell><cell cols="2">0.05 1.94 0</cell><cell cols="2">9430 98.30</cell><cell cols="2">0.22 1.48 0</cell></row><row><cell>q14 Sure</cell><cell>4785</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>2539</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>1007</cell><cell>100</cell><cell>0</cell><cell>0 0</cell></row><row><cell>Likely</cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell>0</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Poss.</cell><cell>166</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>2412</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>3944</cell><cell>100</cell><cell>0</cell><cell>0 0</cell></row><row><cell>q15 Sure</cell><cell>12050</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>1715</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>54</cell><cell>100</cell><cell>0</cell><cell>0 0</cell></row><row><cell>Poss.</cell><cell cols="2">1702 99.82</cell><cell cols="4">0 0.18 0 12143 99.28</cell><cell cols="4">0.02 0.70 0 13946 98.69</cell><cell cols="2">0.03 1.28 0</cell></row><row><cell>q17 Sure</cell><cell>27</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell>0</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Poss.</cell><cell>10</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>37</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell cols="2">39 82.05</cell><cell>17.95</cell><cell>0 0</cell></row><row><cell>q18 Sure</cell><cell cols="2">81760 &gt;99.99</cell><cell>&lt;0.01</cell><cell cols="3">0 0 58294 99.99</cell><cell>0.01</cell><cell cols="3">0 0 34795 99.98</cell><cell>0.02</cell><cell>0 0</cell></row><row><cell>Poss.</cell><cell>1342</cell><cell>100</cell><cell>0</cell><cell cols="3">0 0 24959 99.87</cell><cell>0.13</cell><cell cols="3">0 0 48770 99.91</cell><cell>0.09</cell><cell>0 0</cell></row><row><cell>q19 Poss.</cell><cell>1</cell><cell>0</cell><cell>100</cell><cell>0 0</cell><cell>8</cell><cell>0</cell><cell cols="2">87.50 12.50 0</cell><cell>20</cell><cell>0</cell><cell>45</cell><cell>55 0</cell></row><row><cell>q20 Sure</cell><cell>50</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>25</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>0</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Poss.</cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell>25</cell><cell>100</cell><cell>0</cell><cell>0 0</cell><cell>50</cell><cell>100</cell><cell>0</cell><cell>0 0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 9 :</head><label>9</label><figDesc>Number of answers of each class with distribution (in %) of their explanation times (in second) per query over ABoxes with 100 universities and three different ratios of conflicts.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 10 :</head><label>10</label><figDesc>Distribution of the times (in second) for explaining K |= S q( a) in Case 1.</figDesc><table><row><cell>1[ &gt;1</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>Our results for DL-LiteR do not require the UNA, but it is standard to adopt the UNA for databases and DL-Lite and necessary for the proper treatment of other DL-Lite dialects admitting functionality.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_1"><p>This proposition is similar to Theorem 6 by<ref type="bibr" target="#b51">Lembo et al. (2015)</ref>. We give a proof here for the sake of completeness and since our formulation differs somewhat.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_2"><p>Available for download at: https://www.lri.fr/ ~bourgaux/CQAPri</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_3"><p>These queries were available on the websites associated with these systems at the time we developed our benchmark, but the websites are no longer online.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was supported by the <rs type="funder">ANR</rs> project <rs type="projectName">PAGODA</rs> (<rs type="grantNumber">ANR-12-JS02-007-01</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_pdA7y8V">
					<idno type="grant-number">ANR-12-JS02-007-01</idno>
					<orgName type="project" subtype="full">PAGODA</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ALGORITHM 4: RelNecNegIAR Input: a conjunctive query q( x), a candidate answer a, a KB K = T , A Output: relevant and necessary assertions for explaining K |= IAR q( a)</p><p>1 Causes ← ComputeCauses(q( a), K);</p><p>11 Relevant ← Relevant i ; 12 Output Relevant, N ecessary;</p><p>Proof. We can decide in NP that an explanation E is not a best explanation (according to some polynomial-time ranking criterion) by guessing a subset E ⊆ A and verifying in polynomial time w.r.t. data complexity that E is an explanation and that it is better than E according to the given criterion. This yields a coNP upper bound for best rec.</p><p>Finally, we establish the intractability of best rec and genBest when explanations are ranked by cardinality.</p><p>Proposition 5.25. Regarding explanations for negative IAR-answers in the case where explanations are ranked by cardinality, genBest is NP-hard, and best rec is coNP-hard w.r.t. data complexity.</p><p>Proof. We give a reduction from the problem of deciding if a truth assignment that satisfies a monotone 2-SAT formula assigns a smallest number of variables to true. This problem is coNP-complete (coNP-hardness can be shown by a straightforward reduction from the complement of the well-known NP-complete vertex cover problem).</p><p>Let ϕ = C 1 ∧ ... ∧ C k be a monotone 2-CNF over the variables {X 1 , ..., X n }, and let ν be a truth assignment that satisfies ϕ. Consider the following KB:</p><p>The causes for q take the form {P 1 (c j , x i 1 ), P 2 (c j , x i 2 )}. It follows that an explanation for T , A |= IAR q is a set E of T -assertions such that for every c j , there is at least one X i ∈ C j such that T (x i ) ∈ E. Thus, deciding if ν assigns a minimal number of variables to true is equivalent to deciding if E = {T (x i ) | ν(X i ) = true} is a smallest explanation. This yields the coNP-hardness of best rec, as well as the NP-and coNP-hardness of genBest: we can solve the minimum assignment problem -and its complement -by generating a cardinality-minimal explanation and comparing its size with the number of variables set to true by the candidate assignment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A. Omitted Proofs of Membership in AC 0</head><p>Thoughout this section, we will be working with a TBox T , a CQ q, a candidate answer a, and a UCQ-rewriting Q of q( a) w.r.t. T and consistent ABoxes. We let Σ = Σ C ∪ Σ R denote the signature of T and q, with Σ C (resp. Σ R ) is the set of concept names (resp. role names) occurring in T and/or q.</p><p>We begin with some technical preliminaries. Recall that I A is the interpretation isomorphic to ABox A, i.e. having the individuals from A as its universe and interpreting all concept and role names so that an assertion holds iff it appears in A. For any CQ Ψ, we can define a corresponding ABox A Ψ consisting of the assertions obtained by replacing each variable v in Ψ by a fresh individual a v , and then let I Ψ be the interpretation isomorphic to A Ψ . Given a first-order formula Φ and an interpretation I, the notation I |= π Φ will denote that Φ is satisfied in the interpretation I under a variable assignment π that maps every variable in Φ to an element of the universe of I (which is an individual if we consider an interpretation of the form I A ). We will use π(Φ) to denote the result of replacing each variable v in Φ by π(v). Note that when Φ is a CQ, π(Φ) is a conjunction of assertions, which can be viewed as an ABox, continuing our convention of treating CQs either as conjunctive formulas or sets of atoms, depending on which is more convenient.</p><p>To establish the AC 0 membership results from Propositions 5.7, 5.15, and 5.23, we show how to construct FO-formulas that solve the recognition, relevance, and necessity tasks from these propositions. To render our constructions shorter and more readable, we will build these formulas in a modular way, with subformulas introduced for expressions that are used in multiple rewritings. For example, we will construct subformulas that check whether the image of a CQ defines a cause or whether it conflicts with all causes of q( a). Our constructions are very loosely based upon the rewritings for k-support and k-defeater semantics by <ref type="bibr" target="#b21">Bienvenu and Rosati (2013)</ref>.</p><p>We start by defining some basic formulas that can be used to check whether an image of a CQ contains a certain assertion, is T -(in)consistent, entails the query answer, or has a conflict in the ABox.</p><p>Lemma A.1. Given a CQ Ψ and an atom α, one can construct FO-formulas contains(Ψ, α), cons(Ψ), incons(Ψ), hasMatch(Ψ), and hasConflict(Ψ) such that the following statements hold for every ABox A and variable assignment π with π(Ψ) ⊆ A:</p><p>For (1), we show how to define the formula contains(Ψ, α) when α is a role atom R(t, t ) (with t, t terms). If R(t 1 , t 1 ), . . . , R(t n , t n ) is an enumeration of all of the R-atoms occurring in the CQ Ψ, then it suffices to set</p><p>Note that v and v are fresh variables not occurring in z. Correctness follows from Proposition 5.21, together with Lemmas A.1 and A.2.</p><p>Appendix B. Tables <ref type="table"></ref>and<ref type="table">Figures from Sections 6</ref> and<ref type="table">7</ref> Figure <ref type="figure">3</ref>: Screenshot from Protégé ontology editor (https://protege.stanford.edu/). The left side displays a part of the concept hierarchy of the LUBM ∃ 20 ontology, and the upper part of the right side shows of which concepts AssistantProfessor is a subconcept (here the single concept Professor). The lower part of the right side displays the negative inclusions added between AssistantProfessor and concepts with the same closest super-concept Professor: FullProfessor, ExDean, VisitingProfessor, AssociateProfessor and Dean. We did not add disjointness axioms with the concepts SubjXProfessor, because such concepts indicate the domain of a professor, which is independent from its seniority.    Table <ref type="table">13</ref>: Distribution of the times (in second) for explaining K |= IAR q( a) in Case 4.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">) ∧ teacherOf(x, z) ∧ advisor(u, x)∧ graduateStudent(u) ∧ degreeFrom(x, v) ∧ degreeFrom(u, w) q5(x) =∃yPerson(Dept2.U niv0/GradStudent131)∧ takesCourse(Dept2.U niv0/GradStudent131, y)∧ GraduateCourse(y) ∧ takesCourse(x, y) ∧ Person(x) q6(x, z) =∃yEmployee(x) ∧ publicationAuthor(y, x) ∧ memberOf(x, Dept4.U niv0)∧ Employee(z) ∧ publicationAuthor(y, z) ∧ memberOf(z, Dept4.U niv0) q7(y) =∃xEmployee(x) ∧ memberOf(x, Dept2.U niv0) ∧ degreeFrom(x, y) q8(x) =∃yteacherOf(x, y) ∧ degreeFrom(x, U niv532) q9(x, z) =∃yuEmployee(x) ∧ memberOf(x, u) ∧ degreeFrom(x, y)∧ Employee(z) ∧ memberOf(z, u) ∧ degreeFrom(z, y) q10(x, z) =∃uEmployee(x) ∧ memberOf(x, u) ∧ degreeFrom(x, U niv532)∧ Employee(z) ∧ memberOf(z, u) ∧ degreeFrom(z, U niv532) q11(x) =∃yFaculty(x) ∧ publicationAuthor(y, x) q12(x) =Organization(x)</title>
	</analytic>
	<monogr>
		<title level="j">References</title>
		<imprint/>
		<respStmt>
			<orgName>Dept</orgName>
		</respStmt>
	</monogr>
	<note>: Queries used in experiments</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Consistent query answers in inconsistent databases</title>
		<author>
			<persName><forename type="first">M</forename><surname>Arenas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Bertossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chomicki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of PODS</title>
		<meeting>PODS</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Dialectical characterization of consistent query explanation with existential rules</title>
		<author>
			<persName><forename type="first">A</forename><surname>Arioua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Croitoru</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of FLAIRS</title>
		<meeting>FLAIRS</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A dialectical proof theory for universal acceptance in coherent logic-based argumentation frameworks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Arioua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Croitoru</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ECAI</title>
		<meeting>ECAI</meeting>
		<imprint>
			<date type="published" when="2016">2016b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">DALEK: A tool for dialectical explanations in inconsistent knowledge bases</title>
		<author>
			<persName><forename type="first">A</forename><surname>Arioua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Croitoru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Buche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COMMA</title>
		<meeting>COMMA</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">On conceptual graphs and explanation of query answering under inconsistency</title>
		<author>
			<persName><forename type="first">A</forename><surname>Arioua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tamani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Croitoru</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCS</title>
		<meeting>ICCS</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Query answering explanation in inconsistent Datalog+/-knowledge bases</title>
		<author>
			<persName><forename type="first">A</forename><surname>Arioua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tamani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Croitoru</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of DEXA</title>
		<meeting>DEXA</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Computational Complexity -A Modern Approach</title>
		<author>
			<persName><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Barak</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The DL-Lite family and relations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Artale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Calvanese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kontchakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zakharyaschev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research (JAIR)</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1" to="69" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">The Description Logic Handbook: Theory, Implementation and Applications</title>
		<editor>Baader, F., Calvanese, D., McGuinness, D., Nardi, D., &amp; Patel-Schneider, P. F.</editor>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Pinpointing in the description logic EL +</title>
		<author>
			<persName><forename type="first">F</forename><surname>Baader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Peñaloza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Suntisrivaraporn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of KI</title>
		<meeting>KI</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The logical diversity of explanations in OWL ontologies</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Parsia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Sattler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CIKM</title>
		<meeting>CIKM</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Non-objection inference for inconsistency-tolerant query answering</title>
		<author>
			<persName><forename type="first">S</forename><surname>Benferhat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Bouraoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Croitoru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Papini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tabia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The sat4j library, release 2.2</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Berre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Parrain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JSAT</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="59" to="64" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Consistent query answering in databases</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Bertossi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGMOD Record</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="68" to="76" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Database Repairing and Consistent Query Answering</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Bertossi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Synthesis Lectures on Data Management</title>
		<imprint>
			<publisher>Morgan &amp; Claypool Publishers</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Query-based why-not provenance with nedexplain</title>
		<author>
			<persName><forename type="first">N</forename><surname>Bidoit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Herschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tzompanaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EDBT</title>
		<meeting>EDBT</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">On the complexity of consistent query answering in the presence of simple ontologies</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bienvenu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Inconsistency-tolerant querying of description logic knowledge bases</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bienvenu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bourgaux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Reasoning Web, Tutorial Lectures</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="156" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Querying inconsistent description logic knowledge bases under preferred repair semantics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bienvenu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bourgaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Goasdoué</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Explaining inconsistency-tolerant query answering over description logic knowledge bases</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bienvenu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bourgaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Goasdoué</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Tractable approximations of consistent query answering for robust ontology-based data access</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bienvenu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rosati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Explanation in the DL-Lite family of description logics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Borgida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Calvanese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rodriguez-Muro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of OTM</title>
		<meeting>OTM</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Explaining ALC subsumption</title>
		<author>
			<persName><forename type="first">A</forename><surname>Borgida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Franconi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Horrocks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ECAI</title>
		<meeting>ECAI</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An efficient incremental algorithm for generating all maximal independent sets in hypergraphs of bounded dimension</title>
		<author>
			<persName><forename type="first">E</forename><surname>Boros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Elbassioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gurvich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Khachiyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Parallel Processing Letters</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="253" to="266" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Inconsistency Handling in Ontology-Mediated Query Answering</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bourgaux</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<pubPlace>France</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Paris-Saclay</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Efficient query answering in DL-Lite through FOL reformulation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bursztyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Goasdoué</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Manolescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of DL</title>
		<meeting>DL</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>extended abstract</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Teaching an RDBMS about ontological constraints</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bursztyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Goasdoué</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Manolescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1161" to="1172" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Tractable reasoning and efficient query answering in description logics: The DL-Lite family</title>
		<author>
			<persName><forename type="first">D</forename><surname>Calvanese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>De Giacomo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lembo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lenzerini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rosati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Automated Reasoning (JAR)</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="385" to="429" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Reasoning about explanations for negative query answers in DL-Lite</title>
		<author>
			<persName><forename type="first">D</forename><surname>Calvanese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ortiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Simkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Stefanoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research (JAIR)</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="635" to="669" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Optimal implementation of conjunctive queries in relational data bases</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Merlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of STOC</title>
		<meeting>STOC</meeting>
		<imprint>
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Provenance in databases: Why, how, and where</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cheney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chiticariu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">C</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends in Databases</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="379" to="474" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Consistent query answering: Five easy pieces</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chomicki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICDT</title>
		<meeting>ICDT</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Computing consistent query answers using conflict hypergraphs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chomicki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Marcinkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Staworko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CIKM</title>
		<meeting>CIKM</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Hippo: A system for computing consistent answers to a class of SQL queries</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chomicki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Marcinkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Staworko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EDBT</title>
		<meeting>EDBT</meeting>
		<imprint>
			<date type="published" when="2004">2004b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Optimized query rewriting for OWL 2 QL</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chortaras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Trivela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Stamou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CADE</title>
		<meeting>CADE</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Weight-based consistent query answering over inconsistent SHIQ knowledge bases</title>
		<author>
			<persName><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-D</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge and Information Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="335" to="371" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A tractable approach to abox abduction over description logic ontologies</title>
		<author>
			<persName><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Towards tractable and practical ABox abduction over inconsistent description logic ontologies</title>
		<author>
			<persName><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Query rewriting for Horn-SHIQ plus rules</title>
		<author>
			<persName><forename type="first">T</forename><surname>Eiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ortiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Simkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Conquer: Efficient management of inconsistent databases</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fuxman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fazli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGMOD</title>
		<meeting>SIGMOD</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">First-order query rewriting for inconsistent databases</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fuxman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICDT</title>
		<meeting>ICDT</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">LUBM: A benchmark for OWL knowledge base systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heflin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Web Sem</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="158" to="182" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Explaining missing answers to SPJUA queries</title>
		<author>
			<persName><forename type="first">M</forename><surname>Herschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Hernández</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="185" to="196" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">The cognitive complexity of OWL justifications</title>
		<author>
			<persName><forename type="first">M</forename><surname>Horridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Parsia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Sattler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ISWC</title>
		<meeting>ISWC</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Extracting justifications from bioportal ontologies</title>
		<author>
			<persName><forename type="first">M</forename><surname>Horridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Parsia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Sattler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ISWC</title>
		<meeting>ISWC</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Expressibility as a complexity measure: results and directions</title>
		<author>
			<persName><forename type="first">N</forename><surname>Immerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Conference on Structure in Complexity Theory</title>
		<meeting>Conference on Structure in Complexity Theory</meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Debugging unsatisfiable classes in OWL ontologies</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kalyanpur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Parsia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sirin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Hendler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal Web Sem</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="268" to="293" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Efficient querying of inconsistent databases with binary integer programming</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Kolaitis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pema</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-C</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="397" to="408" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Inconsistency-tolerant semantics for description logics</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lembo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lenzerini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rosati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ruzzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Savo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of RR</title>
		<meeting>RR</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Query rewriting for inconsistent DL-Lite ontologies</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lembo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lenzerini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rosati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ruzzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Savo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of RR</title>
		<meeting>RR</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Inconsistency-tolerant query answering in ontology-based data access</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lembo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lenzerini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rosati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ruzzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Savo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal Web Sem</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="3" to="29" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Redundancy in logic I: Cnf propositional formulae</title>
		<author>
			<persName><forename type="first">P</forename><surname>Liberatore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell. (AIJ)</title>
		<imprint>
			<biblScope unit="volume">163</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="232" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Inconsistency handling in Datalog+/-ontologies</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lukasiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">I</forename><surname>Simari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ECAI</title>
		<meeting>ECAI</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Complexity of inconsistencytolerant query answering in Datalog+</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lukasiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">I</forename><surname>Simari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of OTM</title>
		<meeting>OTM</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">The combined approach to OBDA: Taming role hierarchies using filters</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lutz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Seylan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Toman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wolter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ISWC</title>
		<meeting>ISWC</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">The consistency extractor system: Answer set programs for consistent query answering in databases</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Marileo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Bertossi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Knowl. Eng</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="545" to="572" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Explaining subsumption in description logics</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Mcguinness</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Borgida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">OWL 2 Web Ontology Language profiles</title>
		<author>
			<persName><forename type="first">B</forename><surname>Motik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cuenca Grau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Horrocks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fokoue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lutz</surname></persName>
		</author>
		<ptr target="http://www.w3.org/TR/owl2-profiles/" />
	</analytic>
	<monogr>
		<title level="m">W3C Recommendation</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Factorised representations of query results: size bounds and readability</title>
		<author>
			<persName><forename type="first">D</forename><surname>Olteanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zavodny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICDT</title>
		<meeting>ICDT</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">OWL 2 Web Ontology Language: Document overview</title>
		<author>
			<persName><forename type="first">W</forename></persName>
			<affiliation>
				<orgName type="collaboration">OWL Working Group</orgName>
			</affiliation>
		</author>
		<ptr target="https://www.w3.org/TR/owl2-overview/" />
	</analytic>
	<monogr>
		<title level="m">W3C Recommendation</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Computational complexity</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Papadimitriou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Addison-Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Complexity of axiom pinpointing in the DL-Lite family of description logics</title>
		<author>
			<persName><forename type="first">R</forename><surname>Peñaloza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sertkaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ECAI</title>
		<meeting>ECAI</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Efficient query answering for OWL 2</title>
		<author>
			<persName><forename type="first">H</forename><surname>Pérez-Urbina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Horrocks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Motik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ISWC</title>
		<meeting>ISWC</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">On the complexity of dealing with inconsistency in description logic ontologies</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rosati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Improving query answering over DL-Lite ontologies</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rosati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Almatelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of KR</title>
		<meeting>KR</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Evaluation of techniques for inconsistency handling in OWL 2 QL ontologies</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rosati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ruzzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Graziosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Masotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ISWC</title>
		<meeting>ISWC</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Non-standard reasoning services for the debugging of description logic terminologies</title>
		<author>
			<persName><forename type="first">S</forename><surname>Schlobach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cornet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Axiom pinpointing in lightweight description logics via horn-sat encoding and conflict analysis</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sebastiani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vescovi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CADE</title>
		<meeting>CADE</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Knowledge compilation using horn approximations</title>
		<author>
			<persName><forename type="first">B</forename><surname>Selman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Compact rewritings for existential rules</title>
		<author>
			<persName><forename type="first">M</forename><surname>Thomazo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Efficient query answering over expressive inconsistent description logics</title>
		<author>
			<persName><forename type="first">E</forename><surname>Tsalapati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Stoilos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Stamou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Koletsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Towards scalable and complete query explanation with OWL 2 EL ontologies</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chitsaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CIKM</title>
		<meeting>CIKM</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Pagoda: Payas-you-go ontology query answering using a Datalog reasoner</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Grau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nenov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kaminski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Horrocks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research (JAIR)</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="309" to="367" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
